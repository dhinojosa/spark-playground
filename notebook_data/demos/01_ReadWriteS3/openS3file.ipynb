{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "199688dc-56e6-4406-a0c5-b5a47e7d3dd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/09/24 04:48:33 INFO SparkContext: Running Spark version 3.3.0\n",
      "23/09/24 04:48:33 INFO ResourceUtils: ==============================================================\n",
      "23/09/24 04:48:33 INFO ResourceUtils: No custom resources configured for spark.driver.\n",
      "23/09/24 04:48:33 INFO ResourceUtils: ==============================================================\n",
      "23/09/24 04:48:33 INFO SparkContext: Submitted application: openS3file\n",
      "23/09/24 04:48:33 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)\n",
      "23/09/24 04:48:33 INFO ResourceProfile: Limiting resource is cpu\n",
      "23/09/24 04:48:33 INFO ResourceProfileManager: Added ResourceProfile id: 0\n",
      "23/09/24 04:48:33 INFO SecurityManager: Changing view acls to: root\n",
      "23/09/24 04:48:33 INFO SecurityManager: Changing modify acls to: root\n",
      "23/09/24 04:48:33 INFO SecurityManager: Changing view acls groups to: \n",
      "23/09/24 04:48:33 INFO SecurityManager: Changing modify acls groups to: \n",
      "23/09/24 04:48:33 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()\n",
      "23/09/24 04:48:33 DEBUG TransportServer: Shuffle server started on port: 35985\n",
      "23/09/24 04:48:33 INFO Utils: Successfully started service 'sparkDriver' on port 35985.\n",
      "23/09/24 04:48:33 DEBUG SparkEnv: Using serializer: class org.apache.spark.serializer.JavaSerializer\n",
      "23/09/24 04:48:33 INFO SparkEnv: Registering MapOutputTracker\n",
      "23/09/24 04:48:33 DEBUG MapOutputTrackerMasterEndpoint: init\n",
      "23/09/24 04:48:33 INFO SparkEnv: Registering BlockManagerMaster\n",
      "23/09/24 04:48:33 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information\n",
      "23/09/24 04:48:33 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up\n",
      "23/09/24 04:48:33 INFO SparkEnv: Registering BlockManagerMasterHeartbeat\n",
      "23/09/24 04:48:33 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-2fc667c8-6e8c-4804-958a-36a7ea1aaaa7\n",
      "23/09/24 04:48:33 DEBUG DiskBlockManager: Adding shutdown hook\n",
      "23/09/24 04:48:33 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB\n",
      "23/09/24 04:48:33 INFO SparkEnv: Registering OutputCommitCoordinator\n",
      "23/09/24 04:48:33 DEBUG OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: init\n",
      "23/09/24 04:48:33 DEBUG SecurityManager: Created SSL options for ui: SSLOptions{enabled=false, port=None, keyStore=None, keyStorePassword=None, trustStore=None, trustStorePassword=None, protocol=None, enabledAlgorithms=Set()}\n",
      "23/09/24 04:48:33 DEBUG JettyUtils: Using requestHeaderSize: 8192\n",
      "23/09/24 04:48:33 INFO Utils: Successfully started service 'SparkUI' on port 4040.\n",
      "23/09/24 04:48:33 INFO SparkContext: Added JAR file:///root/.ivy2/jars/org.apache.spark_spark-hadoop-cloud_2.12-3.3.0.jar at spark://172.18.0.4:35985/jars/org.apache.spark_spark-hadoop-cloud_2.12-3.3.0.jar with timestamp 1695530913524\n",
      "23/09/24 04:48:33 INFO SparkContext: Added JAR file:///root/.ivy2/jars/org.apache.hadoop_hadoop-client-runtime-3.3.2.jar at spark://172.18.0.4:35985/jars/org.apache.hadoop_hadoop-client-runtime-3.3.2.jar with timestamp 1695530913524\n",
      "23/09/24 04:48:33 INFO SparkContext: Added JAR file:///root/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.2.jar at spark://172.18.0.4:35985/jars/org.apache.hadoop_hadoop-aws-3.3.2.jar with timestamp 1695530913524\n",
      "23/09/24 04:48:33 INFO SparkContext: Added JAR file:///root/.ivy2/jars/org.apache.hadoop_hadoop-openstack-3.3.2.jar at spark://172.18.0.4:35985/jars/org.apache.hadoop_hadoop-openstack-3.3.2.jar with timestamp 1695530913524\n",
      "23/09/24 04:48:33 INFO SparkContext: Added JAR file:///root/.ivy2/jars/joda-time_joda-time-2.10.13.jar at spark://172.18.0.4:35985/jars/joda-time_joda-time-2.10.13.jar with timestamp 1695530913524\n",
      "23/09/24 04:48:33 INFO SparkContext: Added JAR file:///root/.ivy2/jars/com.fasterxml.jackson.core_jackson-databind-2.13.3.jar at spark://172.18.0.4:35985/jars/com.fasterxml.jackson.core_jackson-databind-2.13.3.jar with timestamp 1695530913524\n",
      "23/09/24 04:48:33 INFO SparkContext: Added JAR file:///root/.ivy2/jars/com.fasterxml.jackson.core_jackson-annotations-2.13.3.jar at spark://172.18.0.4:35985/jars/com.fasterxml.jackson.core_jackson-annotations-2.13.3.jar with timestamp 1695530913524\n",
      "23/09/24 04:48:33 INFO SparkContext: Added JAR file:///root/.ivy2/jars/com.fasterxml.jackson.dataformat_jackson-dataformat-cbor-2.13.3.jar at spark://172.18.0.4:35985/jars/com.fasterxml.jackson.dataformat_jackson-dataformat-cbor-2.13.3.jar with timestamp 1695530913524\n",
      "23/09/24 04:48:33 INFO SparkContext: Added JAR file:///root/.ivy2/jars/org.apache.httpcomponents_httpclient-4.5.13.jar at spark://172.18.0.4:35985/jars/org.apache.httpcomponents_httpclient-4.5.13.jar with timestamp 1695530913524\n",
      "23/09/24 04:48:33 INFO SparkContext: Added JAR file:///root/.ivy2/jars/org.apache.httpcomponents_httpcore-4.4.14.jar at spark://172.18.0.4:35985/jars/org.apache.httpcomponents_httpcore-4.4.14.jar with timestamp 1695530913524\n",
      "23/09/24 04:48:33 INFO SparkContext: Added JAR file:///root/.ivy2/jars/org.apache.hadoop_hadoop-azure-3.3.2.jar at spark://172.18.0.4:35985/jars/org.apache.hadoop_hadoop-azure-3.3.2.jar with timestamp 1695530913524\n",
      "23/09/24 04:48:33 INFO SparkContext: Added JAR file:///root/.ivy2/jars/org.apache.hadoop_hadoop-cloud-storage-3.3.2.jar at spark://172.18.0.4:35985/jars/org.apache.hadoop_hadoop-cloud-storage-3.3.2.jar with timestamp 1695530913524\n",
      "23/09/24 04:48:33 INFO SparkContext: Added JAR file:///root/.ivy2/jars/org.eclipse.jetty_jetty-util-ajax-9.4.46.v20220331.jar at spark://172.18.0.4:35985/jars/org.eclipse.jetty_jetty-util-ajax-9.4.46.v20220331.jar with timestamp 1695530913524\n",
      "23/09/24 04:48:33 INFO SparkContext: Added JAR file:///root/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar at spark://172.18.0.4:35985/jars/org.spark-project.spark_unused-1.0.0.jar with timestamp 1695530913524\n",
      "23/09/24 04:48:33 INFO SparkContext: Added JAR file:///root/.ivy2/jars/org.apache.hadoop_hadoop-client-api-3.3.2.jar at spark://172.18.0.4:35985/jars/org.apache.hadoop_hadoop-client-api-3.3.2.jar with timestamp 1695530913524\n",
      "23/09/24 04:48:33 INFO SparkContext: Added JAR file:///root/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.8.4.jar at spark://172.18.0.4:35985/jars/org.xerial.snappy_snappy-java-1.1.8.4.jar with timestamp 1695530913524\n",
      "23/09/24 04:48:33 INFO SparkContext: Added JAR file:///root/.ivy2/jars/org.slf4j_slf4j-api-1.7.32.jar at spark://172.18.0.4:35985/jars/org.slf4j_slf4j-api-1.7.32.jar with timestamp 1695530913524\n",
      "23/09/24 04:48:33 INFO SparkContext: Added JAR file:///root/.ivy2/jars/commons-logging_commons-logging-1.1.3.jar at spark://172.18.0.4:35985/jars/commons-logging_commons-logging-1.1.3.jar with timestamp 1695530913524\n",
      "23/09/24 04:48:33 INFO SparkContext: Added JAR file:///root/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.0.jar at spark://172.18.0.4:35985/jars/com.google.code.findbugs_jsr305-3.0.0.jar with timestamp 1695530913524\n",
      "23/09/24 04:48:33 INFO SparkContext: Added JAR file:///root/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.11.1026.jar at spark://172.18.0.4:35985/jars/com.amazonaws_aws-java-sdk-bundle-1.11.1026.jar with timestamp 1695530913524\n",
      "23/09/24 04:48:33 INFO SparkContext: Added JAR file:///root/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar at spark://172.18.0.4:35985/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar with timestamp 1695530913524\n",
      "23/09/24 04:48:33 INFO SparkContext: Added JAR file:///root/.ivy2/jars/org.apache.hadoop_hadoop-annotations-3.3.2.jar at spark://172.18.0.4:35985/jars/org.apache.hadoop_hadoop-annotations-3.3.2.jar with timestamp 1695530913524\n",
      "23/09/24 04:48:33 INFO SparkContext: Added JAR file:///root/.ivy2/jars/com.fasterxml.jackson.core_jackson-core-2.13.3.jar at spark://172.18.0.4:35985/jars/com.fasterxml.jackson.core_jackson-core-2.13.3.jar with timestamp 1695530913524\n",
      "23/09/24 04:48:33 INFO SparkContext: Added JAR file:///root/.ivy2/jars/commons-codec_commons-codec-1.15.jar at spark://172.18.0.4:35985/jars/commons-codec_commons-codec-1.15.jar with timestamp 1695530913524\n",
      "23/09/24 04:48:33 INFO SparkContext: Added JAR file:///root/.ivy2/jars/com.microsoft.azure_azure-storage-7.0.1.jar at spark://172.18.0.4:35985/jars/com.microsoft.azure_azure-storage-7.0.1.jar with timestamp 1695530913524\n",
      "23/09/24 04:48:33 INFO SparkContext: Added JAR file:///root/.ivy2/jars/org.apache.hadoop.thirdparty_hadoop-shaded-guava-1.1.1.jar at spark://172.18.0.4:35985/jars/org.apache.hadoop.thirdparty_hadoop-shaded-guava-1.1.1.jar with timestamp 1695530913524\n",
      "23/09/24 04:48:33 INFO SparkContext: Added JAR file:///root/.ivy2/jars/org.codehaus.jackson_jackson-mapper-asl-1.9.13.jar at spark://172.18.0.4:35985/jars/org.codehaus.jackson_jackson-mapper-asl-1.9.13.jar with timestamp 1695530913524\n",
      "23/09/24 04:48:33 INFO SparkContext: Added JAR file:///root/.ivy2/jars/org.codehaus.jackson_jackson-core-asl-1.9.13.jar at spark://172.18.0.4:35985/jars/org.codehaus.jackson_jackson-core-asl-1.9.13.jar with timestamp 1695530913524\n",
      "23/09/24 04:48:33 INFO SparkContext: Added JAR file:///root/.ivy2/jars/com.microsoft.azure_azure-keyvault-core-1.0.0.jar at spark://172.18.0.4:35985/jars/com.microsoft.azure_azure-keyvault-core-1.0.0.jar with timestamp 1695530913524\n",
      "23/09/24 04:48:33 INFO SparkContext: Added JAR file:///root/.ivy2/jars/org.apache.hadoop_hadoop-aliyun-3.3.2.jar at spark://172.18.0.4:35985/jars/org.apache.hadoop_hadoop-aliyun-3.3.2.jar with timestamp 1695530913524\n",
      "23/09/24 04:48:33 INFO SparkContext: Added JAR file:///root/.ivy2/jars/org.apache.hadoop_hadoop-azure-datalake-3.3.2.jar at spark://172.18.0.4:35985/jars/org.apache.hadoop_hadoop-azure-datalake-3.3.2.jar with timestamp 1695530913524\n",
      "23/09/24 04:48:33 INFO SparkContext: Added JAR file:///root/.ivy2/jars/org.apache.hadoop_hadoop-cos-3.3.2.jar at spark://172.18.0.4:35985/jars/org.apache.hadoop_hadoop-cos-3.3.2.jar with timestamp 1695530913524\n",
      "23/09/24 04:48:33 INFO SparkContext: Added JAR file:///root/.ivy2/jars/com.aliyun.oss_aliyun-sdk-oss-3.13.0.jar at spark://172.18.0.4:35985/jars/com.aliyun.oss_aliyun-sdk-oss-3.13.0.jar with timestamp 1695530913524\n",
      "23/09/24 04:48:33 INFO SparkContext: Added JAR file:///root/.ivy2/jars/org.jdom_jdom2-2.0.6.jar at spark://172.18.0.4:35985/jars/org.jdom_jdom2-2.0.6.jar with timestamp 1695530913524\n",
      "23/09/24 04:48:33 INFO SparkContext: Added JAR file:///root/.ivy2/jars/org.codehaus.jettison_jettison-1.1.jar at spark://172.18.0.4:35985/jars/org.codehaus.jettison_jettison-1.1.jar with timestamp 1695530913524\n",
      "23/09/24 04:48:33 INFO SparkContext: Added JAR file:///root/.ivy2/jars/com.aliyun_aliyun-java-sdk-core-4.5.10.jar at spark://172.18.0.4:35985/jars/com.aliyun_aliyun-java-sdk-core-4.5.10.jar with timestamp 1695530913524\n",
      "23/09/24 04:48:33 INFO SparkContext: Added JAR file:///root/.ivy2/jars/com.aliyun_aliyun-java-sdk-ram-3.1.0.jar at spark://172.18.0.4:35985/jars/com.aliyun_aliyun-java-sdk-ram-3.1.0.jar with timestamp 1695530913524\n",
      "23/09/24 04:48:33 INFO SparkContext: Added JAR file:///root/.ivy2/jars/com.aliyun_aliyun-java-sdk-kms-2.11.0.jar at spark://172.18.0.4:35985/jars/com.aliyun_aliyun-java-sdk-kms-2.11.0.jar with timestamp 1695530913524\n",
      "23/09/24 04:48:33 INFO SparkContext: Added JAR file:///root/.ivy2/jars/stax_stax-api-1.0.1.jar at spark://172.18.0.4:35985/jars/stax_stax-api-1.0.1.jar with timestamp 1695530913524\n",
      "23/09/24 04:48:33 INFO SparkContext: Added JAR file:///root/.ivy2/jars/com.google.code.gson_gson-2.8.9.jar at spark://172.18.0.4:35985/jars/com.google.code.gson_gson-2.8.9.jar with timestamp 1695530913524\n",
      "23/09/24 04:48:33 INFO SparkContext: Added JAR file:///root/.ivy2/jars/javax.xml.bind_jaxb-api-2.2.11.jar at spark://172.18.0.4:35985/jars/javax.xml.bind_jaxb-api-2.2.11.jar with timestamp 1695530913524\n",
      "23/09/24 04:48:33 INFO SparkContext: Added JAR file:///root/.ivy2/jars/org.ini4j_ini4j-0.5.4.jar at spark://172.18.0.4:35985/jars/org.ini4j_ini4j-0.5.4.jar with timestamp 1695530913524\n",
      "23/09/24 04:48:33 INFO SparkContext: Added JAR file:///root/.ivy2/jars/io.opentracing_opentracing-api-0.33.0.jar at spark://172.18.0.4:35985/jars/io.opentracing_opentracing-api-0.33.0.jar with timestamp 1695530913524\n",
      "23/09/24 04:48:33 INFO SparkContext: Added JAR file:///root/.ivy2/jars/io.opentracing_opentracing-util-0.33.0.jar at spark://172.18.0.4:35985/jars/io.opentracing_opentracing-util-0.33.0.jar with timestamp 1695530913524\n",
      "23/09/24 04:48:33 INFO SparkContext: Added JAR file:///root/.ivy2/jars/io.opentracing_opentracing-noop-0.33.0.jar at spark://172.18.0.4:35985/jars/io.opentracing_opentracing-noop-0.33.0.jar with timestamp 1695530913524\n",
      "23/09/24 04:48:33 INFO SparkContext: Added JAR file:///root/.ivy2/jars/com.microsoft.azure_azure-data-lake-store-sdk-2.3.9.jar at spark://172.18.0.4:35985/jars/com.microsoft.azure_azure-data-lake-store-sdk-2.3.9.jar with timestamp 1695530913524\n",
      "23/09/24 04:48:33 INFO SparkContext: Added JAR file:///root/.ivy2/jars/com.qcloud_cos_api-bundle-5.6.19.jar at spark://172.18.0.4:35985/jars/com.qcloud_cos_api-bundle-5.6.19.jar with timestamp 1695530913524\n",
      "23/09/24 04:48:33 INFO SparkContext: Added JAR file:///root/.ivy2/jars/org.eclipse.jetty_jetty-util-9.4.46.v20220331.jar at spark://172.18.0.4:35985/jars/org.eclipse.jetty_jetty-util-9.4.46.v20220331.jar with timestamp 1695530913524\n",
      "23/09/24 04:48:33 INFO SparkContext: Added file file:///root/.ivy2/jars/org.apache.spark_spark-hadoop-cloud_2.12-3.3.0.jar at spark://172.18.0.4:35985/files/org.apache.spark_spark-hadoop-cloud_2.12-3.3.0.jar with timestamp 1695530913524\n",
      "23/09/24 04:48:33 INFO Utils: Copying /root/.ivy2/jars/org.apache.spark_spark-hadoop-cloud_2.12-3.3.0.jar to /tmp/spark-9fedc60b-ac5c-421e-9381-e8f5a2a217df/userFiles-47247bc4-19dc-4de5-8397-8c6f941c0548/org.apache.spark_spark-hadoop-cloud_2.12-3.3.0.jar\n",
      "23/09/24 04:48:33 INFO SparkContext: Added file file:///root/.ivy2/jars/org.apache.hadoop_hadoop-client-runtime-3.3.2.jar at spark://172.18.0.4:35985/files/org.apache.hadoop_hadoop-client-runtime-3.3.2.jar with timestamp 1695530913524\n",
      "23/09/24 04:48:33 INFO Utils: Copying /root/.ivy2/jars/org.apache.hadoop_hadoop-client-runtime-3.3.2.jar to /tmp/spark-9fedc60b-ac5c-421e-9381-e8f5a2a217df/userFiles-47247bc4-19dc-4de5-8397-8c6f941c0548/org.apache.hadoop_hadoop-client-runtime-3.3.2.jar\n",
      "23/09/24 04:48:33 INFO SparkContext: Added file file:///root/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.2.jar at spark://172.18.0.4:35985/files/org.apache.hadoop_hadoop-aws-3.3.2.jar with timestamp 1695530913524\n",
      "23/09/24 04:48:33 INFO Utils: Copying /root/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.2.jar to /tmp/spark-9fedc60b-ac5c-421e-9381-e8f5a2a217df/userFiles-47247bc4-19dc-4de5-8397-8c6f941c0548/org.apache.hadoop_hadoop-aws-3.3.2.jar\n",
      "23/09/24 04:48:33 INFO SparkContext: Added file file:///root/.ivy2/jars/org.apache.hadoop_hadoop-openstack-3.3.2.jar at spark://172.18.0.4:35985/files/org.apache.hadoop_hadoop-openstack-3.3.2.jar with timestamp 1695530913524\n",
      "23/09/24 04:48:33 INFO Utils: Copying /root/.ivy2/jars/org.apache.hadoop_hadoop-openstack-3.3.2.jar to /tmp/spark-9fedc60b-ac5c-421e-9381-e8f5a2a217df/userFiles-47247bc4-19dc-4de5-8397-8c6f941c0548/org.apache.hadoop_hadoop-openstack-3.3.2.jar\n",
      "23/09/24 04:48:33 INFO SparkContext: Added file file:///root/.ivy2/jars/joda-time_joda-time-2.10.13.jar at spark://172.18.0.4:35985/files/joda-time_joda-time-2.10.13.jar with timestamp 1695530913524\n",
      "23/09/24 04:48:33 INFO Utils: Copying /root/.ivy2/jars/joda-time_joda-time-2.10.13.jar to /tmp/spark-9fedc60b-ac5c-421e-9381-e8f5a2a217df/userFiles-47247bc4-19dc-4de5-8397-8c6f941c0548/joda-time_joda-time-2.10.13.jar\n",
      "23/09/24 04:48:33 INFO SparkContext: Added file file:///root/.ivy2/jars/com.fasterxml.jackson.core_jackson-databind-2.13.3.jar at spark://172.18.0.4:35985/files/com.fasterxml.jackson.core_jackson-databind-2.13.3.jar with timestamp 1695530913524\n",
      "23/09/24 04:48:33 INFO Utils: Copying /root/.ivy2/jars/com.fasterxml.jackson.core_jackson-databind-2.13.3.jar to /tmp/spark-9fedc60b-ac5c-421e-9381-e8f5a2a217df/userFiles-47247bc4-19dc-4de5-8397-8c6f941c0548/com.fasterxml.jackson.core_jackson-databind-2.13.3.jar\n",
      "23/09/24 04:48:33 INFO SparkContext: Added file file:///root/.ivy2/jars/com.fasterxml.jackson.core_jackson-annotations-2.13.3.jar at spark://172.18.0.4:35985/files/com.fasterxml.jackson.core_jackson-annotations-2.13.3.jar with timestamp 1695530913524\n",
      "23/09/24 04:48:33 INFO Utils: Copying /root/.ivy2/jars/com.fasterxml.jackson.core_jackson-annotations-2.13.3.jar to /tmp/spark-9fedc60b-ac5c-421e-9381-e8f5a2a217df/userFiles-47247bc4-19dc-4de5-8397-8c6f941c0548/com.fasterxml.jackson.core_jackson-annotations-2.13.3.jar\n",
      "23/09/24 04:48:33 INFO SparkContext: Added file file:///root/.ivy2/jars/com.fasterxml.jackson.dataformat_jackson-dataformat-cbor-2.13.3.jar at spark://172.18.0.4:35985/files/com.fasterxml.jackson.dataformat_jackson-dataformat-cbor-2.13.3.jar with timestamp 1695530913524\n",
      "23/09/24 04:48:33 INFO Utils: Copying /root/.ivy2/jars/com.fasterxml.jackson.dataformat_jackson-dataformat-cbor-2.13.3.jar to /tmp/spark-9fedc60b-ac5c-421e-9381-e8f5a2a217df/userFiles-47247bc4-19dc-4de5-8397-8c6f941c0548/com.fasterxml.jackson.dataformat_jackson-dataformat-cbor-2.13.3.jar\n",
      "23/09/24 04:48:33 INFO SparkContext: Added file file:///root/.ivy2/jars/org.apache.httpcomponents_httpclient-4.5.13.jar at spark://172.18.0.4:35985/files/org.apache.httpcomponents_httpclient-4.5.13.jar with timestamp 1695530913524\n",
      "23/09/24 04:48:33 INFO Utils: Copying /root/.ivy2/jars/org.apache.httpcomponents_httpclient-4.5.13.jar to /tmp/spark-9fedc60b-ac5c-421e-9381-e8f5a2a217df/userFiles-47247bc4-19dc-4de5-8397-8c6f941c0548/org.apache.httpcomponents_httpclient-4.5.13.jar\n",
      "23/09/24 04:48:33 INFO SparkContext: Added file file:///root/.ivy2/jars/org.apache.httpcomponents_httpcore-4.4.14.jar at spark://172.18.0.4:35985/files/org.apache.httpcomponents_httpcore-4.4.14.jar with timestamp 1695530913524\n",
      "23/09/24 04:48:33 INFO Utils: Copying /root/.ivy2/jars/org.apache.httpcomponents_httpcore-4.4.14.jar to /tmp/spark-9fedc60b-ac5c-421e-9381-e8f5a2a217df/userFiles-47247bc4-19dc-4de5-8397-8c6f941c0548/org.apache.httpcomponents_httpcore-4.4.14.jar\n",
      "23/09/24 04:48:33 INFO SparkContext: Added file file:///root/.ivy2/jars/org.apache.hadoop_hadoop-azure-3.3.2.jar at spark://172.18.0.4:35985/files/org.apache.hadoop_hadoop-azure-3.3.2.jar with timestamp 1695530913524\n",
      "23/09/24 04:48:33 INFO Utils: Copying /root/.ivy2/jars/org.apache.hadoop_hadoop-azure-3.3.2.jar to /tmp/spark-9fedc60b-ac5c-421e-9381-e8f5a2a217df/userFiles-47247bc4-19dc-4de5-8397-8c6f941c0548/org.apache.hadoop_hadoop-azure-3.3.2.jar\n",
      "23/09/24 04:48:33 INFO SparkContext: Added file file:///root/.ivy2/jars/org.apache.hadoop_hadoop-cloud-storage-3.3.2.jar at spark://172.18.0.4:35985/files/org.apache.hadoop_hadoop-cloud-storage-3.3.2.jar with timestamp 1695530913524\n",
      "23/09/24 04:48:33 INFO Utils: Copying /root/.ivy2/jars/org.apache.hadoop_hadoop-cloud-storage-3.3.2.jar to /tmp/spark-9fedc60b-ac5c-421e-9381-e8f5a2a217df/userFiles-47247bc4-19dc-4de5-8397-8c6f941c0548/org.apache.hadoop_hadoop-cloud-storage-3.3.2.jar\n",
      "23/09/24 04:48:33 INFO SparkContext: Added file file:///root/.ivy2/jars/org.eclipse.jetty_jetty-util-ajax-9.4.46.v20220331.jar at spark://172.18.0.4:35985/files/org.eclipse.jetty_jetty-util-ajax-9.4.46.v20220331.jar with timestamp 1695530913524\n",
      "23/09/24 04:48:33 INFO Utils: Copying /root/.ivy2/jars/org.eclipse.jetty_jetty-util-ajax-9.4.46.v20220331.jar to /tmp/spark-9fedc60b-ac5c-421e-9381-e8f5a2a217df/userFiles-47247bc4-19dc-4de5-8397-8c6f941c0548/org.eclipse.jetty_jetty-util-ajax-9.4.46.v20220331.jar\n",
      "23/09/24 04:48:33 INFO SparkContext: Added file file:///root/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar at spark://172.18.0.4:35985/files/org.spark-project.spark_unused-1.0.0.jar with timestamp 1695530913524\n",
      "23/09/24 04:48:33 INFO Utils: Copying /root/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar to /tmp/spark-9fedc60b-ac5c-421e-9381-e8f5a2a217df/userFiles-47247bc4-19dc-4de5-8397-8c6f941c0548/org.spark-project.spark_unused-1.0.0.jar\n",
      "23/09/24 04:48:33 INFO SparkContext: Added file file:///root/.ivy2/jars/org.apache.hadoop_hadoop-client-api-3.3.2.jar at spark://172.18.0.4:35985/files/org.apache.hadoop_hadoop-client-api-3.3.2.jar with timestamp 1695530913524\n",
      "23/09/24 04:48:33 INFO Utils: Copying /root/.ivy2/jars/org.apache.hadoop_hadoop-client-api-3.3.2.jar to /tmp/spark-9fedc60b-ac5c-421e-9381-e8f5a2a217df/userFiles-47247bc4-19dc-4de5-8397-8c6f941c0548/org.apache.hadoop_hadoop-client-api-3.3.2.jar\n",
      "23/09/24 04:48:33 INFO SparkContext: Added file file:///root/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.8.4.jar at spark://172.18.0.4:35985/files/org.xerial.snappy_snappy-java-1.1.8.4.jar with timestamp 1695530913524\n",
      "23/09/24 04:48:33 INFO Utils: Copying /root/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.8.4.jar to /tmp/spark-9fedc60b-ac5c-421e-9381-e8f5a2a217df/userFiles-47247bc4-19dc-4de5-8397-8c6f941c0548/org.xerial.snappy_snappy-java-1.1.8.4.jar\n",
      "23/09/24 04:48:33 INFO SparkContext: Added file file:///root/.ivy2/jars/org.slf4j_slf4j-api-1.7.32.jar at spark://172.18.0.4:35985/files/org.slf4j_slf4j-api-1.7.32.jar with timestamp 1695530913524\n",
      "23/09/24 04:48:33 INFO Utils: Copying /root/.ivy2/jars/org.slf4j_slf4j-api-1.7.32.jar to /tmp/spark-9fedc60b-ac5c-421e-9381-e8f5a2a217df/userFiles-47247bc4-19dc-4de5-8397-8c6f941c0548/org.slf4j_slf4j-api-1.7.32.jar\n",
      "23/09/24 04:48:33 INFO SparkContext: Added file file:///root/.ivy2/jars/commons-logging_commons-logging-1.1.3.jar at spark://172.18.0.4:35985/files/commons-logging_commons-logging-1.1.3.jar with timestamp 1695530913524\n",
      "23/09/24 04:48:33 INFO Utils: Copying /root/.ivy2/jars/commons-logging_commons-logging-1.1.3.jar to /tmp/spark-9fedc60b-ac5c-421e-9381-e8f5a2a217df/userFiles-47247bc4-19dc-4de5-8397-8c6f941c0548/commons-logging_commons-logging-1.1.3.jar\n",
      "23/09/24 04:48:33 INFO SparkContext: Added file file:///root/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.0.jar at spark://172.18.0.4:35985/files/com.google.code.findbugs_jsr305-3.0.0.jar with timestamp 1695530913524\n",
      "23/09/24 04:48:33 INFO Utils: Copying /root/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.0.jar to /tmp/spark-9fedc60b-ac5c-421e-9381-e8f5a2a217df/userFiles-47247bc4-19dc-4de5-8397-8c6f941c0548/com.google.code.findbugs_jsr305-3.0.0.jar\n",
      "23/09/24 04:48:33 INFO SparkContext: Added file file:///root/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.11.1026.jar at spark://172.18.0.4:35985/files/com.amazonaws_aws-java-sdk-bundle-1.11.1026.jar with timestamp 1695530913524\n",
      "23/09/24 04:48:33 INFO Utils: Copying /root/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.11.1026.jar to /tmp/spark-9fedc60b-ac5c-421e-9381-e8f5a2a217df/userFiles-47247bc4-19dc-4de5-8397-8c6f941c0548/com.amazonaws_aws-java-sdk-bundle-1.11.1026.jar\n",
      "23/09/24 04:48:34 INFO SparkContext: Added file file:///root/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar at spark://172.18.0.4:35985/files/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar with timestamp 1695530913524\n",
      "23/09/24 04:48:34 INFO Utils: Copying /root/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar to /tmp/spark-9fedc60b-ac5c-421e-9381-e8f5a2a217df/userFiles-47247bc4-19dc-4de5-8397-8c6f941c0548/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar\n",
      "23/09/24 04:48:34 INFO SparkContext: Added file file:///root/.ivy2/jars/org.apache.hadoop_hadoop-annotations-3.3.2.jar at spark://172.18.0.4:35985/files/org.apache.hadoop_hadoop-annotations-3.3.2.jar with timestamp 1695530913524\n",
      "23/09/24 04:48:34 INFO Utils: Copying /root/.ivy2/jars/org.apache.hadoop_hadoop-annotations-3.3.2.jar to /tmp/spark-9fedc60b-ac5c-421e-9381-e8f5a2a217df/userFiles-47247bc4-19dc-4de5-8397-8c6f941c0548/org.apache.hadoop_hadoop-annotations-3.3.2.jar\n",
      "23/09/24 04:48:34 INFO SparkContext: Added file file:///root/.ivy2/jars/com.fasterxml.jackson.core_jackson-core-2.13.3.jar at spark://172.18.0.4:35985/files/com.fasterxml.jackson.core_jackson-core-2.13.3.jar with timestamp 1695530913524\n",
      "23/09/24 04:48:34 INFO Utils: Copying /root/.ivy2/jars/com.fasterxml.jackson.core_jackson-core-2.13.3.jar to /tmp/spark-9fedc60b-ac5c-421e-9381-e8f5a2a217df/userFiles-47247bc4-19dc-4de5-8397-8c6f941c0548/com.fasterxml.jackson.core_jackson-core-2.13.3.jar\n",
      "23/09/24 04:48:34 INFO SparkContext: Added file file:///root/.ivy2/jars/commons-codec_commons-codec-1.15.jar at spark://172.18.0.4:35985/files/commons-codec_commons-codec-1.15.jar with timestamp 1695530913524\n",
      "23/09/24 04:48:34 INFO Utils: Copying /root/.ivy2/jars/commons-codec_commons-codec-1.15.jar to /tmp/spark-9fedc60b-ac5c-421e-9381-e8f5a2a217df/userFiles-47247bc4-19dc-4de5-8397-8c6f941c0548/commons-codec_commons-codec-1.15.jar\n",
      "23/09/24 04:48:34 INFO SparkContext: Added file file:///root/.ivy2/jars/com.microsoft.azure_azure-storage-7.0.1.jar at spark://172.18.0.4:35985/files/com.microsoft.azure_azure-storage-7.0.1.jar with timestamp 1695530913524\n",
      "23/09/24 04:48:34 INFO Utils: Copying /root/.ivy2/jars/com.microsoft.azure_azure-storage-7.0.1.jar to /tmp/spark-9fedc60b-ac5c-421e-9381-e8f5a2a217df/userFiles-47247bc4-19dc-4de5-8397-8c6f941c0548/com.microsoft.azure_azure-storage-7.0.1.jar\n",
      "23/09/24 04:48:34 INFO SparkContext: Added file file:///root/.ivy2/jars/org.apache.hadoop.thirdparty_hadoop-shaded-guava-1.1.1.jar at spark://172.18.0.4:35985/files/org.apache.hadoop.thirdparty_hadoop-shaded-guava-1.1.1.jar with timestamp 1695530913524\n",
      "23/09/24 04:48:34 INFO Utils: Copying /root/.ivy2/jars/org.apache.hadoop.thirdparty_hadoop-shaded-guava-1.1.1.jar to /tmp/spark-9fedc60b-ac5c-421e-9381-e8f5a2a217df/userFiles-47247bc4-19dc-4de5-8397-8c6f941c0548/org.apache.hadoop.thirdparty_hadoop-shaded-guava-1.1.1.jar\n",
      "23/09/24 04:48:34 INFO SparkContext: Added file file:///root/.ivy2/jars/org.codehaus.jackson_jackson-mapper-asl-1.9.13.jar at spark://172.18.0.4:35985/files/org.codehaus.jackson_jackson-mapper-asl-1.9.13.jar with timestamp 1695530913524\n",
      "23/09/24 04:48:34 INFO Utils: Copying /root/.ivy2/jars/org.codehaus.jackson_jackson-mapper-asl-1.9.13.jar to /tmp/spark-9fedc60b-ac5c-421e-9381-e8f5a2a217df/userFiles-47247bc4-19dc-4de5-8397-8c6f941c0548/org.codehaus.jackson_jackson-mapper-asl-1.9.13.jar\n",
      "23/09/24 04:48:34 INFO SparkContext: Added file file:///root/.ivy2/jars/org.codehaus.jackson_jackson-core-asl-1.9.13.jar at spark://172.18.0.4:35985/files/org.codehaus.jackson_jackson-core-asl-1.9.13.jar with timestamp 1695530913524\n",
      "23/09/24 04:48:34 INFO Utils: Copying /root/.ivy2/jars/org.codehaus.jackson_jackson-core-asl-1.9.13.jar to /tmp/spark-9fedc60b-ac5c-421e-9381-e8f5a2a217df/userFiles-47247bc4-19dc-4de5-8397-8c6f941c0548/org.codehaus.jackson_jackson-core-asl-1.9.13.jar\n",
      "23/09/24 04:48:34 INFO SparkContext: Added file file:///root/.ivy2/jars/com.microsoft.azure_azure-keyvault-core-1.0.0.jar at spark://172.18.0.4:35985/files/com.microsoft.azure_azure-keyvault-core-1.0.0.jar with timestamp 1695530913524\n",
      "23/09/24 04:48:34 INFO Utils: Copying /root/.ivy2/jars/com.microsoft.azure_azure-keyvault-core-1.0.0.jar to /tmp/spark-9fedc60b-ac5c-421e-9381-e8f5a2a217df/userFiles-47247bc4-19dc-4de5-8397-8c6f941c0548/com.microsoft.azure_azure-keyvault-core-1.0.0.jar\n",
      "23/09/24 04:48:34 INFO SparkContext: Added file file:///root/.ivy2/jars/org.apache.hadoop_hadoop-aliyun-3.3.2.jar at spark://172.18.0.4:35985/files/org.apache.hadoop_hadoop-aliyun-3.3.2.jar with timestamp 1695530913524\n",
      "23/09/24 04:48:34 INFO Utils: Copying /root/.ivy2/jars/org.apache.hadoop_hadoop-aliyun-3.3.2.jar to /tmp/spark-9fedc60b-ac5c-421e-9381-e8f5a2a217df/userFiles-47247bc4-19dc-4de5-8397-8c6f941c0548/org.apache.hadoop_hadoop-aliyun-3.3.2.jar\n",
      "23/09/24 04:48:34 INFO SparkContext: Added file file:///root/.ivy2/jars/org.apache.hadoop_hadoop-azure-datalake-3.3.2.jar at spark://172.18.0.4:35985/files/org.apache.hadoop_hadoop-azure-datalake-3.3.2.jar with timestamp 1695530913524\n",
      "23/09/24 04:48:34 INFO Utils: Copying /root/.ivy2/jars/org.apache.hadoop_hadoop-azure-datalake-3.3.2.jar to /tmp/spark-9fedc60b-ac5c-421e-9381-e8f5a2a217df/userFiles-47247bc4-19dc-4de5-8397-8c6f941c0548/org.apache.hadoop_hadoop-azure-datalake-3.3.2.jar\n",
      "23/09/24 04:48:34 INFO SparkContext: Added file file:///root/.ivy2/jars/org.apache.hadoop_hadoop-cos-3.3.2.jar at spark://172.18.0.4:35985/files/org.apache.hadoop_hadoop-cos-3.3.2.jar with timestamp 1695530913524\n",
      "23/09/24 04:48:34 INFO Utils: Copying /root/.ivy2/jars/org.apache.hadoop_hadoop-cos-3.3.2.jar to /tmp/spark-9fedc60b-ac5c-421e-9381-e8f5a2a217df/userFiles-47247bc4-19dc-4de5-8397-8c6f941c0548/org.apache.hadoop_hadoop-cos-3.3.2.jar\n",
      "23/09/24 04:48:34 INFO SparkContext: Added file file:///root/.ivy2/jars/com.aliyun.oss_aliyun-sdk-oss-3.13.0.jar at spark://172.18.0.4:35985/files/com.aliyun.oss_aliyun-sdk-oss-3.13.0.jar with timestamp 1695530913524\n",
      "23/09/24 04:48:34 INFO Utils: Copying /root/.ivy2/jars/com.aliyun.oss_aliyun-sdk-oss-3.13.0.jar to /tmp/spark-9fedc60b-ac5c-421e-9381-e8f5a2a217df/userFiles-47247bc4-19dc-4de5-8397-8c6f941c0548/com.aliyun.oss_aliyun-sdk-oss-3.13.0.jar\n",
      "23/09/24 04:48:34 INFO SparkContext: Added file file:///root/.ivy2/jars/org.jdom_jdom2-2.0.6.jar at spark://172.18.0.4:35985/files/org.jdom_jdom2-2.0.6.jar with timestamp 1695530913524\n",
      "23/09/24 04:48:34 INFO Utils: Copying /root/.ivy2/jars/org.jdom_jdom2-2.0.6.jar to /tmp/spark-9fedc60b-ac5c-421e-9381-e8f5a2a217df/userFiles-47247bc4-19dc-4de5-8397-8c6f941c0548/org.jdom_jdom2-2.0.6.jar\n",
      "23/09/24 04:48:34 INFO SparkContext: Added file file:///root/.ivy2/jars/org.codehaus.jettison_jettison-1.1.jar at spark://172.18.0.4:35985/files/org.codehaus.jettison_jettison-1.1.jar with timestamp 1695530913524\n",
      "23/09/24 04:48:34 INFO Utils: Copying /root/.ivy2/jars/org.codehaus.jettison_jettison-1.1.jar to /tmp/spark-9fedc60b-ac5c-421e-9381-e8f5a2a217df/userFiles-47247bc4-19dc-4de5-8397-8c6f941c0548/org.codehaus.jettison_jettison-1.1.jar\n",
      "23/09/24 04:48:34 INFO SparkContext: Added file file:///root/.ivy2/jars/com.aliyun_aliyun-java-sdk-core-4.5.10.jar at spark://172.18.0.4:35985/files/com.aliyun_aliyun-java-sdk-core-4.5.10.jar with timestamp 1695530913524\n",
      "23/09/24 04:48:34 INFO Utils: Copying /root/.ivy2/jars/com.aliyun_aliyun-java-sdk-core-4.5.10.jar to /tmp/spark-9fedc60b-ac5c-421e-9381-e8f5a2a217df/userFiles-47247bc4-19dc-4de5-8397-8c6f941c0548/com.aliyun_aliyun-java-sdk-core-4.5.10.jar\n",
      "23/09/24 04:48:34 INFO SparkContext: Added file file:///root/.ivy2/jars/com.aliyun_aliyun-java-sdk-ram-3.1.0.jar at spark://172.18.0.4:35985/files/com.aliyun_aliyun-java-sdk-ram-3.1.0.jar with timestamp 1695530913524\n",
      "23/09/24 04:48:34 INFO Utils: Copying /root/.ivy2/jars/com.aliyun_aliyun-java-sdk-ram-3.1.0.jar to /tmp/spark-9fedc60b-ac5c-421e-9381-e8f5a2a217df/userFiles-47247bc4-19dc-4de5-8397-8c6f941c0548/com.aliyun_aliyun-java-sdk-ram-3.1.0.jar\n",
      "23/09/24 04:48:34 INFO SparkContext: Added file file:///root/.ivy2/jars/com.aliyun_aliyun-java-sdk-kms-2.11.0.jar at spark://172.18.0.4:35985/files/com.aliyun_aliyun-java-sdk-kms-2.11.0.jar with timestamp 1695530913524\n",
      "23/09/24 04:48:34 INFO Utils: Copying /root/.ivy2/jars/com.aliyun_aliyun-java-sdk-kms-2.11.0.jar to /tmp/spark-9fedc60b-ac5c-421e-9381-e8f5a2a217df/userFiles-47247bc4-19dc-4de5-8397-8c6f941c0548/com.aliyun_aliyun-java-sdk-kms-2.11.0.jar\n",
      "23/09/24 04:48:34 INFO SparkContext: Added file file:///root/.ivy2/jars/stax_stax-api-1.0.1.jar at spark://172.18.0.4:35985/files/stax_stax-api-1.0.1.jar with timestamp 1695530913524\n",
      "23/09/24 04:48:34 INFO Utils: Copying /root/.ivy2/jars/stax_stax-api-1.0.1.jar to /tmp/spark-9fedc60b-ac5c-421e-9381-e8f5a2a217df/userFiles-47247bc4-19dc-4de5-8397-8c6f941c0548/stax_stax-api-1.0.1.jar\n",
      "23/09/24 04:48:34 INFO SparkContext: Added file file:///root/.ivy2/jars/com.google.code.gson_gson-2.8.9.jar at spark://172.18.0.4:35985/files/com.google.code.gson_gson-2.8.9.jar with timestamp 1695530913524\n",
      "23/09/24 04:48:34 INFO Utils: Copying /root/.ivy2/jars/com.google.code.gson_gson-2.8.9.jar to /tmp/spark-9fedc60b-ac5c-421e-9381-e8f5a2a217df/userFiles-47247bc4-19dc-4de5-8397-8c6f941c0548/com.google.code.gson_gson-2.8.9.jar\n",
      "23/09/24 04:48:34 INFO SparkContext: Added file file:///root/.ivy2/jars/javax.xml.bind_jaxb-api-2.2.11.jar at spark://172.18.0.4:35985/files/javax.xml.bind_jaxb-api-2.2.11.jar with timestamp 1695530913524\n",
      "23/09/24 04:48:34 INFO Utils: Copying /root/.ivy2/jars/javax.xml.bind_jaxb-api-2.2.11.jar to /tmp/spark-9fedc60b-ac5c-421e-9381-e8f5a2a217df/userFiles-47247bc4-19dc-4de5-8397-8c6f941c0548/javax.xml.bind_jaxb-api-2.2.11.jar\n",
      "23/09/24 04:48:34 INFO SparkContext: Added file file:///root/.ivy2/jars/org.ini4j_ini4j-0.5.4.jar at spark://172.18.0.4:35985/files/org.ini4j_ini4j-0.5.4.jar with timestamp 1695530913524\n",
      "23/09/24 04:48:34 INFO Utils: Copying /root/.ivy2/jars/org.ini4j_ini4j-0.5.4.jar to /tmp/spark-9fedc60b-ac5c-421e-9381-e8f5a2a217df/userFiles-47247bc4-19dc-4de5-8397-8c6f941c0548/org.ini4j_ini4j-0.5.4.jar\n",
      "23/09/24 04:48:34 INFO SparkContext: Added file file:///root/.ivy2/jars/io.opentracing_opentracing-api-0.33.0.jar at spark://172.18.0.4:35985/files/io.opentracing_opentracing-api-0.33.0.jar with timestamp 1695530913524\n",
      "23/09/24 04:48:34 INFO Utils: Copying /root/.ivy2/jars/io.opentracing_opentracing-api-0.33.0.jar to /tmp/spark-9fedc60b-ac5c-421e-9381-e8f5a2a217df/userFiles-47247bc4-19dc-4de5-8397-8c6f941c0548/io.opentracing_opentracing-api-0.33.0.jar\n",
      "23/09/24 04:48:34 INFO SparkContext: Added file file:///root/.ivy2/jars/io.opentracing_opentracing-util-0.33.0.jar at spark://172.18.0.4:35985/files/io.opentracing_opentracing-util-0.33.0.jar with timestamp 1695530913524\n",
      "23/09/24 04:48:34 INFO Utils: Copying /root/.ivy2/jars/io.opentracing_opentracing-util-0.33.0.jar to /tmp/spark-9fedc60b-ac5c-421e-9381-e8f5a2a217df/userFiles-47247bc4-19dc-4de5-8397-8c6f941c0548/io.opentracing_opentracing-util-0.33.0.jar\n",
      "23/09/24 04:48:34 INFO SparkContext: Added file file:///root/.ivy2/jars/io.opentracing_opentracing-noop-0.33.0.jar at spark://172.18.0.4:35985/files/io.opentracing_opentracing-noop-0.33.0.jar with timestamp 1695530913524\n",
      "23/09/24 04:48:34 INFO Utils: Copying /root/.ivy2/jars/io.opentracing_opentracing-noop-0.33.0.jar to /tmp/spark-9fedc60b-ac5c-421e-9381-e8f5a2a217df/userFiles-47247bc4-19dc-4de5-8397-8c6f941c0548/io.opentracing_opentracing-noop-0.33.0.jar\n",
      "23/09/24 04:48:34 INFO SparkContext: Added file file:///root/.ivy2/jars/com.microsoft.azure_azure-data-lake-store-sdk-2.3.9.jar at spark://172.18.0.4:35985/files/com.microsoft.azure_azure-data-lake-store-sdk-2.3.9.jar with timestamp 1695530913524\n",
      "23/09/24 04:48:34 INFO Utils: Copying /root/.ivy2/jars/com.microsoft.azure_azure-data-lake-store-sdk-2.3.9.jar to /tmp/spark-9fedc60b-ac5c-421e-9381-e8f5a2a217df/userFiles-47247bc4-19dc-4de5-8397-8c6f941c0548/com.microsoft.azure_azure-data-lake-store-sdk-2.3.9.jar\n",
      "23/09/24 04:48:34 INFO SparkContext: Added file file:///root/.ivy2/jars/com.qcloud_cos_api-bundle-5.6.19.jar at spark://172.18.0.4:35985/files/com.qcloud_cos_api-bundle-5.6.19.jar with timestamp 1695530913524\n",
      "23/09/24 04:48:34 INFO Utils: Copying /root/.ivy2/jars/com.qcloud_cos_api-bundle-5.6.19.jar to /tmp/spark-9fedc60b-ac5c-421e-9381-e8f5a2a217df/userFiles-47247bc4-19dc-4de5-8397-8c6f941c0548/com.qcloud_cos_api-bundle-5.6.19.jar\n",
      "23/09/24 04:48:34 INFO SparkContext: Added file file:///root/.ivy2/jars/org.eclipse.jetty_jetty-util-9.4.46.v20220331.jar at spark://172.18.0.4:35985/files/org.eclipse.jetty_jetty-util-9.4.46.v20220331.jar with timestamp 1695530913524\n",
      "23/09/24 04:48:34 INFO Utils: Copying /root/.ivy2/jars/org.eclipse.jetty_jetty-util-9.4.46.v20220331.jar to /tmp/spark-9fedc60b-ac5c-421e-9381-e8f5a2a217df/userFiles-47247bc4-19dc-4de5-8397-8c6f941c0548/org.eclipse.jetty_jetty-util-9.4.46.v20220331.jar\n",
      "23/09/24 04:48:34 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark:7077...\n",
      "23/09/24 04:48:34 DEBUG TransportClientFactory: Creating new connection to spark/172.18.0.8:7077\n",
      "23/09/24 04:48:34 DEBUG TransportClientFactory: Connection to spark/172.18.0.8:7077 successful, running bootstraps...\n",
      "23/09/24 04:48:34 INFO TransportClientFactory: Successfully created connection to spark/172.18.0.8:7077 after 2 ms (0 ms spent in bootstraps)\n",
      "23/09/24 04:48:34 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20230924044834-0001\n",
      "23/09/24 04:48:34 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20230924044834-0001/0 on worker-20230924044154-172.18.0.5-38549 (172.18.0.5:38549) with 1 core(s)\n",
      "23/09/24 04:48:34 INFO StandaloneSchedulerBackend: Granted executor ID app-20230924044834-0001/0 on hostPort 172.18.0.5:38549 with 1 core(s), 1024.0 MiB RAM\n",
      "23/09/24 04:48:34 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20230924044834-0001/1 on worker-20230924044155-172.18.0.6-44289 (172.18.0.6:44289) with 1 core(s)\n",
      "23/09/24 04:48:34 INFO StandaloneSchedulerBackend: Granted executor ID app-20230924044834-0001/1 on hostPort 172.18.0.6:44289 with 1 core(s), 1024.0 MiB RAM\n",
      "23/09/24 04:48:34 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20230924044834-0001/2 on worker-20230924044155-172.18.0.7-36541 (172.18.0.7:36541) with 1 core(s)\n",
      "23/09/24 04:48:34 INFO StandaloneSchedulerBackend: Granted executor ID app-20230924044834-0001/2 on hostPort 172.18.0.7:36541 with 1 core(s), 1024.0 MiB RAM\n",
      "23/09/24 04:48:34 DEBUG TransportServer: Shuffle server started on port: 33447\n",
      "23/09/24 04:48:34 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 33447.\n",
      "23/09/24 04:48:34 INFO NettyBlockTransferService: Server created on 172.18.0.4:33447\n",
      "23/09/24 04:48:34 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy\n",
      "23/09/24 04:48:34 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 172.18.0.4, 33447, None)\n",
      "23/09/24 04:48:34 DEBUG DefaultTopologyMapper: Got a request for 172.18.0.4\n",
      "23/09/24 04:48:34 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.4:33447 with 366.3 MiB RAM, BlockManagerId(driver, 172.18.0.4, 33447, None)\n",
      "23/09/24 04:48:34 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 172.18.0.4, 33447, None)\n",
      "23/09/24 04:48:34 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 172.18.0.4, 33447, None)\n",
      "23/09/24 04:48:34 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20230924044834-0001/1 is now RUNNING\n",
      "23/09/24 04:48:34 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20230924044834-0001/0 is now RUNNING\n",
      "23/09/24 04:48:34 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20230924044834-0001/2 is now RUNNING\n",
      "23/09/24 04:48:34 DEBUG SparkContext: Adding shutdown hook\n",
      "23/09/24 04:48:34 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0\n",
      "23/09/24 04:48:34 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.\n",
      "23/09/24 04:48:34 DEBUG SharedState: Applying other initial session options to HadoopConf: spark.driver.host -> 172.18.0.4\n",
      "23/09/24 04:48:34 DEBUG SharedState: Applying other initial session options to HadoopConf: spark.eventLog.enabled -> false\n",
      "23/09/24 04:48:34 DEBUG SharedState: Applying other initial session options to HadoopConf: spark.jars -> file:///root/.ivy2/jars/org.apache.spark_spark-hadoop-cloud_2.12-3.3.0.jar,file:///root/.ivy2/jars/org.apache.hadoop_hadoop-client-runtime-3.3.2.jar,file:///root/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.2.jar,file:///root/.ivy2/jars/org.apache.hadoop_hadoop-openstack-3.3.2.jar,file:///root/.ivy2/jars/joda-time_joda-time-2.10.13.jar,file:///root/.ivy2/jars/com.fasterxml.jackson.core_jackson-databind-2.13.3.jar,file:///root/.ivy2/jars/com.fasterxml.jackson.core_jackson-annotations-2.13.3.jar,file:///root/.ivy2/jars/com.fasterxml.jackson.dataformat_jackson-dataformat-cbor-2.13.3.jar,file:///root/.ivy2/jars/org.apache.httpcomponents_httpclient-4.5.13.jar,file:///root/.ivy2/jars/org.apache.httpcomponents_httpcore-4.4.14.jar,file:///root/.ivy2/jars/org.apache.hadoop_hadoop-azure-3.3.2.jar,file:///root/.ivy2/jars/org.apache.hadoop_hadoop-cloud-storage-3.3.2.jar,file:///root/.ivy2/jars/org.eclipse.jetty_jetty-util-ajax-9.4.46.v20220331.jar,file:///root/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar,file:///root/.ivy2/jars/org.apache.hadoop_hadoop-client-api-3.3.2.jar,file:///root/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.8.4.jar,file:///root/.ivy2/jars/org.slf4j_slf4j-api-1.7.32.jar,file:///root/.ivy2/jars/commons-logging_commons-logging-1.1.3.jar,file:///root/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.0.jar,file:///root/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.11.1026.jar,file:///root/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar,file:///root/.ivy2/jars/org.apache.hadoop_hadoop-annotations-3.3.2.jar,file:///root/.ivy2/jars/com.fasterxml.jackson.core_jackson-core-2.13.3.jar,file:///root/.ivy2/jars/commons-codec_commons-codec-1.15.jar,file:///root/.ivy2/jars/com.microsoft.azure_azure-storage-7.0.1.jar,file:///root/.ivy2/jars/org.apache.hadoop.thirdparty_hadoop-shaded-guava-1.1.1.jar,file:///root/.ivy2/jars/org.codehaus.jackson_jackson-mapper-asl-1.9.13.jar,file:///root/.ivy2/jars/org.codehaus.jackson_jackson-core-asl-1.9.13.jar,file:///root/.ivy2/jars/com.microsoft.azure_azure-keyvault-core-1.0.0.jar,file:///root/.ivy2/jars/org.apache.hadoop_hadoop-aliyun-3.3.2.jar,file:///root/.ivy2/jars/org.apache.hadoop_hadoop-azure-datalake-3.3.2.jar,file:///root/.ivy2/jars/org.apache.hadoop_hadoop-cos-3.3.2.jar,file:///root/.ivy2/jars/com.aliyun.oss_aliyun-sdk-oss-3.13.0.jar,file:///root/.ivy2/jars/org.jdom_jdom2-2.0.6.jar,file:///root/.ivy2/jars/org.codehaus.jettison_jettison-1.1.jar,file:///root/.ivy2/jars/com.aliyun_aliyun-java-sdk-core-4.5.10.jar,file:///root/.ivy2/jars/com.aliyun_aliyun-java-sdk-ram-3.1.0.jar,file:///root/.ivy2/jars/com.aliyun_aliyun-java-sdk-kms-2.11.0.jar,file:///root/.ivy2/jars/stax_stax-api-1.0.1.jar,file:///root/.ivy2/jars/com.google.code.gson_gson-2.8.9.jar,file:///root/.ivy2/jars/javax.xml.bind_jaxb-api-2.2.11.jar,file:///root/.ivy2/jars/org.ini4j_ini4j-0.5.4.jar,file:///root/.ivy2/jars/io.opentracing_opentracing-api-0.33.0.jar,file:///root/.ivy2/jars/io.opentracing_opentracing-util-0.33.0.jar,file:///root/.ivy2/jars/io.opentracing_opentracing-noop-0.33.0.jar,file:///root/.ivy2/jars/com.microsoft.azure_azure-data-lake-store-sdk-2.3.9.jar,file:///root/.ivy2/jars/com.qcloud_cos_api-bundle-5.6.19.jar,file:///root/.ivy2/jars/org.eclipse.jetty_jetty-util-9.4.46.v20220331.jar\n",
      "23/09/24 04:48:34 DEBUG SharedState: Applying other initial session options to HadoopConf: spark.hadoop.fs.s3a.path.style.access -> True\n",
      "23/09/24 04:48:34 DEBUG SharedState: Applying other initial session options to HadoopConf: spark.app.name -> openS3file\n",
      "23/09/24 04:48:34 DEBUG SharedState: Applying other initial session options to HadoopConf: spark.hadoop.fs.s3a.secret.key -> minio-root-password\n",
      "23/09/24 04:48:34 DEBUG SharedState: Applying other initial session options to HadoopConf: spark.logConf -> false\n",
      "23/09/24 04:48:34 DEBUG SharedState: Applying other initial session options to HadoopConf: spark.hadoop.fs.s3a.access.key -> minio-root-user\n",
      "23/09/24 04:48:34 DEBUG SharedState: Applying other initial session options to HadoopConf: spark.submit.pyFiles -> /root/.ivy2/jars/org.apache.spark_spark-hadoop-cloud_2.12-3.3.0.jar,/root/.ivy2/jars/org.apache.hadoop_hadoop-client-runtime-3.3.2.jar,/root/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.2.jar,/root/.ivy2/jars/org.apache.hadoop_hadoop-openstack-3.3.2.jar,/root/.ivy2/jars/joda-time_joda-time-2.10.13.jar,/root/.ivy2/jars/com.fasterxml.jackson.core_jackson-databind-2.13.3.jar,/root/.ivy2/jars/com.fasterxml.jackson.core_jackson-annotations-2.13.3.jar,/root/.ivy2/jars/com.fasterxml.jackson.dataformat_jackson-dataformat-cbor-2.13.3.jar,/root/.ivy2/jars/org.apache.httpcomponents_httpclient-4.5.13.jar,/root/.ivy2/jars/org.apache.httpcomponents_httpcore-4.4.14.jar,/root/.ivy2/jars/org.apache.hadoop_hadoop-azure-3.3.2.jar,/root/.ivy2/jars/org.apache.hadoop_hadoop-cloud-storage-3.3.2.jar,/root/.ivy2/jars/org.eclipse.jetty_jetty-util-ajax-9.4.46.v20220331.jar,/root/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar,/root/.ivy2/jars/org.apache.hadoop_hadoop-client-api-3.3.2.jar,/root/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.8.4.jar,/root/.ivy2/jars/org.slf4j_slf4j-api-1.7.32.jar,/root/.ivy2/jars/commons-logging_commons-logging-1.1.3.jar,/root/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.0.jar,/root/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.11.1026.jar,/root/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar,/root/.ivy2/jars/org.apache.hadoop_hadoop-annotations-3.3.2.jar,/root/.ivy2/jars/com.fasterxml.jackson.core_jackson-core-2.13.3.jar,/root/.ivy2/jars/commons-codec_commons-codec-1.15.jar,/root/.ivy2/jars/com.microsoft.azure_azure-storage-7.0.1.jar,/root/.ivy2/jars/org.apache.hadoop.thirdparty_hadoop-shaded-guava-1.1.1.jar,/root/.ivy2/jars/org.codehaus.jackson_jackson-mapper-asl-1.9.13.jar,/root/.ivy2/jars/org.codehaus.jackson_jackson-core-asl-1.9.13.jar,/root/.ivy2/jars/com.microsoft.azure_azure-keyvault-core-1.0.0.jar,/root/.ivy2/jars/org.apache.hadoop_hadoop-aliyun-3.3.2.jar,/root/.ivy2/jars/org.apache.hadoop_hadoop-azure-datalake-3.3.2.jar,/root/.ivy2/jars/org.apache.hadoop_hadoop-cos-3.3.2.jar,/root/.ivy2/jars/com.aliyun.oss_aliyun-sdk-oss-3.13.0.jar,/root/.ivy2/jars/org.jdom_jdom2-2.0.6.jar,/root/.ivy2/jars/org.codehaus.jettison_jettison-1.1.jar,/root/.ivy2/jars/com.aliyun_aliyun-java-sdk-core-4.5.10.jar,/root/.ivy2/jars/com.aliyun_aliyun-java-sdk-ram-3.1.0.jar,/root/.ivy2/jars/com.aliyun_aliyun-java-sdk-kms-2.11.0.jar,/root/.ivy2/jars/stax_stax-api-1.0.1.jar,/root/.ivy2/jars/com.google.code.gson_gson-2.8.9.jar,/root/.ivy2/jars/javax.xml.bind_jaxb-api-2.2.11.jar,/root/.ivy2/jars/org.ini4j_ini4j-0.5.4.jar,/root/.ivy2/jars/io.opentracing_opentracing-api-0.33.0.jar,/root/.ivy2/jars/io.opentracing_opentracing-util-0.33.0.jar,/root/.ivy2/jars/io.opentracing_opentracing-noop-0.33.0.jar,/root/.ivy2/jars/com.microsoft.azure_azure-data-lake-store-sdk-2.3.9.jar,/root/.ivy2/jars/com.qcloud_cos_api-bundle-5.6.19.jar,/root/.ivy2/jars/org.eclipse.jetty_jetty-util-9.4.46.v20220331.jar\n",
      "23/09/24 04:48:34 DEBUG SharedState: Applying other initial session options to HadoopConf: spark.ui.showConsoleProgress -> true\n",
      "23/09/24 04:48:34 DEBUG SharedState: Applying other initial session options to HadoopConf: spark.app.submitTime -> 1695530681571\n",
      "23/09/24 04:48:34 DEBUG SharedState: Applying other initial session options to HadoopConf: spark.jars.packages -> org.apache.hadoop:hadoop-aws:3.2.0,com.amazonaws:aws-java-sdk-bundle:1.11.704,org.apache.spark:spark-hadoop-cloud_2.12:3.3.0\n",
      "23/09/24 04:48:34 DEBUG SharedState: Applying other initial session options to HadoopConf: spark.driver.bindAddress -> 0.0.0.0\n",
      "23/09/24 04:48:34 DEBUG SharedState: Applying other initial session options to HadoopConf: spark.hadoop.fs.s3a.bucket.all.committer.magic.enabled -> True\n",
      "23/09/24 04:48:34 DEBUG SharedState: Applying other initial session options to HadoopConf: spark.files -> file:///root/.ivy2/jars/org.apache.spark_spark-hadoop-cloud_2.12-3.3.0.jar,file:///root/.ivy2/jars/org.apache.hadoop_hadoop-client-runtime-3.3.2.jar,file:///root/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.2.jar,file:///root/.ivy2/jars/org.apache.hadoop_hadoop-openstack-3.3.2.jar,file:///root/.ivy2/jars/joda-time_joda-time-2.10.13.jar,file:///root/.ivy2/jars/com.fasterxml.jackson.core_jackson-databind-2.13.3.jar,file:///root/.ivy2/jars/com.fasterxml.jackson.core_jackson-annotations-2.13.3.jar,file:///root/.ivy2/jars/com.fasterxml.jackson.dataformat_jackson-dataformat-cbor-2.13.3.jar,file:///root/.ivy2/jars/org.apache.httpcomponents_httpclient-4.5.13.jar,file:///root/.ivy2/jars/org.apache.httpcomponents_httpcore-4.4.14.jar,file:///root/.ivy2/jars/org.apache.hadoop_hadoop-azure-3.3.2.jar,file:///root/.ivy2/jars/org.apache.hadoop_hadoop-cloud-storage-3.3.2.jar,file:///root/.ivy2/jars/org.eclipse.jetty_jetty-util-ajax-9.4.46.v20220331.jar,file:///root/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar,file:///root/.ivy2/jars/org.apache.hadoop_hadoop-client-api-3.3.2.jar,file:///root/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.8.4.jar,file:///root/.ivy2/jars/org.slf4j_slf4j-api-1.7.32.jar,file:///root/.ivy2/jars/commons-logging_commons-logging-1.1.3.jar,file:///root/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.0.jar,file:///root/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.11.1026.jar,file:///root/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar,file:///root/.ivy2/jars/org.apache.hadoop_hadoop-annotations-3.3.2.jar,file:///root/.ivy2/jars/com.fasterxml.jackson.core_jackson-core-2.13.3.jar,file:///root/.ivy2/jars/commons-codec_commons-codec-1.15.jar,file:///root/.ivy2/jars/com.microsoft.azure_azure-storage-7.0.1.jar,file:///root/.ivy2/jars/org.apache.hadoop.thirdparty_hadoop-shaded-guava-1.1.1.jar,file:///root/.ivy2/jars/org.codehaus.jackson_jackson-mapper-asl-1.9.13.jar,file:///root/.ivy2/jars/org.codehaus.jackson_jackson-core-asl-1.9.13.jar,file:///root/.ivy2/jars/com.microsoft.azure_azure-keyvault-core-1.0.0.jar,file:///root/.ivy2/jars/org.apache.hadoop_hadoop-aliyun-3.3.2.jar,file:///root/.ivy2/jars/org.apache.hadoop_hadoop-azure-datalake-3.3.2.jar,file:///root/.ivy2/jars/org.apache.hadoop_hadoop-cos-3.3.2.jar,file:///root/.ivy2/jars/com.aliyun.oss_aliyun-sdk-oss-3.13.0.jar,file:///root/.ivy2/jars/org.jdom_jdom2-2.0.6.jar,file:///root/.ivy2/jars/org.codehaus.jettison_jettison-1.1.jar,file:///root/.ivy2/jars/com.aliyun_aliyun-java-sdk-core-4.5.10.jar,file:///root/.ivy2/jars/com.aliyun_aliyun-java-sdk-ram-3.1.0.jar,file:///root/.ivy2/jars/com.aliyun_aliyun-java-sdk-kms-2.11.0.jar,file:///root/.ivy2/jars/stax_stax-api-1.0.1.jar,file:///root/.ivy2/jars/com.google.code.gson_gson-2.8.9.jar,file:///root/.ivy2/jars/javax.xml.bind_jaxb-api-2.2.11.jar,file:///root/.ivy2/jars/org.ini4j_ini4j-0.5.4.jar,file:///root/.ivy2/jars/io.opentracing_opentracing-api-0.33.0.jar,file:///root/.ivy2/jars/io.opentracing_opentracing-util-0.33.0.jar,file:///root/.ivy2/jars/io.opentracing_opentracing-noop-0.33.0.jar,file:///root/.ivy2/jars/com.microsoft.azure_azure-data-lake-store-sdk-2.3.9.jar,file:///root/.ivy2/jars/com.qcloud_cos_api-bundle-5.6.19.jar,file:///root/.ivy2/jars/org.eclipse.jetty_jetty-util-9.4.46.v20220331.jar\n",
      "23/09/24 04:48:34 DEBUG SharedState: Applying other initial session options to HadoopConf: spark.submit.deployMode -> client\n",
      "23/09/24 04:48:34 DEBUG SharedState: Applying other initial session options to HadoopConf: spark.master -> spark://spark:7077\n",
      "23/09/24 04:48:34 DEBUG SharedState: Applying other initial session options to HadoopConf: spark.hadoop.fs.s3a.endpoint -> http://minio:9000\n",
      "23/09/24 04:48:34 DEBUG SharedState: Applying other initial session options to HadoopConf: spark.repl.local.jars -> file:///root/.ivy2/jars/org.apache.spark_spark-hadoop-cloud_2.12-3.3.0.jar,file:///root/.ivy2/jars/org.apache.hadoop_hadoop-client-runtime-3.3.2.jar,file:///root/.ivy2/jars/org.apache.hadoop_hadoop-aws-3.3.2.jar,file:///root/.ivy2/jars/org.apache.hadoop_hadoop-openstack-3.3.2.jar,file:///root/.ivy2/jars/joda-time_joda-time-2.10.13.jar,file:///root/.ivy2/jars/com.fasterxml.jackson.core_jackson-databind-2.13.3.jar,file:///root/.ivy2/jars/com.fasterxml.jackson.core_jackson-annotations-2.13.3.jar,file:///root/.ivy2/jars/com.fasterxml.jackson.dataformat_jackson-dataformat-cbor-2.13.3.jar,file:///root/.ivy2/jars/org.apache.httpcomponents_httpclient-4.5.13.jar,file:///root/.ivy2/jars/org.apache.httpcomponents_httpcore-4.4.14.jar,file:///root/.ivy2/jars/org.apache.hadoop_hadoop-azure-3.3.2.jar,file:///root/.ivy2/jars/org.apache.hadoop_hadoop-cloud-storage-3.3.2.jar,file:///root/.ivy2/jars/org.eclipse.jetty_jetty-util-ajax-9.4.46.v20220331.jar,file:///root/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar,file:///root/.ivy2/jars/org.apache.hadoop_hadoop-client-api-3.3.2.jar,file:///root/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.8.4.jar,file:///root/.ivy2/jars/org.slf4j_slf4j-api-1.7.32.jar,file:///root/.ivy2/jars/commons-logging_commons-logging-1.1.3.jar,file:///root/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.0.jar,file:///root/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.11.1026.jar,file:///root/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar,file:///root/.ivy2/jars/org.apache.hadoop_hadoop-annotations-3.3.2.jar,file:///root/.ivy2/jars/com.fasterxml.jackson.core_jackson-core-2.13.3.jar,file:///root/.ivy2/jars/commons-codec_commons-codec-1.15.jar,file:///root/.ivy2/jars/com.microsoft.azure_azure-storage-7.0.1.jar,file:///root/.ivy2/jars/org.apache.hadoop.thirdparty_hadoop-shaded-guava-1.1.1.jar,file:///root/.ivy2/jars/org.codehaus.jackson_jackson-mapper-asl-1.9.13.jar,file:///root/.ivy2/jars/org.codehaus.jackson_jackson-core-asl-1.9.13.jar,file:///root/.ivy2/jars/com.microsoft.azure_azure-keyvault-core-1.0.0.jar,file:///root/.ivy2/jars/org.apache.hadoop_hadoop-aliyun-3.3.2.jar,file:///root/.ivy2/jars/org.apache.hadoop_hadoop-azure-datalake-3.3.2.jar,file:///root/.ivy2/jars/org.apache.hadoop_hadoop-cos-3.3.2.jar,file:///root/.ivy2/jars/com.aliyun.oss_aliyun-sdk-oss-3.13.0.jar,file:///root/.ivy2/jars/org.jdom_jdom2-2.0.6.jar,file:///root/.ivy2/jars/org.codehaus.jettison_jettison-1.1.jar,file:///root/.ivy2/jars/com.aliyun_aliyun-java-sdk-core-4.5.10.jar,file:///root/.ivy2/jars/com.aliyun_aliyun-java-sdk-ram-3.1.0.jar,file:///root/.ivy2/jars/com.aliyun_aliyun-java-sdk-kms-2.11.0.jar,file:///root/.ivy2/jars/stax_stax-api-1.0.1.jar,file:///root/.ivy2/jars/com.google.code.gson_gson-2.8.9.jar,file:///root/.ivy2/jars/javax.xml.bind_jaxb-api-2.2.11.jar,file:///root/.ivy2/jars/org.ini4j_ini4j-0.5.4.jar,file:///root/.ivy2/jars/io.opentracing_opentracing-api-0.33.0.jar,file:///root/.ivy2/jars/io.opentracing_opentracing-util-0.33.0.jar,file:///root/.ivy2/jars/io.opentracing_opentracing-noop-0.33.0.jar,file:///root/.ivy2/jars/com.microsoft.azure_azure-data-lake-store-sdk-2.3.9.jar,file:///root/.ivy2/jars/com.qcloud_cos_api-bundle-5.6.19.jar,file:///root/.ivy2/jars/org.eclipse.jetty_jetty-util-9.4.46.v20220331.jar\n",
      "23/09/24 04:48:34 DEBUG SharedState: Applying other initial session options to HadoopConf: spark.hadoop.fs.s3a.impl -> org.apache.hadoop.fs.s3a.S3AFileSystem\n",
      "23/09/24 04:48:34 DEBUG SharedState: Applying other initial session options to HadoopConf: spark.hadoop.fs.s3a.fast.upload -> True\n",
      "23/09/24 04:48:34 INFO SharedState: Warehouse path is 'file:/opt/bitnami/spark/work/demos/01_ReadWriteS3/spark-warehouse'.\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "from pyspark.conf import SparkConf\n",
    "from pyspark.sql import SparkSession, Catalog\n",
    "from pyspark.sql import DataFrame, DataFrameStatFunctions, DataFrameNaFunctions\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import types as T\n",
    "from pyspark.sql.types import Row\n",
    "from subprocess import check_output\n",
    "\n",
    "SPARK_DRIVER_HOST = check_output([\"hostname\", \"-i\"]).decode(encoding=\"utf-8\").strip()\n",
    "spark_conf = SparkConf()\n",
    "spark_conf.setAll([\n",
    "    ('spark.master', 'spark://spark:7077'),\n",
    "    ('spark.app.name', 'openS3file'),\n",
    "    ('spark.submit.deployMode', 'client'),\n",
    "    ('spark.ui.showConsoleProgress', 'true'),\n",
    "    ('spark.eventLog.enabled', 'false'),\n",
    "    ('spark.logConf', 'false'),\n",
    "    ('spark.driver.bindAddress', '0.0.0.0'),\n",
    "    ('spark.driver.host', SPARK_DRIVER_HOST),\n",
    "    ('spark.jars.packages', 'org.apache.hadoop:hadoop-aws:3.2.0,com.amazonaws:aws-java-sdk-bundle:1.11.704,org.apache.spark:spark-hadoop-cloud_2.12:3.3.0'),\n",
    "    (\"spark.hadoop.fs.s3a.endpoint\", 'http://minio:9000'),\n",
    "    ('spark.hadoop.fs.s3a.access.key', 'minio-root-user'),\n",
    "    ('spark.hadoop.fs.s3a.secret.key', 'minio-root-password'),\n",
    "    ('spark.hadoop.fs.s3a.bucket.all.committer.magic.enabled', True),\n",
    "    (\"spark.hadoop.fs.s3a.fast.upload\", True),\n",
    "    (\"spark.hadoop.fs.s3a.path.style.access\", True),\n",
    "    (\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\")\n",
    "])\n",
    " \n",
    "spark_sess          = SparkSession.builder.config(conf=spark_conf).getOrCreate()\n",
    "spark_ctxt          = spark_sess.sparkContext\n",
    "spark_reader        = spark_sess.read\n",
    "spark_streamReader  = spark_sess.readStream\n",
    "spark_ctxt.setLogLevel(\"WARN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "751619ed-955f-4027-865a-308e12592e78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+-------+-----+-------+-------+-------+-----+------------------+--------+\n",
      "|LatD | \"LatM\"| \"LatS\"| \"NS\"| \"LonD\"| \"LonM\"| \"LonS\"| \"EW\"| \"City\"           | \"State\"|\n",
      "+-----+-------+-------+-----+-------+-------+-------+-----+------------------+--------+\n",
      "|   41|    5  |   59  | \"N\" |     80|   39  |    0  | \"W\" | \"Youngstown\"     | OH     |\n",
      "|   42|   52  |   48  | \"N\" |     97|   23  |   23  | \"W\" | \"Yankton\"        | SD     |\n",
      "|   46|   35  |   59  | \"N\" |    120|   30  |   36  | \"W\" | \"Yakima\"         | WA     |\n",
      "|   42|   16  |   12  | \"N\" |     71|   48  |    0  | \"W\" | \"Worcester\"      | MA     |\n",
      "|   43|   37  |   48  | \"N\" |     89|   46  |   11  | \"W\" | \"Wisconsin Dells\"| WI     |\n",
      "|   36|    5  |   59  | \"N\" |     80|   15  |    0  | \"W\" | \"Winston-Salem\"  | NC     |\n",
      "|   49|   52  |   48  | \"N\" |     97|    9  |    0  | \"W\" | \"Winnipeg\"       | MB     |\n",
      "|   39|   11  |   23  | \"N\" |     78|    9  |   36  | \"W\" | \"Winchester\"     | VA     |\n",
      "|   34|   14  |   24  | \"N\" |     77|   55  |   11  | \"W\" | \"Wilmington\"     | NC     |\n",
      "|   39|   45  |    0  | \"N\" |     75|   33  |    0  | \"W\" | \"Wilmington\"     | DE     |\n",
      "|   48|    9  |    0  | \"N\" |    103|   37  |   12  | \"W\" | \"Williston\"      | ND     |\n",
      "|   41|   15  |    0  | \"N\" |     77|    0  |    0  | \"W\" | \"Williamsport\"   | PA     |\n",
      "|   37|   40  |   48  | \"N\" |     82|   16  |   47  | \"W\" | \"Williamson\"     | WV     |\n",
      "|   33|   54  |    0  | \"N\" |     98|   29  |   23  | \"W\" | \"Wichita Falls\"  | TX     |\n",
      "|   37|   41  |   23  | \"N\" |     97|   20  |   23  | \"W\" | \"Wichita\"        | KS     |\n",
      "|   40|    4  |   11  | \"N\" |     80|   43  |   12  | \"W\" | \"Wheeling\"       | WV     |\n",
      "|   26|   43  |   11  | \"N\" |     80|    3  |    0  | \"W\" | \"West Palm Beach\"| FL     |\n",
      "|   47|   25  |   11  | \"N\" |    120|   19  |   11  | \"W\" | \"Wenatchee\"      | WA     |\n",
      "|   41|   25  |   11  | \"N\" |    122|   23  |   23  | \"W\" | \"Weed\"           | CA     |\n",
      "|   31|   13  |   11  | \"N\" |     82|   20  |   59  | \"W\" | \"Waycross\"       | GA     |\n",
      "+-----+-------+-------+-----+-------+-------+-------+-----+------------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "citiesDF = spark_sess.read.option(\"header\",True).csv('s3a://cities/cities.csv')\n",
    "\n",
    "citiesDF.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81e3f4e9-0235-48ed-8b4e-a948c9416dcb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'citiesDF' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m citiesDF\u001b[38;5;241m.\u001b[39mcolumns\n",
      "\u001b[0;31mNameError\u001b[0m: name 'citiesDF' is not defined"
     ]
    }
   ],
   "source": [
    "citiesDF.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83e7d1b9-6ae7-479d-8a2a-92f81cb575e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/09/24 03:02:26 DEBUG BaseSessionStateBuilder$$anon$1: Resolving 'LatM to LatM#89\n",
      "23/09/24 03:02:26 DEBUG BaseSessionStateBuilder$$anon$1: Resolving 'LonM to LonM#100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[LatM: string, LonM: string]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, column\n",
    "cleanCitiesDF = citiesDF \\\n",
    "   .withColumnRenamed(' \"LatM\"', 'LatM') \\\n",
    "   .withColumnRenamed(' \"LonM\"', 'LonM') \\\n",
    "   .select(col('LatM'), col('LonM'))\n",
    "cleanCitiesDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6df081e-bba1-457b-ae0c-a47b82c40b2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/09/24 03:02:29 DEBUG SparkSqlParser: Parsing command: LatM < 10\n",
      "23/09/24 03:02:29 DEBUG BaseSessionStateBuilder$$anon$1: Resolving 'LatM to LatM#113\n",
      "23/09/24 03:02:29 INFO FileSourceStrategy: Pushed Filters: IsNotNull( \"LatM\")\n",
      "23/09/24 03:02:29 INFO FileSourceStrategy: Post-Scan Filters: isnotnull( \"LatM\"#18),(cast( \"LatM\"#18 as int) < 10)\n",
      "23/09/24 03:02:29 INFO FileSourceStrategy: Output Data Schema: struct<LatD: string,  \"LatM\": string,  \"LatS\": string,  \"NS\": string,  \"LonD\": string ... 8 more fields>\n",
      "23/09/24 03:02:29 DEBUG WholeStageCodegenExec: \n",
      "/* 001 */ public Object generate(Object[] references) {\n",
      "/* 002 */   return new GeneratedIteratorForCodegenStage1(references);\n",
      "/* 003 */ }\n",
      "/* 004 */\n",
      "/* 005 */ // codegenStageId=1\n",
      "/* 006 */ final class GeneratedIteratorForCodegenStage1 extends org.apache.spark.sql.execution.BufferedRowIterator {\n",
      "/* 007 */   private Object[] references;\n",
      "/* 008 */   private scala.collection.Iterator[] inputs;\n",
      "/* 009 */   private scala.collection.Iterator inputadapter_input_0;\n",
      "/* 010 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] filter_mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[2];\n",
      "/* 011 */\n",
      "/* 012 */   public GeneratedIteratorForCodegenStage1(Object[] references) {\n",
      "/* 013 */     this.references = references;\n",
      "/* 014 */   }\n",
      "/* 015 */\n",
      "/* 016 */   public void init(int index, scala.collection.Iterator[] inputs) {\n",
      "/* 017 */     partitionIndex = index;\n",
      "/* 018 */     this.inputs = inputs;\n",
      "/* 019 */     inputadapter_input_0 = inputs[0];\n",
      "/* 020 */     filter_mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(10, 320);\n",
      "/* 021 */     filter_mutableStateArray_0[1] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(10, 320);\n",
      "/* 022 */\n",
      "/* 023 */   }\n",
      "/* 024 */\n",
      "/* 025 */   protected void processNext() throws java.io.IOException {\n",
      "/* 026 */     while ( inputadapter_input_0.hasNext()) {\n",
      "/* 027 */       InternalRow inputadapter_row_0 = (InternalRow) inputadapter_input_0.next();\n",
      "/* 028 */\n",
      "/* 029 */       do {\n",
      "/* 030 */         boolean inputadapter_isNull_1 = inputadapter_row_0.isNullAt(1);\n",
      "/* 031 */         UTF8String inputadapter_value_1 = inputadapter_isNull_1 ?\n",
      "/* 032 */         null : (inputadapter_row_0.getUTF8String(1));\n",
      "/* 033 */\n",
      "/* 034 */         boolean filter_value_2 = !inputadapter_isNull_1;\n",
      "/* 035 */         if (!filter_value_2) continue;\n",
      "/* 036 */\n",
      "/* 037 */         boolean filter_isNull_2 = true;\n",
      "/* 038 */         boolean filter_value_3 = false;\n",
      "/* 039 */         boolean filter_isNull_3 = inputadapter_isNull_1;\n",
      "/* 040 */         int filter_value_4 = -1;\n",
      "/* 041 */         if (!inputadapter_isNull_1) {\n",
      "/* 042 */           UTF8String.IntWrapper filter_intWrapper_0 = new UTF8String.IntWrapper();\n",
      "/* 043 */           if (inputadapter_value_1.toInt(filter_intWrapper_0)) {\n",
      "/* 044 */             filter_value_4 = filter_intWrapper_0.value;\n",
      "/* 045 */           } else {\n",
      "/* 046 */             filter_isNull_3 = true;\n",
      "/* 047 */           }\n",
      "/* 048 */           filter_intWrapper_0 = null;\n",
      "/* 049 */         }\n",
      "/* 050 */         if (!filter_isNull_3) {\n",
      "/* 051 */           filter_isNull_2 = false; // resultCode could change nullability.\n",
      "/* 052 */           filter_value_3 = filter_value_4 < 10;\n",
      "/* 053 */\n",
      "/* 054 */         }\n",
      "/* 055 */         if (filter_isNull_2 || !filter_value_3) continue;\n",
      "/* 056 */\n",
      "/* 057 */         ((org.apache.spark.sql.execution.metric.SQLMetric) references[0] /* numOutputRows */).add(1);\n",
      "/* 058 */\n",
      "/* 059 */         // common sub-expressions\n",
      "/* 060 */\n",
      "/* 061 */         boolean inputadapter_isNull_0 = inputadapter_row_0.isNullAt(0);\n",
      "/* 062 */         UTF8String inputadapter_value_0 = inputadapter_isNull_0 ?\n",
      "/* 063 */         null : (inputadapter_row_0.getUTF8String(0));\n",
      "/* 064 */         boolean inputadapter_isNull_2 = inputadapter_row_0.isNullAt(2);\n",
      "/* 065 */         UTF8String inputadapter_value_2 = inputadapter_isNull_2 ?\n",
      "/* 066 */         null : (inputadapter_row_0.getUTF8String(2));\n",
      "/* 067 */         boolean inputadapter_isNull_3 = inputadapter_row_0.isNullAt(3);\n",
      "/* 068 */         UTF8String inputadapter_value_3 = inputadapter_isNull_3 ?\n",
      "/* 069 */         null : (inputadapter_row_0.getUTF8String(3));\n",
      "/* 070 */         boolean inputadapter_isNull_4 = inputadapter_row_0.isNullAt(4);\n",
      "/* 071 */         UTF8String inputadapter_value_4 = inputadapter_isNull_4 ?\n",
      "/* 072 */         null : (inputadapter_row_0.getUTF8String(4));\n",
      "/* 073 */         boolean inputadapter_isNull_5 = inputadapter_row_0.isNullAt(5);\n",
      "/* 074 */         UTF8String inputadapter_value_5 = inputadapter_isNull_5 ?\n",
      "/* 075 */         null : (inputadapter_row_0.getUTF8String(5));\n",
      "/* 076 */         boolean inputadapter_isNull_6 = inputadapter_row_0.isNullAt(6);\n",
      "/* 077 */         UTF8String inputadapter_value_6 = inputadapter_isNull_6 ?\n",
      "/* 078 */         null : (inputadapter_row_0.getUTF8String(6));\n",
      "/* 079 */         boolean inputadapter_isNull_7 = inputadapter_row_0.isNullAt(7);\n",
      "/* 080 */         UTF8String inputadapter_value_7 = inputadapter_isNull_7 ?\n",
      "/* 081 */         null : (inputadapter_row_0.getUTF8String(7));\n",
      "/* 082 */         boolean inputadapter_isNull_8 = inputadapter_row_0.isNullAt(8);\n",
      "/* 083 */         UTF8String inputadapter_value_8 = inputadapter_isNull_8 ?\n",
      "/* 084 */         null : (inputadapter_row_0.getUTF8String(8));\n",
      "/* 085 */         boolean inputadapter_isNull_9 = inputadapter_row_0.isNullAt(9);\n",
      "/* 086 */         UTF8String inputadapter_value_9 = inputadapter_isNull_9 ?\n",
      "/* 087 */         null : (inputadapter_row_0.getUTF8String(9));\n",
      "/* 088 */         filter_mutableStateArray_0[1].reset();\n",
      "/* 089 */\n",
      "/* 090 */         filter_mutableStateArray_0[1].zeroOutNullBytes();\n",
      "/* 091 */\n",
      "/* 092 */         if (inputadapter_isNull_0) {\n",
      "/* 093 */           filter_mutableStateArray_0[1].setNullAt(0);\n",
      "/* 094 */         } else {\n",
      "/* 095 */           filter_mutableStateArray_0[1].write(0, inputadapter_value_0);\n",
      "/* 096 */         }\n",
      "/* 097 */\n",
      "/* 098 */         if (false) {\n",
      "/* 099 */           filter_mutableStateArray_0[1].setNullAt(1);\n",
      "/* 100 */         } else {\n",
      "/* 101 */           filter_mutableStateArray_0[1].write(1, inputadapter_value_1);\n",
      "/* 102 */         }\n",
      "/* 103 */\n",
      "/* 104 */         if (inputadapter_isNull_2) {\n",
      "/* 105 */           filter_mutableStateArray_0[1].setNullAt(2);\n",
      "/* 106 */         } else {\n",
      "/* 107 */           filter_mutableStateArray_0[1].write(2, inputadapter_value_2);\n",
      "/* 108 */         }\n",
      "/* 109 */\n",
      "/* 110 */         if (inputadapter_isNull_3) {\n",
      "/* 111 */           filter_mutableStateArray_0[1].setNullAt(3);\n",
      "/* 112 */         } else {\n",
      "/* 113 */           filter_mutableStateArray_0[1].write(3, inputadapter_value_3);\n",
      "/* 114 */         }\n",
      "/* 115 */\n",
      "/* 116 */         if (inputadapter_isNull_4) {\n",
      "/* 117 */           filter_mutableStateArray_0[1].setNullAt(4);\n",
      "/* 118 */         } else {\n",
      "/* 119 */           filter_mutableStateArray_0[1].write(4, inputadapter_value_4);\n",
      "/* 120 */         }\n",
      "/* 121 */\n",
      "/* 122 */         if (inputadapter_isNull_5) {\n",
      "/* 123 */           filter_mutableStateArray_0[1].setNullAt(5);\n",
      "/* 124 */         } else {\n",
      "/* 125 */           filter_mutableStateArray_0[1].write(5, inputadapter_value_5);\n",
      "/* 126 */         }\n",
      "/* 127 */\n",
      "/* 128 */         if (inputadapter_isNull_6) {\n",
      "/* 129 */           filter_mutableStateArray_0[1].setNullAt(6);\n",
      "/* 130 */         } else {\n",
      "/* 131 */           filter_mutableStateArray_0[1].write(6, inputadapter_value_6);\n",
      "/* 132 */         }\n",
      "/* 133 */\n",
      "/* 134 */         if (inputadapter_isNull_7) {\n",
      "/* 135 */           filter_mutableStateArray_0[1].setNullAt(7);\n",
      "/* 136 */         } else {\n",
      "/* 137 */           filter_mutableStateArray_0[1].write(7, inputadapter_value_7);\n",
      "/* 138 */         }\n",
      "/* 139 */\n",
      "/* 140 */         if (inputadapter_isNull_8) {\n",
      "/* 141 */           filter_mutableStateArray_0[1].setNullAt(8);\n",
      "/* 142 */         } else {\n",
      "/* 143 */           filter_mutableStateArray_0[1].write(8, inputadapter_value_8);\n",
      "/* 144 */         }\n",
      "/* 145 */\n",
      "/* 146 */         if (inputadapter_isNull_9) {\n",
      "/* 147 */           filter_mutableStateArray_0[1].setNullAt(9);\n",
      "/* 148 */         } else {\n",
      "/* 149 */           filter_mutableStateArray_0[1].write(9, inputadapter_value_9);\n",
      "/* 150 */         }\n",
      "/* 151 */         append((filter_mutableStateArray_0[1].getRow()));\n",
      "/* 152 */\n",
      "/* 153 */       } while(false);\n",
      "/* 154 */       if (shouldStop()) return;\n",
      "/* 155 */     }\n",
      "/* 156 */   }\n",
      "/* 157 */\n",
      "/* 158 */ }\n",
      "\n",
      "23/09/24 03:02:29 DEBUG CodeGenerator: \n",
      "/* 001 */ public Object generate(Object[] references) {\n",
      "/* 002 */   return new GeneratedIteratorForCodegenStage1(references);\n",
      "/* 003 */ }\n",
      "/* 004 */\n",
      "/* 005 */ // codegenStageId=1\n",
      "/* 006 */ final class GeneratedIteratorForCodegenStage1 extends org.apache.spark.sql.execution.BufferedRowIterator {\n",
      "/* 007 */   private Object[] references;\n",
      "/* 008 */   private scala.collection.Iterator[] inputs;\n",
      "/* 009 */   private scala.collection.Iterator inputadapter_input_0;\n",
      "/* 010 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] filter_mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[2];\n",
      "/* 011 */\n",
      "/* 012 */   public GeneratedIteratorForCodegenStage1(Object[] references) {\n",
      "/* 013 */     this.references = references;\n",
      "/* 014 */   }\n",
      "/* 015 */\n",
      "/* 016 */   public void init(int index, scala.collection.Iterator[] inputs) {\n",
      "/* 017 */     partitionIndex = index;\n",
      "/* 018 */     this.inputs = inputs;\n",
      "/* 019 */     inputadapter_input_0 = inputs[0];\n",
      "/* 020 */     filter_mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(10, 320);\n",
      "/* 021 */     filter_mutableStateArray_0[1] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(10, 320);\n",
      "/* 022 */\n",
      "/* 023 */   }\n",
      "/* 024 */\n",
      "/* 025 */   protected void processNext() throws java.io.IOException {\n",
      "/* 026 */     while ( inputadapter_input_0.hasNext()) {\n",
      "/* 027 */       InternalRow inputadapter_row_0 = (InternalRow) inputadapter_input_0.next();\n",
      "/* 028 */\n",
      "/* 029 */       do {\n",
      "/* 030 */         boolean inputadapter_isNull_1 = inputadapter_row_0.isNullAt(1);\n",
      "/* 031 */         UTF8String inputadapter_value_1 = inputadapter_isNull_1 ?\n",
      "/* 032 */         null : (inputadapter_row_0.getUTF8String(1));\n",
      "/* 033 */\n",
      "/* 034 */         boolean filter_value_2 = !inputadapter_isNull_1;\n",
      "/* 035 */         if (!filter_value_2) continue;\n",
      "/* 036 */\n",
      "/* 037 */         boolean filter_isNull_2 = true;\n",
      "/* 038 */         boolean filter_value_3 = false;\n",
      "/* 039 */         boolean filter_isNull_3 = inputadapter_isNull_1;\n",
      "/* 040 */         int filter_value_4 = -1;\n",
      "/* 041 */         if (!inputadapter_isNull_1) {\n",
      "/* 042 */           UTF8String.IntWrapper filter_intWrapper_0 = new UTF8String.IntWrapper();\n",
      "/* 043 */           if (inputadapter_value_1.toInt(filter_intWrapper_0)) {\n",
      "/* 044 */             filter_value_4 = filter_intWrapper_0.value;\n",
      "/* 045 */           } else {\n",
      "/* 046 */             filter_isNull_3 = true;\n",
      "/* 047 */           }\n",
      "/* 048 */           filter_intWrapper_0 = null;\n",
      "/* 049 */         }\n",
      "/* 050 */         if (!filter_isNull_3) {\n",
      "/* 051 */           filter_isNull_2 = false; // resultCode could change nullability.\n",
      "/* 052 */           filter_value_3 = filter_value_4 < 10;\n",
      "/* 053 */\n",
      "/* 054 */         }\n",
      "/* 055 */         if (filter_isNull_2 || !filter_value_3) continue;\n",
      "/* 056 */\n",
      "/* 057 */         ((org.apache.spark.sql.execution.metric.SQLMetric) references[0] /* numOutputRows */).add(1);\n",
      "/* 058 */\n",
      "/* 059 */         // common sub-expressions\n",
      "/* 060 */\n",
      "/* 061 */         boolean inputadapter_isNull_0 = inputadapter_row_0.isNullAt(0);\n",
      "/* 062 */         UTF8String inputadapter_value_0 = inputadapter_isNull_0 ?\n",
      "/* 063 */         null : (inputadapter_row_0.getUTF8String(0));\n",
      "/* 064 */         boolean inputadapter_isNull_2 = inputadapter_row_0.isNullAt(2);\n",
      "/* 065 */         UTF8String inputadapter_value_2 = inputadapter_isNull_2 ?\n",
      "/* 066 */         null : (inputadapter_row_0.getUTF8String(2));\n",
      "/* 067 */         boolean inputadapter_isNull_3 = inputadapter_row_0.isNullAt(3);\n",
      "/* 068 */         UTF8String inputadapter_value_3 = inputadapter_isNull_3 ?\n",
      "/* 069 */         null : (inputadapter_row_0.getUTF8String(3));\n",
      "/* 070 */         boolean inputadapter_isNull_4 = inputadapter_row_0.isNullAt(4);\n",
      "/* 071 */         UTF8String inputadapter_value_4 = inputadapter_isNull_4 ?\n",
      "/* 072 */         null : (inputadapter_row_0.getUTF8String(4));\n",
      "/* 073 */         boolean inputadapter_isNull_5 = inputadapter_row_0.isNullAt(5);\n",
      "/* 074 */         UTF8String inputadapter_value_5 = inputadapter_isNull_5 ?\n",
      "/* 075 */         null : (inputadapter_row_0.getUTF8String(5));\n",
      "/* 076 */         boolean inputadapter_isNull_6 = inputadapter_row_0.isNullAt(6);\n",
      "/* 077 */         UTF8String inputadapter_value_6 = inputadapter_isNull_6 ?\n",
      "/* 078 */         null : (inputadapter_row_0.getUTF8String(6));\n",
      "/* 079 */         boolean inputadapter_isNull_7 = inputadapter_row_0.isNullAt(7);\n",
      "/* 080 */         UTF8String inputadapter_value_7 = inputadapter_isNull_7 ?\n",
      "/* 081 */         null : (inputadapter_row_0.getUTF8String(7));\n",
      "/* 082 */         boolean inputadapter_isNull_8 = inputadapter_row_0.isNullAt(8);\n",
      "/* 083 */         UTF8String inputadapter_value_8 = inputadapter_isNull_8 ?\n",
      "/* 084 */         null : (inputadapter_row_0.getUTF8String(8));\n",
      "/* 085 */         boolean inputadapter_isNull_9 = inputadapter_row_0.isNullAt(9);\n",
      "/* 086 */         UTF8String inputadapter_value_9 = inputadapter_isNull_9 ?\n",
      "/* 087 */         null : (inputadapter_row_0.getUTF8String(9));\n",
      "/* 088 */         filter_mutableStateArray_0[1].reset();\n",
      "/* 089 */\n",
      "/* 090 */         filter_mutableStateArray_0[1].zeroOutNullBytes();\n",
      "/* 091 */\n",
      "/* 092 */         if (inputadapter_isNull_0) {\n",
      "/* 093 */           filter_mutableStateArray_0[1].setNullAt(0);\n",
      "/* 094 */         } else {\n",
      "/* 095 */           filter_mutableStateArray_0[1].write(0, inputadapter_value_0);\n",
      "/* 096 */         }\n",
      "/* 097 */\n",
      "/* 098 */         if (false) {\n",
      "/* 099 */           filter_mutableStateArray_0[1].setNullAt(1);\n",
      "/* 100 */         } else {\n",
      "/* 101 */           filter_mutableStateArray_0[1].write(1, inputadapter_value_1);\n",
      "/* 102 */         }\n",
      "/* 103 */\n",
      "/* 104 */         if (inputadapter_isNull_2) {\n",
      "/* 105 */           filter_mutableStateArray_0[1].setNullAt(2);\n",
      "/* 106 */         } else {\n",
      "/* 107 */           filter_mutableStateArray_0[1].write(2, inputadapter_value_2);\n",
      "/* 108 */         }\n",
      "/* 109 */\n",
      "/* 110 */         if (inputadapter_isNull_3) {\n",
      "/* 111 */           filter_mutableStateArray_0[1].setNullAt(3);\n",
      "/* 112 */         } else {\n",
      "/* 113 */           filter_mutableStateArray_0[1].write(3, inputadapter_value_3);\n",
      "/* 114 */         }\n",
      "/* 115 */\n",
      "/* 116 */         if (inputadapter_isNull_4) {\n",
      "/* 117 */           filter_mutableStateArray_0[1].setNullAt(4);\n",
      "/* 118 */         } else {\n",
      "/* 119 */           filter_mutableStateArray_0[1].write(4, inputadapter_value_4);\n",
      "/* 120 */         }\n",
      "/* 121 */\n",
      "/* 122 */         if (inputadapter_isNull_5) {\n",
      "/* 123 */           filter_mutableStateArray_0[1].setNullAt(5);\n",
      "/* 124 */         } else {\n",
      "/* 125 */           filter_mutableStateArray_0[1].write(5, inputadapter_value_5);\n",
      "/* 126 */         }\n",
      "/* 127 */\n",
      "/* 128 */         if (inputadapter_isNull_6) {\n",
      "/* 129 */           filter_mutableStateArray_0[1].setNullAt(6);\n",
      "/* 130 */         } else {\n",
      "/* 131 */           filter_mutableStateArray_0[1].write(6, inputadapter_value_6);\n",
      "/* 132 */         }\n",
      "/* 133 */\n",
      "/* 134 */         if (inputadapter_isNull_7) {\n",
      "/* 135 */           filter_mutableStateArray_0[1].setNullAt(7);\n",
      "/* 136 */         } else {\n",
      "/* 137 */           filter_mutableStateArray_0[1].write(7, inputadapter_value_7);\n",
      "/* 138 */         }\n",
      "/* 139 */\n",
      "/* 140 */         if (inputadapter_isNull_8) {\n",
      "/* 141 */           filter_mutableStateArray_0[1].setNullAt(8);\n",
      "/* 142 */         } else {\n",
      "/* 143 */           filter_mutableStateArray_0[1].write(8, inputadapter_value_8);\n",
      "/* 144 */         }\n",
      "/* 145 */\n",
      "/* 146 */         if (inputadapter_isNull_9) {\n",
      "/* 147 */           filter_mutableStateArray_0[1].setNullAt(9);\n",
      "/* 148 */         } else {\n",
      "/* 149 */           filter_mutableStateArray_0[1].write(9, inputadapter_value_9);\n",
      "/* 150 */         }\n",
      "/* 151 */         append((filter_mutableStateArray_0[1].getRow()));\n",
      "/* 152 */\n",
      "/* 153 */       } while(false);\n",
      "/* 154 */       if (shouldStop()) return;\n",
      "/* 155 */     }\n",
      "/* 156 */   }\n",
      "/* 157 */\n",
      "/* 158 */ }\n",
      "\n",
      "23/09/24 03:02:29 INFO CodeGenerator: Code generated in 105.906805 ms\n",
      "23/09/24 03:02:29 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 405.9 KiB, free 364.6 MiB)\n",
      "23/09/24 03:02:29 DEBUG BlockManager: Put block broadcast_5 locally took 2 ms\n",
      "23/09/24 03:02:29 DEBUG BlockManager: Putting block broadcast_5 without replication took 3 ms\n",
      "23/09/24 03:02:29 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 40.8 KiB, free 364.5 MiB)\n",
      "23/09/24 03:02:29 DEBUG BlockManagerMasterEndpoint: Updating block info on master broadcast_5_piece0 for BlockManagerId(driver, 172.18.0.5, 38339, None)\n",
      "23/09/24 03:02:29 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.18.0.5:38339 (size: 40.8 KiB, free: 366.1 MiB)\n",
      "23/09/24 03:02:29 DEBUG BlockManagerMaster: Updated info of block broadcast_5_piece0\n",
      "23/09/24 03:02:29 DEBUG BlockManager: Told master about block broadcast_5_piece0\n",
      "23/09/24 03:02:29 DEBUG BlockManager: Put block broadcast_5_piece0 locally took 2 ms\n",
      "23/09/24 03:02:29 DEBUG BlockManager: Putting block broadcast_5_piece0 without replication took 2 ms\n",
      "23/09/24 03:02:29 INFO SparkContext: Created broadcast 5 from showString at NativeMethodAccessorImpl.java:0\n",
      "23/09/24 03:02:29 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "23/09/24 03:02:30 DEBUG ClosureCleaner: Cleaning indylambda closure: $anonfun$doExecute$4$adapted\n",
      "23/09/24 03:02:30 DEBUG ClosureCleaner:  +++ indylambda closure ($anonfun$doExecute$4$adapted) is now cleaned +++\n",
      "23/09/24 03:02:30 DEBUG ClosureCleaner: Cleaning indylambda closure: $anonfun$executeTake$2\n",
      "23/09/24 03:02:30 DEBUG ClosureCleaner:  +++ indylambda closure ($anonfun$executeTake$2) is now cleaned +++\n",
      "23/09/24 03:02:30 DEBUG ClosureCleaner: Cleaning indylambda closure: $anonfun$runJob$5\n",
      "23/09/24 03:02:30 DEBUG ClosureCleaner:  +++ indylambda closure ($anonfun$runJob$5) is now cleaned +++\n",
      "23/09/24 03:02:30 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0\n",
      "23/09/24 03:02:30 DEBUG DAGScheduler: eagerlyComputePartitionsForRddAndAncestors for RDD 16 took 0.000142 seconds\n",
      "23/09/24 03:02:30 DEBUG DAGScheduler: Merging stage rdd profiles: Set()\n",
      "23/09/24 03:02:30 INFO DAGScheduler: Got job 2 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/09/24 03:02:30 INFO DAGScheduler: Final stage: ResultStage 2 (showString at NativeMethodAccessorImpl.java:0)\n",
      "23/09/24 03:02:30 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/09/24 03:02:30 INFO DAGScheduler: Missing parents: List()\n",
      "23/09/24 03:02:30 DEBUG DAGScheduler: submitStage(ResultStage 2 (name=showString at NativeMethodAccessorImpl.java:0;jobs=2))\n",
      "23/09/24 03:02:30 DEBUG DAGScheduler: missing: List()\n",
      "23/09/24 03:02:30 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[16] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/09/24 03:02:30 DEBUG DAGScheduler: submitMissingTasks(ResultStage 2)\n",
      "23/09/24 03:02:30 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 17.6 KiB, free 364.5 MiB)\n",
      "23/09/24 03:02:30 DEBUG BlockManager: Put block broadcast_6 locally took 0 ms\n",
      "23/09/24 03:02:30 DEBUG BlockManager: Putting block broadcast_6 without replication took 0 ms\n",
      "23/09/24 03:02:30 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 7.9 KiB, free 364.5 MiB)\n",
      "23/09/24 03:02:30 DEBUG BlockManagerMasterEndpoint: Updating block info on master broadcast_6_piece0 for BlockManagerId(driver, 172.18.0.5, 38339, None)\n",
      "23/09/24 03:02:30 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.18.0.5:38339 (size: 7.9 KiB, free: 366.1 MiB)\n",
      "23/09/24 03:02:30 DEBUG BlockManagerMaster: Updated info of block broadcast_6_piece0\n",
      "23/09/24 03:02:30 DEBUG BlockManager: Told master about block broadcast_6_piece0\n",
      "23/09/24 03:02:30 DEBUG BlockManager: Put block broadcast_6_piece0 locally took 1 ms\n",
      "23/09/24 03:02:30 DEBUG BlockManager: Putting block broadcast_6_piece0 without replication took 1 ms\n",
      "23/09/24 03:02:30 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1513\n",
      "23/09/24 03:02:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[16] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/09/24 03:02:30 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0\n",
      "23/09/24 03:02:30 DEBUG TaskSetManager: Epoch for TaskSet 2.0: 0\n",
      "23/09/24 03:02:30 DEBUG TaskSetManager: Adding pending tasks took 0 ms\n",
      "23/09/24 03:02:30 DEBUG TaskSetManager: Valid locality levels for TaskSet 2.0: NO_PREF, ANY\n",
      "23/09/24 03:02:30 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_2.0, runningTasks: 0\n",
      "23/09/24 03:02:30 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (172.18.0.2, executor 1, partition 0, PROCESS_LOCAL, 4898 bytes) taskResourceAssignments Map()\n",
      "23/09/24 03:02:30 DEBUG TaskSetManager: No tasks for locality level NO_PREF, so moving to locality level ANY\n",
      "23/09/24 03:02:30 DEBUG CoarseGrainedSchedulerBackend$DriverEndpoint: Launching task 2 on executor id: 1 hostname: 172.18.0.2.\n",
      "23/09/24 03:02:30 DEBUG BlockManager: Getting local block broadcast_6_piece0 as bytes\n",
      "23/09/24 03:02:30 DEBUG BlockManager: Level for block broadcast_6_piece0 is StorageLevel(disk, memory, 1 replicas)\n",
      "23/09/24 03:02:30 DEBUG BlockManagerMasterEndpoint: Updating block info on master broadcast_6_piece0 for BlockManagerId(1, 172.18.0.2, 35209, None)\n",
      "23/09/24 03:02:30 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.18.0.2:35209 (size: 7.9 KiB, free: 366.2 MiB)\n",
      "23/09/24 03:02:30 DEBUG BlockManager: Getting local block broadcast_5_piece0 as bytes\n",
      "23/09/24 03:02:30 DEBUG BlockManager: Level for block broadcast_5_piece0 is StorageLevel(disk, memory, 1 replicas)\n",
      "23/09/24 03:02:30 DEBUG BlockManagerMasterEndpoint: Updating block info on master broadcast_5_piece0 for BlockManagerId(1, 172.18.0.2, 35209, None)\n",
      "23/09/24 03:02:30 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.18.0.2:35209 (size: 40.8 KiB, free: 366.2 MiB)\n",
      "23/09/24 03:02:30 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 503 ms on 172.18.0.2 (executor 1) (1/1)\n",
      "23/09/24 03:02:30 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool \n",
      "23/09/24 03:02:30 INFO DAGScheduler: ResultStage 2 (showString at NativeMethodAccessorImpl.java:0) finished in 0.515 s\n",
      "23/09/24 03:02:30 DEBUG DAGScheduler: After removal of stage 2, remaining stages = 0\n",
      "23/09/24 03:02:30 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/09/24 03:02:30 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished\n",
      "23/09/24 03:02:30 INFO DAGScheduler: Job 2 finished: showString at NativeMethodAccessorImpl.java:0, took 0.519669 s\n",
      "23/09/24 03:02:30 DEBUG GenerateSafeProjection: code for createexternalrow(input[0, string, true].toString, input[1, string, true].toString, input[2, string, true].toString, input[3, string, true].toString, input[4, string, true].toString, input[5, string, true].toString, input[6, string, true].toString, input[7, string, true].toString, input[8, string, true].toString, input[9, string, true].toString, StructField(LatD,StringType,true), StructField(LatM,StringType,true), StructField( \"LatS\",StringType,true), StructField( \"NS\",StringType,true), StructField( \"LonD\",StringType,true), StructField(LonM,StringType,true), StructField( \"LonS\",StringType,true), StructField( \"EW\",StringType,true), StructField( \"City\",StringType,true), StructField( \"State\",StringType,true)):\n",
      "/* 001 */ public java.lang.Object generate(Object[] references) {\n",
      "/* 002 */   return new SpecificSafeProjection(references);\n",
      "/* 003 */ }\n",
      "/* 004 */\n",
      "/* 005 */ class SpecificSafeProjection extends org.apache.spark.sql.catalyst.expressions.codegen.BaseProjection {\n",
      "/* 006 */\n",
      "/* 007 */   private Object[] references;\n",
      "/* 008 */   private InternalRow mutableRow;\n",
      "/* 009 */\n",
      "/* 010 */\n",
      "/* 011 */   public SpecificSafeProjection(Object[] references) {\n",
      "/* 012 */     this.references = references;\n",
      "/* 013 */     mutableRow = (InternalRow) references[references.length - 1];\n",
      "/* 014 */\n",
      "/* 015 */   }\n",
      "/* 016 */\n",
      "/* 017 */   public void initialize(int partitionIndex) {\n",
      "/* 018 */\n",
      "/* 019 */   }\n",
      "/* 020 */\n",
      "/* 021 */   public java.lang.Object apply(java.lang.Object _i) {\n",
      "/* 022 */     InternalRow i = (InternalRow) _i;\n",
      "/* 023 */     Object[] values_0 = new Object[10];\n",
      "/* 024 */     createExternalRow_0_0(i, values_0);\n",
      "/* 025 */     createExternalRow_0_1(i, values_0);\n",
      "/* 026 */     createExternalRow_0_2(i, values_0);\n",
      "/* 027 */     createExternalRow_0_3(i, values_0);\n",
      "/* 028 */     final org.apache.spark.sql.Row value_0 = new org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema(values_0, ((org.apache.spark.sql.types.StructType) references[0] /* schema */));\n",
      "/* 029 */     if (false) {\n",
      "/* 030 */       mutableRow.setNullAt(0);\n",
      "/* 031 */     } else {\n",
      "/* 032 */\n",
      "/* 033 */       mutableRow.update(0, value_0);\n",
      "/* 034 */     }\n",
      "/* 035 */\n",
      "/* 036 */     return mutableRow;\n",
      "/* 037 */   }\n",
      "/* 038 */\n",
      "/* 039 */\n",
      "/* 040 */   private void createExternalRow_0_2(InternalRow i, Object[] values_0) {\n",
      "/* 041 */\n",
      "/* 042 */     boolean isNull_14 = i.isNullAt(6);\n",
      "/* 043 */     UTF8String value_14 = isNull_14 ?\n",
      "/* 044 */     null : (i.getUTF8String(6));\n",
      "/* 045 */     boolean isNull_13 = true;\n",
      "/* 046 */     java.lang.String value_13 = null;\n",
      "/* 047 */     if (!isNull_14) {\n",
      "/* 048 */       isNull_13 = false;\n",
      "/* 049 */       if (!isNull_13) {\n",
      "/* 050 */\n",
      "/* 051 */         Object funcResult_6 = null;\n",
      "/* 052 */         funcResult_6 = value_14.toString();\n",
      "/* 053 */         value_13 = (java.lang.String) funcResult_6;\n",
      "/* 054 */\n",
      "/* 055 */       }\n",
      "/* 056 */     }\n",
      "/* 057 */     if (isNull_13) {\n",
      "/* 058 */       values_0[6] = null;\n",
      "/* 059 */     } else {\n",
      "/* 060 */       values_0[6] = value_13;\n",
      "/* 061 */     }\n",
      "/* 062 */\n",
      "/* 063 */     boolean isNull_16 = i.isNullAt(7);\n",
      "/* 064 */     UTF8String value_16 = isNull_16 ?\n",
      "/* 065 */     null : (i.getUTF8String(7));\n",
      "/* 066 */     boolean isNull_15 = true;\n",
      "/* 067 */     java.lang.String value_15 = null;\n",
      "/* 068 */     if (!isNull_16) {\n",
      "/* 069 */       isNull_15 = false;\n",
      "/* 070 */       if (!isNull_15) {\n",
      "/* 071 */\n",
      "/* 072 */         Object funcResult_7 = null;\n",
      "/* 073 */         funcResult_7 = value_16.toString();\n",
      "/* 074 */         value_15 = (java.lang.String) funcResult_7;\n",
      "/* 075 */\n",
      "/* 076 */       }\n",
      "/* 077 */     }\n",
      "/* 078 */     if (isNull_15) {\n",
      "/* 079 */       values_0[7] = null;\n",
      "/* 080 */     } else {\n",
      "/* 081 */       values_0[7] = value_15;\n",
      "/* 082 */     }\n",
      "/* 083 */\n",
      "/* 084 */     boolean isNull_18 = i.isNullAt(8);\n",
      "/* 085 */     UTF8String value_18 = isNull_18 ?\n",
      "/* 086 */     null : (i.getUTF8String(8));\n",
      "/* 087 */     boolean isNull_17 = true;\n",
      "/* 088 */     java.lang.String value_17 = null;\n",
      "/* 089 */     if (!isNull_18) {\n",
      "/* 090 */       isNull_17 = false;\n",
      "/* 091 */       if (!isNull_17) {\n",
      "/* 092 */\n",
      "/* 093 */         Object funcResult_8 = null;\n",
      "/* 094 */         funcResult_8 = value_18.toString();\n",
      "/* 095 */         value_17 = (java.lang.String) funcResult_8;\n",
      "/* 096 */\n",
      "/* 097 */       }\n",
      "/* 098 */     }\n",
      "/* 099 */     if (isNull_17) {\n",
      "/* 100 */       values_0[8] = null;\n",
      "/* 101 */     } else {\n",
      "/* 102 */       values_0[8] = value_17;\n",
      "/* 103 */     }\n",
      "/* 104 */\n",
      "/* 105 */   }\n",
      "/* 106 */\n",
      "/* 107 */\n",
      "/* 108 */   private void createExternalRow_0_1(InternalRow i, Object[] values_0) {\n",
      "/* 109 */\n",
      "/* 110 */     boolean isNull_8 = i.isNullAt(3);\n",
      "/* 111 */     UTF8String value_8 = isNull_8 ?\n",
      "/* 112 */     null : (i.getUTF8String(3));\n",
      "/* 113 */     boolean isNull_7 = true;\n",
      "/* 114 */     java.lang.String value_7 = null;\n",
      "/* 115 */     if (!isNull_8) {\n",
      "/* 116 */       isNull_7 = false;\n",
      "/* 117 */       if (!isNull_7) {\n",
      "/* 118 */\n",
      "/* 119 */         Object funcResult_3 = null;\n",
      "/* 120 */         funcResult_3 = value_8.toString();\n",
      "/* 121 */         value_7 = (java.lang.String) funcResult_3;\n",
      "/* 122 */\n",
      "/* 123 */       }\n",
      "/* 124 */     }\n",
      "/* 125 */     if (isNull_7) {\n",
      "/* 126 */       values_0[3] = null;\n",
      "/* 127 */     } else {\n",
      "/* 128 */       values_0[3] = value_7;\n",
      "/* 129 */     }\n",
      "/* 130 */\n",
      "/* 131 */     boolean isNull_10 = i.isNullAt(4);\n",
      "/* 132 */     UTF8String value_10 = isNull_10 ?\n",
      "/* 133 */     null : (i.getUTF8String(4));\n",
      "/* 134 */     boolean isNull_9 = true;\n",
      "/* 135 */     java.lang.String value_9 = null;\n",
      "/* 136 */     if (!isNull_10) {\n",
      "/* 137 */       isNull_9 = false;\n",
      "/* 138 */       if (!isNull_9) {\n",
      "/* 139 */\n",
      "/* 140 */         Object funcResult_4 = null;\n",
      "/* 141 */         funcResult_4 = value_10.toString();\n",
      "/* 142 */         value_9 = (java.lang.String) funcResult_4;\n",
      "/* 143 */\n",
      "/* 144 */       }\n",
      "/* 145 */     }\n",
      "/* 146 */     if (isNull_9) {\n",
      "/* 147 */       values_0[4] = null;\n",
      "/* 148 */     } else {\n",
      "/* 149 */       values_0[4] = value_9;\n",
      "/* 150 */     }\n",
      "/* 151 */\n",
      "/* 152 */     boolean isNull_12 = i.isNullAt(5);\n",
      "/* 153 */     UTF8String value_12 = isNull_12 ?\n",
      "/* 154 */     null : (i.getUTF8String(5));\n",
      "/* 155 */     boolean isNull_11 = true;\n",
      "/* 156 */     java.lang.String value_11 = null;\n",
      "/* 157 */     if (!isNull_12) {\n",
      "/* 158 */       isNull_11 = false;\n",
      "/* 159 */       if (!isNull_11) {\n",
      "/* 160 */\n",
      "/* 161 */         Object funcResult_5 = null;\n",
      "/* 162 */         funcResult_5 = value_12.toString();\n",
      "/* 163 */         value_11 = (java.lang.String) funcResult_5;\n",
      "/* 164 */\n",
      "/* 165 */       }\n",
      "/* 166 */     }\n",
      "/* 167 */     if (isNull_11) {\n",
      "/* 168 */       values_0[5] = null;\n",
      "/* 169 */     } else {\n",
      "/* 170 */       values_0[5] = value_11;\n",
      "/* 171 */     }\n",
      "/* 172 */\n",
      "/* 173 */   }\n",
      "/* 174 */\n",
      "/* 175 */\n",
      "/* 176 */   private void createExternalRow_0_3(InternalRow i, Object[] values_0) {\n",
      "/* 177 */\n",
      "/* 178 */     boolean isNull_20 = i.isNullAt(9);\n",
      "/* 179 */     UTF8String value_20 = isNull_20 ?\n",
      "/* 180 */     null : (i.getUTF8String(9));\n",
      "/* 181 */     boolean isNull_19 = true;\n",
      "/* 182 */     java.lang.String value_19 = null;\n",
      "/* 183 */     if (!isNull_20) {\n",
      "/* 184 */       isNull_19 = false;\n",
      "/* 185 */       if (!isNull_19) {\n",
      "/* 186 */\n",
      "/* 187 */         Object funcResult_9 = null;\n",
      "/* 188 */         funcResult_9 = value_20.toString();\n",
      "/* 189 */         value_19 = (java.lang.String) funcResult_9;\n",
      "/* 190 */\n",
      "/* 191 */       }\n",
      "/* 192 */     }\n",
      "/* 193 */     if (isNull_19) {\n",
      "/* 194 */       values_0[9] = null;\n",
      "/* 195 */     } else {\n",
      "/* 196 */       values_0[9] = value_19;\n",
      "/* 197 */     }\n",
      "/* 198 */\n",
      "/* 199 */   }\n",
      "/* 200 */\n",
      "/* 201 */\n",
      "/* 202 */   private void createExternalRow_0_0(InternalRow i, Object[] values_0) {\n",
      "/* 203 */\n",
      "/* 204 */     boolean isNull_2 = i.isNullAt(0);\n",
      "/* 205 */     UTF8String value_2 = isNull_2 ?\n",
      "/* 206 */     null : (i.getUTF8String(0));\n",
      "/* 207 */     boolean isNull_1 = true;\n",
      "/* 208 */     java.lang.String value_1 = null;\n",
      "/* 209 */     if (!isNull_2) {\n",
      "/* 210 */       isNull_1 = false;\n",
      "/* 211 */       if (!isNull_1) {\n",
      "/* 212 */\n",
      "/* 213 */         Object funcResult_0 = null;\n",
      "/* 214 */         funcResult_0 = value_2.toString();\n",
      "/* 215 */         value_1 = (java.lang.String) funcResult_0;\n",
      "/* 216 */\n",
      "/* 217 */       }\n",
      "/* 218 */     }\n",
      "/* 219 */     if (isNull_1) {\n",
      "/* 220 */       values_0[0] = null;\n",
      "/* 221 */     } else {\n",
      "/* 222 */       values_0[0] = value_1;\n",
      "/* 223 */     }\n",
      "/* 224 */\n",
      "/* 225 */     boolean isNull_4 = i.isNullAt(1);\n",
      "/* 226 */     UTF8String value_4 = isNull_4 ?\n",
      "/* 227 */     null : (i.getUTF8String(1));\n",
      "/* 228 */     boolean isNull_3 = true;\n",
      "/* 229 */     java.lang.String value_3 = null;\n",
      "/* 230 */     if (!isNull_4) {\n",
      "/* 231 */       isNull_3 = false;\n",
      "/* 232 */       if (!isNull_3) {\n",
      "/* 233 */\n",
      "/* 234 */         Object funcResult_1 = null;\n",
      "/* 235 */         funcResult_1 = value_4.toString();\n",
      "/* 236 */         value_3 = (java.lang.String) funcResult_1;\n",
      "/* 237 */\n",
      "/* 238 */       }\n",
      "/* 239 */     }\n",
      "/* 240 */     if (isNull_3) {\n",
      "/* 241 */       values_0[1] = null;\n",
      "/* 242 */     } else {\n",
      "/* 243 */       values_0[1] = value_3;\n",
      "/* 244 */     }\n",
      "/* 245 */\n",
      "/* 246 */     boolean isNull_6 = i.isNullAt(2);\n",
      "/* 247 */     UTF8String value_6 = isNull_6 ?\n",
      "/* 248 */     null : (i.getUTF8String(2));\n",
      "/* 249 */     boolean isNull_5 = true;\n",
      "/* 250 */     java.lang.String value_5 = null;\n",
      "/* 251 */     if (!isNull_6) {\n",
      "/* 252 */       isNull_5 = false;\n",
      "/* 253 */       if (!isNull_5) {\n",
      "/* 254 */\n",
      "/* 255 */         Object funcResult_2 = null;\n",
      "/* 256 */         funcResult_2 = value_6.toString();\n",
      "/* 257 */         value_5 = (java.lang.String) funcResult_2;\n",
      "/* 258 */\n",
      "/* 259 */       }\n",
      "/* 260 */     }\n",
      "/* 261 */     if (isNull_5) {\n",
      "/* 262 */       values_0[2] = null;\n",
      "/* 263 */     } else {\n",
      "/* 264 */       values_0[2] = value_5;\n",
      "/* 265 */     }\n",
      "/* 266 */\n",
      "/* 267 */   }\n",
      "/* 268 */\n",
      "/* 269 */ }\n",
      "\n",
      "+-----+-----+-------+-----+-------+-----+-------+-----+-----------------+--------+\n",
      "| LatD| LatM| \"LatS\"| \"NS\"| \"LonD\"| LonM| \"LonS\"| \"EW\"|           \"City\"| \"State\"|\n",
      "+-----+-----+-------+-----+-------+-----+-------+-----+-----------------+--------+\n",
      "|   41|    5|     59|  \"N\"|     80|   39|      0|  \"W\"|     \"Youngstown\"|      OH|\n",
      "|   36|    5|     59|  \"N\"|     80|   15|      0|  \"W\"|  \"Winston-Salem\"|      NC|\n",
      "|   48|    9|      0|  \"N\"|    103|   37|     12|  \"W\"|      \"Williston\"|      ND|\n",
      "|   40|    4|     11|  \"N\"|     80|   43|     12|  \"W\"|       \"Wheeling\"|      WV|\n",
      "|   46|    4|     11|  \"N\"|    118|   19|     48|  \"W\"|    \"Walla Walla\"|      WA|\n",
      "|   43|    6|     36|  \"N\"|     75|   13|     48|  \"W\"|          \"Utica\"|      NY|\n",
      "|   36|    9|     35|  \"N\"|     95|   54|     36|  \"W\"|          \"Tulsa\"|      OK|\n",
      "|   39|    2|     59|  \"N\"|     95|   40|     11|  \"W\"|         \"Topeka\"|      KS|\n",
      "|   43|    2|     59|  \"N\"|     76|    9|      0|  \"W\"|       \"Syracuse\"|      NY|\n",
      "|   38|    9|      0|  \"N\"|     79|    4|     11|  \"W\"|       \"Staunton\"|      VA|\n",
      "|   42|    5|     59|  \"N\"|     72|   35|     23|  \"W\"|    \"Springfield\"|      MA|\n",
      "|   32|    4|     48|  \"N\"|     81|    5|     23|  \"W\"|       \"Savannah\"|      GA|\n",
      "|   34|    6|     36|  \"N\"|    117|   18|     35|  \"W\"| \"San Bernardino\"|      CA|\n",
      "|   42|    5|     59|  \"N\"|     86|   28|     48|  \"W\"|   \"Saint Joseph\"|      MI|\n",
      "|   43|    9|     35|  \"N\"|     77|   36|     36|  \"W\"|      \"Rochester\"|      NY|\n",
      "|   44|    1|     12|  \"N\"|     92|   27|     35|  \"W\"|      \"Rochester\"|      MN|\n",
      "|   41|    9|     35|  \"N\"|     81|   14|     23|  \"W\"|        \"Ravenna\"|     OH |\n",
      "+-----+-----+-------+-----+-------+-----+-------+-----+-----------------+--------+\n",
      "\n",
      "23/09/24 03:02:33 DEBUG PoolingHttpClientConnectionManager: Closing connections idle longer than 60000 MILLISECONDS\n"
     ]
    }
   ],
   "source": [
    "manipulatedFrame = citiesDF \\\n",
    "   .withColumnRenamed(' \"LatM\"', 'LatM') \\\n",
    "   .withColumnRenamed(' \"LonM\"', 'LonM')\n",
    "\n",
    "manipulatedFrame.filter('LatM < 10').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0dda403-b193-437e-a673-e27905afecdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/09/24 03:02:40 INFO FileSourceStrategy: Pushed Filters: \n",
      "23/09/24 03:02:40 INFO FileSourceStrategy: Post-Scan Filters: \n",
      "23/09/24 03:02:40 INFO FileSourceStrategy: Output Data Schema: struct<LatD: string,  \"LatM\": string,  \"LatS\": string,  \"NS\": string,  \"LonD\": string ... 8 more fields>\n",
      "23/09/24 03:02:40 DEBUG WholeStageCodegenExec: \n",
      "/* 001 */ public Object generate(Object[] references) {\n",
      "/* 002 */   return new GeneratedIteratorForCodegenStage1(references);\n",
      "/* 003 */ }\n",
      "/* 004 */\n",
      "/* 005 */ // codegenStageId=1\n",
      "/* 006 */ final class GeneratedIteratorForCodegenStage1 extends org.apache.spark.sql.execution.BufferedRowIterator {\n",
      "/* 007 */   private Object[] references;\n",
      "/* 008 */   private scala.collection.Iterator[] inputs;\n",
      "/* 009 */   private scala.collection.Iterator inputadapter_input_0;\n",
      "/* 010 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] project_mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];\n",
      "/* 011 */\n",
      "/* 012 */   public GeneratedIteratorForCodegenStage1(Object[] references) {\n",
      "/* 013 */     this.references = references;\n",
      "/* 014 */   }\n",
      "/* 015 */\n",
      "/* 016 */   public void init(int index, scala.collection.Iterator[] inputs) {\n",
      "/* 017 */     partitionIndex = index;\n",
      "/* 018 */     this.inputs = inputs;\n",
      "/* 019 */     inputadapter_input_0 = inputs[0];\n",
      "/* 020 */     project_mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(10, 320);\n",
      "/* 021 */\n",
      "/* 022 */   }\n",
      "/* 023 */\n",
      "/* 024 */   protected void processNext() throws java.io.IOException {\n",
      "/* 025 */     while ( inputadapter_input_0.hasNext()) {\n",
      "/* 026 */       InternalRow inputadapter_row_0 = (InternalRow) inputadapter_input_0.next();\n",
      "/* 027 */\n",
      "/* 028 */       // common sub-expressions\n",
      "/* 029 */\n",
      "/* 030 */       boolean inputadapter_isNull_0 = inputadapter_row_0.isNullAt(0);\n",
      "/* 031 */       UTF8String inputadapter_value_0 = inputadapter_isNull_0 ?\n",
      "/* 032 */       null : (inputadapter_row_0.getUTF8String(0));\n",
      "/* 033 */       boolean inputadapter_isNull_1 = inputadapter_row_0.isNullAt(1);\n",
      "/* 034 */       UTF8String inputadapter_value_1 = inputadapter_isNull_1 ?\n",
      "/* 035 */       null : (inputadapter_row_0.getUTF8String(1));\n",
      "/* 036 */       boolean inputadapter_isNull_2 = inputadapter_row_0.isNullAt(2);\n",
      "/* 037 */       UTF8String inputadapter_value_2 = inputadapter_isNull_2 ?\n",
      "/* 038 */       null : (inputadapter_row_0.getUTF8String(2));\n",
      "/* 039 */       boolean inputadapter_isNull_3 = inputadapter_row_0.isNullAt(3);\n",
      "/* 040 */       UTF8String inputadapter_value_3 = inputadapter_isNull_3 ?\n",
      "/* 041 */       null : (inputadapter_row_0.getUTF8String(3));\n",
      "/* 042 */       boolean inputadapter_isNull_4 = inputadapter_row_0.isNullAt(4);\n",
      "/* 043 */       UTF8String inputadapter_value_4 = inputadapter_isNull_4 ?\n",
      "/* 044 */       null : (inputadapter_row_0.getUTF8String(4));\n",
      "/* 045 */       boolean inputadapter_isNull_5 = inputadapter_row_0.isNullAt(5);\n",
      "/* 046 */       UTF8String inputadapter_value_5 = inputadapter_isNull_5 ?\n",
      "/* 047 */       null : (inputadapter_row_0.getUTF8String(5));\n",
      "/* 048 */       boolean inputadapter_isNull_6 = inputadapter_row_0.isNullAt(6);\n",
      "/* 049 */       UTF8String inputadapter_value_6 = inputadapter_isNull_6 ?\n",
      "/* 050 */       null : (inputadapter_row_0.getUTF8String(6));\n",
      "/* 051 */       boolean inputadapter_isNull_7 = inputadapter_row_0.isNullAt(7);\n",
      "/* 052 */       UTF8String inputadapter_value_7 = inputadapter_isNull_7 ?\n",
      "/* 053 */       null : (inputadapter_row_0.getUTF8String(7));\n",
      "/* 054 */       boolean inputadapter_isNull_8 = inputadapter_row_0.isNullAt(8);\n",
      "/* 055 */       UTF8String inputadapter_value_8 = inputadapter_isNull_8 ?\n",
      "/* 056 */       null : (inputadapter_row_0.getUTF8String(8));\n",
      "/* 057 */       boolean inputadapter_isNull_9 = inputadapter_row_0.isNullAt(9);\n",
      "/* 058 */       UTF8String inputadapter_value_9 = inputadapter_isNull_9 ?\n",
      "/* 059 */       null : (inputadapter_row_0.getUTF8String(9));\n",
      "/* 060 */       project_mutableStateArray_0[0].reset();\n",
      "/* 061 */\n",
      "/* 062 */       project_mutableStateArray_0[0].zeroOutNullBytes();\n",
      "/* 063 */\n",
      "/* 064 */       if (inputadapter_isNull_0) {\n",
      "/* 065 */         project_mutableStateArray_0[0].setNullAt(0);\n",
      "/* 066 */       } else {\n",
      "/* 067 */         project_mutableStateArray_0[0].write(0, inputadapter_value_0);\n",
      "/* 068 */       }\n",
      "/* 069 */\n",
      "/* 070 */       if (inputadapter_isNull_1) {\n",
      "/* 071 */         project_mutableStateArray_0[0].setNullAt(1);\n",
      "/* 072 */       } else {\n",
      "/* 073 */         project_mutableStateArray_0[0].write(1, inputadapter_value_1);\n",
      "/* 074 */       }\n",
      "/* 075 */\n",
      "/* 076 */       if (inputadapter_isNull_2) {\n",
      "/* 077 */         project_mutableStateArray_0[0].setNullAt(2);\n",
      "/* 078 */       } else {\n",
      "/* 079 */         project_mutableStateArray_0[0].write(2, inputadapter_value_2);\n",
      "/* 080 */       }\n",
      "/* 081 */\n",
      "/* 082 */       if (inputadapter_isNull_3) {\n",
      "/* 083 */         project_mutableStateArray_0[0].setNullAt(3);\n",
      "/* 084 */       } else {\n",
      "/* 085 */         project_mutableStateArray_0[0].write(3, inputadapter_value_3);\n",
      "/* 086 */       }\n",
      "/* 087 */\n",
      "/* 088 */       if (inputadapter_isNull_4) {\n",
      "/* 089 */         project_mutableStateArray_0[0].setNullAt(4);\n",
      "/* 090 */       } else {\n",
      "/* 091 */         project_mutableStateArray_0[0].write(4, inputadapter_value_4);\n",
      "/* 092 */       }\n",
      "/* 093 */\n",
      "/* 094 */       if (inputadapter_isNull_5) {\n",
      "/* 095 */         project_mutableStateArray_0[0].setNullAt(5);\n",
      "/* 096 */       } else {\n",
      "/* 097 */         project_mutableStateArray_0[0].write(5, inputadapter_value_5);\n",
      "/* 098 */       }\n",
      "/* 099 */\n",
      "/* 100 */       if (inputadapter_isNull_6) {\n",
      "/* 101 */         project_mutableStateArray_0[0].setNullAt(6);\n",
      "/* 102 */       } else {\n",
      "/* 103 */         project_mutableStateArray_0[0].write(6, inputadapter_value_6);\n",
      "/* 104 */       }\n",
      "/* 105 */\n",
      "/* 106 */       if (inputadapter_isNull_7) {\n",
      "/* 107 */         project_mutableStateArray_0[0].setNullAt(7);\n",
      "/* 108 */       } else {\n",
      "/* 109 */         project_mutableStateArray_0[0].write(7, inputadapter_value_7);\n",
      "/* 110 */       }\n",
      "/* 111 */\n",
      "/* 112 */       if (inputadapter_isNull_8) {\n",
      "/* 113 */         project_mutableStateArray_0[0].setNullAt(8);\n",
      "/* 114 */       } else {\n",
      "/* 115 */         project_mutableStateArray_0[0].write(8, inputadapter_value_8);\n",
      "/* 116 */       }\n",
      "/* 117 */\n",
      "/* 118 */       if (inputadapter_isNull_9) {\n",
      "/* 119 */         project_mutableStateArray_0[0].setNullAt(9);\n",
      "/* 120 */       } else {\n",
      "/* 121 */         project_mutableStateArray_0[0].write(9, inputadapter_value_9);\n",
      "/* 122 */       }\n",
      "/* 123 */       append((project_mutableStateArray_0[0].getRow()));\n",
      "/* 124 */       if (shouldStop()) return;\n",
      "/* 125 */     }\n",
      "/* 126 */   }\n",
      "/* 127 */\n",
      "/* 128 */ }\n",
      "\n",
      "23/09/24 03:02:40 DEBUG CodeGenerator: \n",
      "/* 001 */ public Object generate(Object[] references) {\n",
      "/* 002 */   return new GeneratedIteratorForCodegenStage1(references);\n",
      "/* 003 */ }\n",
      "/* 004 */\n",
      "/* 005 */ // codegenStageId=1\n",
      "/* 006 */ final class GeneratedIteratorForCodegenStage1 extends org.apache.spark.sql.execution.BufferedRowIterator {\n",
      "/* 007 */   private Object[] references;\n",
      "/* 008 */   private scala.collection.Iterator[] inputs;\n",
      "/* 009 */   private scala.collection.Iterator inputadapter_input_0;\n",
      "/* 010 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] project_mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];\n",
      "/* 011 */\n",
      "/* 012 */   public GeneratedIteratorForCodegenStage1(Object[] references) {\n",
      "/* 013 */     this.references = references;\n",
      "/* 014 */   }\n",
      "/* 015 */\n",
      "/* 016 */   public void init(int index, scala.collection.Iterator[] inputs) {\n",
      "/* 017 */     partitionIndex = index;\n",
      "/* 018 */     this.inputs = inputs;\n",
      "/* 019 */     inputadapter_input_0 = inputs[0];\n",
      "/* 020 */     project_mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(10, 320);\n",
      "/* 021 */\n",
      "/* 022 */   }\n",
      "/* 023 */\n",
      "/* 024 */   protected void processNext() throws java.io.IOException {\n",
      "/* 025 */     while ( inputadapter_input_0.hasNext()) {\n",
      "/* 026 */       InternalRow inputadapter_row_0 = (InternalRow) inputadapter_input_0.next();\n",
      "/* 027 */\n",
      "/* 028 */       // common sub-expressions\n",
      "/* 029 */\n",
      "/* 030 */       boolean inputadapter_isNull_0 = inputadapter_row_0.isNullAt(0);\n",
      "/* 031 */       UTF8String inputadapter_value_0 = inputadapter_isNull_0 ?\n",
      "/* 032 */       null : (inputadapter_row_0.getUTF8String(0));\n",
      "/* 033 */       boolean inputadapter_isNull_1 = inputadapter_row_0.isNullAt(1);\n",
      "/* 034 */       UTF8String inputadapter_value_1 = inputadapter_isNull_1 ?\n",
      "/* 035 */       null : (inputadapter_row_0.getUTF8String(1));\n",
      "/* 036 */       boolean inputadapter_isNull_2 = inputadapter_row_0.isNullAt(2);\n",
      "/* 037 */       UTF8String inputadapter_value_2 = inputadapter_isNull_2 ?\n",
      "/* 038 */       null : (inputadapter_row_0.getUTF8String(2));\n",
      "/* 039 */       boolean inputadapter_isNull_3 = inputadapter_row_0.isNullAt(3);\n",
      "/* 040 */       UTF8String inputadapter_value_3 = inputadapter_isNull_3 ?\n",
      "/* 041 */       null : (inputadapter_row_0.getUTF8String(3));\n",
      "/* 042 */       boolean inputadapter_isNull_4 = inputadapter_row_0.isNullAt(4);\n",
      "/* 043 */       UTF8String inputadapter_value_4 = inputadapter_isNull_4 ?\n",
      "/* 044 */       null : (inputadapter_row_0.getUTF8String(4));\n",
      "/* 045 */       boolean inputadapter_isNull_5 = inputadapter_row_0.isNullAt(5);\n",
      "/* 046 */       UTF8String inputadapter_value_5 = inputadapter_isNull_5 ?\n",
      "/* 047 */       null : (inputadapter_row_0.getUTF8String(5));\n",
      "/* 048 */       boolean inputadapter_isNull_6 = inputadapter_row_0.isNullAt(6);\n",
      "/* 049 */       UTF8String inputadapter_value_6 = inputadapter_isNull_6 ?\n",
      "/* 050 */       null : (inputadapter_row_0.getUTF8String(6));\n",
      "/* 051 */       boolean inputadapter_isNull_7 = inputadapter_row_0.isNullAt(7);\n",
      "/* 052 */       UTF8String inputadapter_value_7 = inputadapter_isNull_7 ?\n",
      "/* 053 */       null : (inputadapter_row_0.getUTF8String(7));\n",
      "/* 054 */       boolean inputadapter_isNull_8 = inputadapter_row_0.isNullAt(8);\n",
      "/* 055 */       UTF8String inputadapter_value_8 = inputadapter_isNull_8 ?\n",
      "/* 056 */       null : (inputadapter_row_0.getUTF8String(8));\n",
      "/* 057 */       boolean inputadapter_isNull_9 = inputadapter_row_0.isNullAt(9);\n",
      "/* 058 */       UTF8String inputadapter_value_9 = inputadapter_isNull_9 ?\n",
      "/* 059 */       null : (inputadapter_row_0.getUTF8String(9));\n",
      "/* 060 */       project_mutableStateArray_0[0].reset();\n",
      "/* 061 */\n",
      "/* 062 */       project_mutableStateArray_0[0].zeroOutNullBytes();\n",
      "/* 063 */\n",
      "/* 064 */       if (inputadapter_isNull_0) {\n",
      "/* 065 */         project_mutableStateArray_0[0].setNullAt(0);\n",
      "/* 066 */       } else {\n",
      "/* 067 */         project_mutableStateArray_0[0].write(0, inputadapter_value_0);\n",
      "/* 068 */       }\n",
      "/* 069 */\n",
      "/* 070 */       if (inputadapter_isNull_1) {\n",
      "/* 071 */         project_mutableStateArray_0[0].setNullAt(1);\n",
      "/* 072 */       } else {\n",
      "/* 073 */         project_mutableStateArray_0[0].write(1, inputadapter_value_1);\n",
      "/* 074 */       }\n",
      "/* 075 */\n",
      "/* 076 */       if (inputadapter_isNull_2) {\n",
      "/* 077 */         project_mutableStateArray_0[0].setNullAt(2);\n",
      "/* 078 */       } else {\n",
      "/* 079 */         project_mutableStateArray_0[0].write(2, inputadapter_value_2);\n",
      "/* 080 */       }\n",
      "/* 081 */\n",
      "/* 082 */       if (inputadapter_isNull_3) {\n",
      "/* 083 */         project_mutableStateArray_0[0].setNullAt(3);\n",
      "/* 084 */       } else {\n",
      "/* 085 */         project_mutableStateArray_0[0].write(3, inputadapter_value_3);\n",
      "/* 086 */       }\n",
      "/* 087 */\n",
      "/* 088 */       if (inputadapter_isNull_4) {\n",
      "/* 089 */         project_mutableStateArray_0[0].setNullAt(4);\n",
      "/* 090 */       } else {\n",
      "/* 091 */         project_mutableStateArray_0[0].write(4, inputadapter_value_4);\n",
      "/* 092 */       }\n",
      "/* 093 */\n",
      "/* 094 */       if (inputadapter_isNull_5) {\n",
      "/* 095 */         project_mutableStateArray_0[0].setNullAt(5);\n",
      "/* 096 */       } else {\n",
      "/* 097 */         project_mutableStateArray_0[0].write(5, inputadapter_value_5);\n",
      "/* 098 */       }\n",
      "/* 099 */\n",
      "/* 100 */       if (inputadapter_isNull_6) {\n",
      "/* 101 */         project_mutableStateArray_0[0].setNullAt(6);\n",
      "/* 102 */       } else {\n",
      "/* 103 */         project_mutableStateArray_0[0].write(6, inputadapter_value_6);\n",
      "/* 104 */       }\n",
      "/* 105 */\n",
      "/* 106 */       if (inputadapter_isNull_7) {\n",
      "/* 107 */         project_mutableStateArray_0[0].setNullAt(7);\n",
      "/* 108 */       } else {\n",
      "/* 109 */         project_mutableStateArray_0[0].write(7, inputadapter_value_7);\n",
      "/* 110 */       }\n",
      "/* 111 */\n",
      "/* 112 */       if (inputadapter_isNull_8) {\n",
      "/* 113 */         project_mutableStateArray_0[0].setNullAt(8);\n",
      "/* 114 */       } else {\n",
      "/* 115 */         project_mutableStateArray_0[0].write(8, inputadapter_value_8);\n",
      "/* 116 */       }\n",
      "/* 117 */\n",
      "/* 118 */       if (inputadapter_isNull_9) {\n",
      "/* 119 */         project_mutableStateArray_0[0].setNullAt(9);\n",
      "/* 120 */       } else {\n",
      "/* 121 */         project_mutableStateArray_0[0].write(9, inputadapter_value_9);\n",
      "/* 122 */       }\n",
      "/* 123 */       append((project_mutableStateArray_0[0].getRow()));\n",
      "/* 124 */       if (shouldStop()) return;\n",
      "/* 125 */     }\n",
      "/* 126 */   }\n",
      "/* 127 */\n",
      "/* 128 */ }\n",
      "\n",
      "23/09/24 03:02:40 INFO CodeGenerator: Code generated in 15.097819 ms\n",
      "23/09/24 03:02:40 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 405.9 KiB, free 364.1 MiB)\n",
      "23/09/24 03:02:40 DEBUG BlockManager: Put block broadcast_7 locally took 2 ms\n",
      "23/09/24 03:02:40 DEBUG BlockManager: Putting block broadcast_7 without replication took 3 ms\n",
      "23/09/24 03:02:40 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 40.8 KiB, free 364.1 MiB)\n",
      "23/09/24 03:02:40 DEBUG BlockManagerMasterEndpoint: Updating block info on master broadcast_7_piece0 for BlockManagerId(driver, 172.18.0.5, 38339, None)\n",
      "23/09/24 03:02:40 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.18.0.5:38339 (size: 40.8 KiB, free: 366.1 MiB)\n",
      "23/09/24 03:02:40 DEBUG BlockManagerMaster: Updated info of block broadcast_7_piece0\n",
      "23/09/24 03:02:40 DEBUG BlockManager: Told master about block broadcast_7_piece0\n",
      "23/09/24 03:02:40 DEBUG BlockManager: Put block broadcast_7_piece0 locally took 1 ms\n",
      "23/09/24 03:02:40 DEBUG BlockManager: Putting block broadcast_7_piece0 without replication took 1 ms\n",
      "23/09/24 03:02:40 INFO SparkContext: Created broadcast 7 from head at /tmp/ipykernel_2252/3046943519.py:1\n",
      "23/09/24 03:02:40 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "23/09/24 03:02:40 DEBUG ClosureCleaner: Cleaning indylambda closure: $anonfun$doExecute$4$adapted\n",
      "23/09/24 03:02:40 DEBUG ClosureCleaner:  +++ indylambda closure ($anonfun$doExecute$4$adapted) is now cleaned +++\n",
      "23/09/24 03:02:40 DEBUG ClosureCleaner: Cleaning indylambda closure: $anonfun$executeTake$2\n",
      "23/09/24 03:02:40 DEBUG ClosureCleaner:  +++ indylambda closure ($anonfun$executeTake$2) is now cleaned +++\n",
      "23/09/24 03:02:40 DEBUG ClosureCleaner: Cleaning indylambda closure: $anonfun$runJob$5\n",
      "23/09/24 03:02:40 DEBUG ClosureCleaner:  +++ indylambda closure ($anonfun$runJob$5) is now cleaned +++\n",
      "23/09/24 03:02:40 INFO SparkContext: Starting job: head at /tmp/ipykernel_2252/3046943519.py:1\n",
      "23/09/24 03:02:40 DEBUG DAGScheduler: eagerlyComputePartitionsForRddAndAncestors for RDD 20 took 0.000086 seconds\n",
      "23/09/24 03:02:40 DEBUG DAGScheduler: Merging stage rdd profiles: Set()\n",
      "23/09/24 03:02:40 INFO DAGScheduler: Got job 3 (head at /tmp/ipykernel_2252/3046943519.py:1) with 1 output partitions\n",
      "23/09/24 03:02:40 INFO DAGScheduler: Final stage: ResultStage 3 (head at /tmp/ipykernel_2252/3046943519.py:1)\n",
      "23/09/24 03:02:40 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/09/24 03:02:40 INFO DAGScheduler: Missing parents: List()\n",
      "23/09/24 03:02:40 DEBUG DAGScheduler: submitStage(ResultStage 3 (name=head at /tmp/ipykernel_2252/3046943519.py:1;jobs=3))\n",
      "23/09/24 03:02:40 DEBUG DAGScheduler: missing: List()\n",
      "23/09/24 03:02:40 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[20] at head at /tmp/ipykernel_2252/3046943519.py:1), which has no missing parents\n",
      "23/09/24 03:02:40 DEBUG DAGScheduler: submitMissingTasks(ResultStage 3)\n",
      "23/09/24 03:02:40 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 16.6 KiB, free 364.0 MiB)\n",
      "23/09/24 03:02:40 DEBUG BlockManager: Put block broadcast_8 locally took 0 ms\n",
      "23/09/24 03:02:40 DEBUG BlockManager: Putting block broadcast_8 without replication took 0 ms\n",
      "23/09/24 03:02:40 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 7.4 KiB, free 364.0 MiB)\n",
      "23/09/24 03:02:40 DEBUG BlockManagerMasterEndpoint: Updating block info on master broadcast_8_piece0 for BlockManagerId(driver, 172.18.0.5, 38339, None)\n",
      "23/09/24 03:02:40 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.18.0.5:38339 (size: 7.4 KiB, free: 366.1 MiB)\n",
      "23/09/24 03:02:40 DEBUG BlockManagerMaster: Updated info of block broadcast_8_piece0\n",
      "23/09/24 03:02:40 DEBUG BlockManager: Told master about block broadcast_8_piece0\n",
      "23/09/24 03:02:40 DEBUG BlockManager: Put block broadcast_8_piece0 locally took 1 ms\n",
      "23/09/24 03:02:40 DEBUG BlockManager: Putting block broadcast_8_piece0 without replication took 1 ms\n",
      "23/09/24 03:02:40 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1513\n",
      "23/09/24 03:02:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[20] at head at /tmp/ipykernel_2252/3046943519.py:1) (first 15 tasks are for partitions Vector(0))\n",
      "23/09/24 03:02:40 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0\n",
      "23/09/24 03:02:40 DEBUG TaskSetManager: Epoch for TaskSet 3.0: 0\n",
      "23/09/24 03:02:40 DEBUG TaskSetManager: Adding pending tasks took 0 ms\n",
      "23/09/24 03:02:40 DEBUG TaskSetManager: Valid locality levels for TaskSet 3.0: NO_PREF, ANY\n",
      "23/09/24 03:02:40 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_3.0, runningTasks: 0\n",
      "23/09/24 03:02:40 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3) (172.18.0.8, executor 0, partition 0, PROCESS_LOCAL, 4898 bytes) taskResourceAssignments Map()\n",
      "23/09/24 03:02:40 DEBUG TaskSetManager: No tasks for locality level NO_PREF, so moving to locality level ANY\n",
      "23/09/24 03:02:40 DEBUG CoarseGrainedSchedulerBackend$DriverEndpoint: Launching task 3 on executor id: 0 hostname: 172.18.0.8.\n",
      "23/09/24 03:02:40 DEBUG BlockManager: Getting local block broadcast_8_piece0 as bytes\n",
      "23/09/24 03:02:40 DEBUG BlockManager: Level for block broadcast_8_piece0 is StorageLevel(disk, memory, 1 replicas)\n",
      "23/09/24 03:02:40 DEBUG BlockManagerMasterEndpoint: Updating block info on master broadcast_8_piece0 for BlockManagerId(0, 172.18.0.8, 42577, None)\n",
      "23/09/24 03:02:40 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.18.0.8:42577 (size: 7.4 KiB, free: 366.2 MiB)\n",
      "23/09/24 03:02:40 DEBUG BlockManager: Getting local block broadcast_7_piece0 as bytes\n",
      "23/09/24 03:02:40 DEBUG BlockManager: Level for block broadcast_7_piece0 is StorageLevel(disk, memory, 1 replicas)\n",
      "23/09/24 03:02:40 DEBUG BlockManagerMasterEndpoint: Updating block info on master broadcast_7_piece0 for BlockManagerId(0, 172.18.0.8, 42577, None)\n",
      "23/09/24 03:02:40 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.18.0.8:42577 (size: 40.8 KiB, free: 366.2 MiB)\n",
      "23/09/24 03:02:40 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 593 ms on 172.18.0.8 (executor 0) (1/1)\n",
      "23/09/24 03:02:40 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool \n",
      "23/09/24 03:02:40 INFO DAGScheduler: ResultStage 3 (head at /tmp/ipykernel_2252/3046943519.py:1) finished in 0.601 s\n",
      "23/09/24 03:02:40 DEBUG DAGScheduler: After removal of stage 3, remaining stages = 0\n",
      "23/09/24 03:02:40 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/09/24 03:02:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished\n",
      "23/09/24 03:02:40 INFO DAGScheduler: Job 3 finished: head at /tmp/ipykernel_2252/3046943519.py:1, took 0.651648 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Row(LatD='   41', LatM='    5',  \"LatS\"='   59',  \"NS\"=' \"N\"',  \"LonD\"='     80', LonM='   39',  \"LonS\"='    0',  \"EW\"=' \"W\"',  \"City\"=' \"Youngstown\"',  \"State\"=' OH')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manipulatedFrame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46aa6eea-04fc-4531-aaeb-d126190720df",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cleanCitiesDF' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m cleanCitiesDF\u001b[38;5;241m.\u001b[39mshow()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cleanCitiesDF' is not defined"
     ]
    }
   ],
   "source": [
    "cleanCitiesDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3fefb972-35cd-44b6-8947-64c881342c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/09/24 03:02:49 INFO FileSourceStrategy: Pushed Filters: \n",
      "23/09/24 03:02:49 INFO FileSourceStrategy: Post-Scan Filters: \n",
      "23/09/24 03:02:49 INFO FileSourceStrategy: Output Data Schema: struct< \"LatM\": string,  \"LonM\": string>\n",
      "23/09/24 03:02:49 DEBUG FileCommitProtocol: Creating committer org.apache.spark.internal.io.cloud.PathOutputCommitProtocol; job a16b3046-8bac-4911-b7eb-6c3a781668eb; output=s3a://cities/cleanCities4.csv; dynamic=false\n",
      "23/09/24 03:02:49 DEBUG FileCommitProtocol: Using (String, String, Boolean) constructor\n",
      "23/09/24 03:02:49 DEBUG IOStatisticsStoreImpl: Incrementing counter op_exists by 1 with final value 2\n",
      "23/09/24 03:02:49 DEBUG S3AFileSystem: Getting path status for s3a://cities/cleanCities4.csv  (cleanCities4.csv); needEmptyDirectory=false\n",
      "23/09/24 03:02:49 DEBUG S3AFileSystem: S3GetFileStatus s3a://cities/cleanCities4.csv\n",
      "23/09/24 03:02:49 DEBUG IOStatisticsStoreImpl: Incrementing counter object_metadata_request by 1 with final value 4\n",
      "23/09/24 03:02:49 DEBUG IOStatisticsStoreImpl: Incrementing counter action_http_head_request by 1 with final value 4\n",
      "23/09/24 03:02:49 DEBUG S3AFileSystem: HEAD cleanCities4.csv with change tracker null\n",
      "23/09/24 03:02:49 DEBUG request: Sending Request: HEAD http://minio:9000 /cities/cleanCities4.csv Headers: (amz-sdk-invocation-id: 17763d24-e621-414e-24fd-4ab313891910, Content-Type: application/octet-stream, User-Agent: Hadoop 3.3.2, aws-sdk-java/1.11.1026 Linux/6.1.44-060144-generic OpenJDK_64-Bit_Server_VM/25.345-b01 java/1.8.0_345 scala/2.12.15 vendor/BellSoft cfg/retry-mode/legacy, ) \n",
      "23/09/24 03:02:49 DEBUG AWS4Signer: AWS4 Canonical Request: '\"HEAD\n",
      "/cities/cleanCities4.csv\n",
      "\n",
      "amz-sdk-invocation-id:17763d24-e621-414e-24fd-4ab313891910\n",
      "amz-sdk-request:ttl=20230924T030609Z;attempt=1;max=21\n",
      "amz-sdk-retry:0/0/500\n",
      "content-type:application/octet-stream\n",
      "host:minio:9000\n",
      "user-agent:Hadoop 3.3.2, aws-sdk-java/1.11.1026 Linux/6.1.44-060144-generic OpenJDK_64-Bit_Server_VM/25.345-b01 java/1.8.0_345 scala/2.12.15 vendor/BellSoft cfg/retry-mode/legacy\n",
      "x-amz-content-sha256:e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\n",
      "x-amz-date:20230924T030249Z\n",
      "\n",
      "amz-sdk-invocation-id;amz-sdk-request;amz-sdk-retry;content-type;host;user-agent;x-amz-content-sha256;x-amz-date\n",
      "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\"\n",
      "23/09/24 03:02:49 DEBUG AWS4Signer: AWS4 String to Sign: '\"AWS4-HMAC-SHA256\n",
      "20230924T030249Z\n",
      "20230924/us-east-1/s3/aws4_request\n",
      "484e796cb403849f16be0be32b65173f0ad9d4114a934a233ec3e5c725b9a763\"\n",
      "23/09/24 03:02:49 DEBUG RequestAddCookies: CookieSpec selected: default\n",
      "23/09/24 03:02:49 DEBUG RequestAuthCache: Auth cache not set in the context\n",
      "23/09/24 03:02:49 DEBUG PoolingHttpClientConnectionManager: Connection request: [route: {}->http://minio:9000][total available: 1; route allocated: 1 of 96; total allocated: 1 of 96]\n",
      "23/09/24 03:02:49 DEBUG CPool: Connection [id:0][route:{}->http://minio:9000][state:null] expired @ Sun Sep 24 03:02:34 UTC 2023\n",
      "23/09/24 03:02:49 DEBUG DefaultManagedHttpClientConnection: http-outgoing-0: Close connection\n",
      "23/09/24 03:02:49 DEBUG PoolingHttpClientConnectionManager: Connection leased: [id: 1][route: {}->http://minio:9000][total available: 0; route allocated: 1 of 96; total allocated: 1 of 96]\n",
      "23/09/24 03:02:49 DEBUG MainClientExec: Opening connection {}->http://minio:9000\n",
      "23/09/24 03:02:49 DEBUG DefaultHttpClientConnectionOperator: Connecting to minio/172.18.0.3:9000\n",
      "23/09/24 03:02:49 DEBUG DefaultHttpClientConnectionOperator: Connection established 172.18.0.5:60076<->172.18.0.3:9000\n",
      "23/09/24 03:02:49 DEBUG DefaultManagedHttpClientConnection: http-outgoing-1: set socket timeout to 200000\n",
      "23/09/24 03:02:49 DEBUG MainClientExec: Executing request HEAD /cities/cleanCities4.csv HTTP/1.1\n",
      "23/09/24 03:02:49 DEBUG MainClientExec: Proxy auth state: UNCHALLENGED\n",
      "23/09/24 03:02:49 DEBUG headers: http-outgoing-1 >> HEAD /cities/cleanCities4.csv HTTP/1.1\n",
      "23/09/24 03:02:49 DEBUG headers: http-outgoing-1 >> Host: minio:9000\n",
      "23/09/24 03:02:49 DEBUG headers: http-outgoing-1 >> amz-sdk-invocation-id: 17763d24-e621-414e-24fd-4ab313891910\n",
      "23/09/24 03:02:49 DEBUG headers: http-outgoing-1 >> amz-sdk-request: ttl=20230924T030609Z;attempt=1;max=21\n",
      "23/09/24 03:02:49 DEBUG headers: http-outgoing-1 >> amz-sdk-retry: 0/0/500\n",
      "23/09/24 03:02:49 DEBUG headers: http-outgoing-1 >> Authorization: AWS4-HMAC-SHA256 Credential=minio-root-user/20230924/us-east-1/s3/aws4_request, SignedHeaders=amz-sdk-invocation-id;amz-sdk-request;amz-sdk-retry;content-type;host;user-agent;x-amz-content-sha256;x-amz-date, Signature=4de71a0bed3423cacef9be58ab2b940c010e54eef058ad4666fb5e3453732826\n",
      "23/09/24 03:02:49 DEBUG headers: http-outgoing-1 >> Content-Type: application/octet-stream\n",
      "23/09/24 03:02:49 DEBUG headers: http-outgoing-1 >> User-Agent: Hadoop 3.3.2, aws-sdk-java/1.11.1026 Linux/6.1.44-060144-generic OpenJDK_64-Bit_Server_VM/25.345-b01 java/1.8.0_345 scala/2.12.15 vendor/BellSoft cfg/retry-mode/legacy\n",
      "23/09/24 03:02:49 DEBUG headers: http-outgoing-1 >> x-amz-content-sha256: e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\n",
      "23/09/24 03:02:49 DEBUG headers: http-outgoing-1 >> X-Amz-Date: 20230924T030249Z\n",
      "23/09/24 03:02:49 DEBUG headers: http-outgoing-1 >> Connection: Keep-Alive\n",
      "23/09/24 03:02:49 DEBUG wire: http-outgoing-1 >> \"HEAD /cities/cleanCities4.csv HTTP/1.1[\\r][\\n]\"\n",
      "23/09/24 03:02:49 DEBUG wire: http-outgoing-1 >> \"Host: minio:9000[\\r][\\n]\"\n",
      "23/09/24 03:02:49 DEBUG wire: http-outgoing-1 >> \"amz-sdk-invocation-id: 17763d24-e621-414e-24fd-4ab313891910[\\r][\\n]\"\n",
      "23/09/24 03:02:49 DEBUG wire: http-outgoing-1 >> \"amz-sdk-request: ttl=20230924T030609Z;attempt=1;max=21[\\r][\\n]\"\n",
      "23/09/24 03:02:49 DEBUG wire: http-outgoing-1 >> \"amz-sdk-retry: 0/0/500[\\r][\\n]\"\n",
      "23/09/24 03:02:49 DEBUG wire: http-outgoing-1 >> \"Authorization: AWS4-HMAC-SHA256 Credential=minio-root-user/20230924/us-east-1/s3/aws4_request, SignedHeaders=amz-sdk-invocation-id;amz-sdk-request;amz-sdk-retry;content-type;host;user-agent;x-amz-content-sha256;x-amz-date, Signature=4de71a0bed3423cacef9be58ab2b940c010e54eef058ad4666fb5e3453732826[\\r][\\n]\"\n",
      "23/09/24 03:02:49 DEBUG wire: http-outgoing-1 >> \"Content-Type: application/octet-stream[\\r][\\n]\"\n",
      "23/09/24 03:02:49 DEBUG wire: http-outgoing-1 >> \"User-Agent: Hadoop 3.3.2, aws-sdk-java/1.11.1026 Linux/6.1.44-060144-generic OpenJDK_64-Bit_Server_VM/25.345-b01 java/1.8.0_345 scala/2.12.15 vendor/BellSoft cfg/retry-mode/legacy[\\r][\\n]\"\n",
      "23/09/24 03:02:49 DEBUG wire: http-outgoing-1 >> \"x-amz-content-sha256: e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855[\\r][\\n]\"\n",
      "23/09/24 03:02:49 DEBUG wire: http-outgoing-1 >> \"X-Amz-Date: 20230924T030249Z[\\r][\\n]\"\n",
      "23/09/24 03:02:49 DEBUG wire: http-outgoing-1 >> \"Connection: Keep-Alive[\\r][\\n]\"\n",
      "23/09/24 03:02:49 DEBUG wire: http-outgoing-1 >> \"[\\r][\\n]\"\n",
      "23/09/24 03:02:49 DEBUG wire: http-outgoing-1 << \"HTTP/1.1 404 Not Found[\\r][\\n]\"\n",
      "23/09/24 03:02:49 DEBUG wire: http-outgoing-1 << \"Accept-Ranges: bytes[\\r][\\n]\"\n",
      "23/09/24 03:02:49 DEBUG wire: http-outgoing-1 << \"Content-Length: 0[\\r][\\n]\"\n",
      "23/09/24 03:02:49 DEBUG wire: http-outgoing-1 << \"Content-Security-Policy: block-all-mixed-content[\\r][\\n]\"\n",
      "23/09/24 03:02:49 DEBUG wire: http-outgoing-1 << \"Server: MinIO[\\r][\\n]\"\n",
      "23/09/24 03:02:49 DEBUG wire: http-outgoing-1 << \"Strict-Transport-Security: max-age=31536000; includeSubDomains[\\r][\\n]\"\n",
      "23/09/24 03:02:49 DEBUG wire: http-outgoing-1 << \"Vary: Origin[\\r][\\n]\"\n",
      "23/09/24 03:02:49 DEBUG wire: http-outgoing-1 << \"Vary: Accept-Encoding[\\r][\\n]\"\n",
      "23/09/24 03:02:49 DEBUG wire: http-outgoing-1 << \"X-Amz-Request-Id: 1787B69CC6DAB98D[\\r][\\n]\"\n",
      "23/09/24 03:02:49 DEBUG wire: http-outgoing-1 << \"X-Content-Type-Options: nosniff[\\r][\\n]\"\n",
      "23/09/24 03:02:49 DEBUG wire: http-outgoing-1 << \"X-Xss-Protection: 1; mode=block[\\r][\\n]\"\n",
      "23/09/24 03:02:49 DEBUG wire: http-outgoing-1 << \"Date: Sun, 24 Sep 2023 03:02:49 GMT[\\r][\\n]\"\n",
      "23/09/24 03:02:49 DEBUG wire: http-outgoing-1 << \"[\\r][\\n]\"\n",
      "23/09/24 03:02:49 DEBUG headers: http-outgoing-1 << HTTP/1.1 404 Not Found\n",
      "23/09/24 03:02:49 DEBUG headers: http-outgoing-1 << Accept-Ranges: bytes\n",
      "23/09/24 03:02:49 DEBUG headers: http-outgoing-1 << Content-Length: 0\n",
      "23/09/24 03:02:49 DEBUG headers: http-outgoing-1 << Content-Security-Policy: block-all-mixed-content\n",
      "23/09/24 03:02:49 DEBUG headers: http-outgoing-1 << Server: MinIO\n",
      "23/09/24 03:02:49 DEBUG headers: http-outgoing-1 << Strict-Transport-Security: max-age=31536000; includeSubDomains\n",
      "23/09/24 03:02:49 DEBUG headers: http-outgoing-1 << Vary: Origin\n",
      "23/09/24 03:02:49 DEBUG headers: http-outgoing-1 << Vary: Accept-Encoding\n",
      "23/09/24 03:02:49 DEBUG headers: http-outgoing-1 << X-Amz-Request-Id: 1787B69CC6DAB98D\n",
      "23/09/24 03:02:49 DEBUG headers: http-outgoing-1 << X-Content-Type-Options: nosniff\n",
      "23/09/24 03:02:49 DEBUG headers: http-outgoing-1 << X-Xss-Protection: 1; mode=block\n",
      "23/09/24 03:02:49 DEBUG headers: http-outgoing-1 << Date: Sun, 24 Sep 2023 03:02:49 GMT\n",
      "23/09/24 03:02:49 DEBUG MainClientExec: Connection can be kept alive for 60000 MILLISECONDS\n",
      "23/09/24 03:02:49 DEBUG PoolingHttpClientConnectionManager: Connection [id: 1][route: {}->http://minio:9000] can be kept alive for 60.0 seconds\n",
      "23/09/24 03:02:49 DEBUG DefaultManagedHttpClientConnection: http-outgoing-1: set socket timeout to 0\n",
      "23/09/24 03:02:49 DEBUG PoolingHttpClientConnectionManager: Connection released: [id: 1][route: {}->http://minio:9000][total available: 1; route allocated: 1 of 96; total allocated: 1 of 96]\n",
      "23/09/24 03:02:49 DEBUG ClockSkewAdjuster: Reported server date (from 'Date' header): Sun, 24 Sep 2023 03:02:49 GMT\n",
      "23/09/24 03:02:49 DEBUG request: Received error response: com.amazonaws.services.s3.model.AmazonS3Exception: Not Found (Service: Amazon S3; Status Code: 404; Error Code: 404 Not Found; Request ID: 1787B69CC6DAB98D; S3 Extended Request ID: null; Proxy: null), S3 Extended Request ID: null\n",
      "23/09/24 03:02:49 DEBUG IOStatisticsStoreImpl: Incrementing counter store_io_request by 1 with final value 8\n",
      "23/09/24 03:02:49 DEBUG latency: ServiceName=[Amazon S3], AWSErrorCode=[404 Not Found], StatusCode=[404], ServiceEndpoint=[http://minio:9000], Exception=[com.amazonaws.services.s3.model.AmazonS3Exception: Not Found (Service: Amazon S3; Status Code: 404; Error Code: 404 Not Found; Request ID: 1787B69CC6DAB98D; S3 Extended Request ID: null; Proxy: null), S3 Extended Request ID: null], RequestType=[GetObjectMetadataRequest], AWSRequestID=[1787B69CC6DAB98D], HttpClientPoolPendingCount=0, RetryCapacityConsumed=0, HttpClientPoolAvailableCount=1, RequestCount=1, Exception=1, HttpClientPoolLeasedCount=0, ClientExecuteTime=[25.454], HttpClientSendRequestTime=[0.462], HttpRequestTime=[4.345], ApiCallLatency=[25.189], RequestSigningTime=[0.367], CredentialsRequestTime=[0.008, 0.004], HttpClientReceiveResponseTime=[1.34], \n",
      "23/09/24 03:02:49 DEBUG S3AFileSystem: LIST List cities:/cleanCities4.csv/ delimiter=/ keys=2 requester pays=false\n",
      "23/09/24 03:02:49 DEBUG S3AFileSystem: Starting: LIST\n",
      "23/09/24 03:02:49 DEBUG IOStatisticsStoreImpl: Incrementing counter object_list_request by 1 with final value 5\n",
      "23/09/24 03:02:49 DEBUG request: Sending Request: GET http://minio:9000 /cities/ Parameters: ({\"list-type\":[\"2\"],\"delimiter\":[\"/\"],\"max-keys\":[\"2\"],\"prefix\":[\"cleanCities4.csv/\"],\"fetch-owner\":[\"false\"]}Headers: (amz-sdk-invocation-id: 4ee64028-d459-808b-af74-664c9cb33db6, Content-Type: application/octet-stream, User-Agent: Hadoop 3.3.2, aws-sdk-java/1.11.1026 Linux/6.1.44-060144-generic OpenJDK_64-Bit_Server_VM/25.345-b01 java/1.8.0_345 scala/2.12.15 vendor/BellSoft cfg/retry-mode/legacy, ) \n",
      "23/09/24 03:02:49 DEBUG AWS4Signer: AWS4 Canonical Request: '\"GET\n",
      "/cities/\n",
      "delimiter=%2F&fetch-owner=false&list-type=2&max-keys=2&prefix=cleanCities4.csv%2F\n",
      "amz-sdk-invocation-id:4ee64028-d459-808b-af74-664c9cb33db6\n",
      "amz-sdk-request:ttl=20230924T030609Z;attempt=1;max=21\n",
      "amz-sdk-retry:0/0/500\n",
      "content-type:application/octet-stream\n",
      "host:minio:9000\n",
      "user-agent:Hadoop 3.3.2, aws-sdk-java/1.11.1026 Linux/6.1.44-060144-generic OpenJDK_64-Bit_Server_VM/25.345-b01 java/1.8.0_345 scala/2.12.15 vendor/BellSoft cfg/retry-mode/legacy\n",
      "x-amz-content-sha256:e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\n",
      "x-amz-date:20230924T030249Z\n",
      "\n",
      "amz-sdk-invocation-id;amz-sdk-request;amz-sdk-retry;content-type;host;user-agent;x-amz-content-sha256;x-amz-date\n",
      "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\"\n",
      "23/09/24 03:02:49 DEBUG AWS4Signer: AWS4 String to Sign: '\"AWS4-HMAC-SHA256\n",
      "20230924T030249Z\n",
      "20230924/us-east-1/s3/aws4_request\n",
      "b2e936894bcc4f0840a720fa29eead50a9683c9b72e4997a3d0701c996bdbe1d\"\n",
      "23/09/24 03:02:49 DEBUG RequestAddCookies: CookieSpec selected: default\n",
      "23/09/24 03:02:49 DEBUG RequestAuthCache: Auth cache not set in the context\n",
      "23/09/24 03:02:49 DEBUG PoolingHttpClientConnectionManager: Connection request: [route: {}->http://minio:9000][total available: 1; route allocated: 1 of 96; total allocated: 1 of 96]\n",
      "23/09/24 03:02:49 DEBUG PoolingHttpClientConnectionManager: Connection leased: [id: 1][route: {}->http://minio:9000][total available: 0; route allocated: 1 of 96; total allocated: 1 of 96]\n",
      "23/09/24 03:02:49 DEBUG DefaultManagedHttpClientConnection: http-outgoing-1: set socket timeout to 200000\n",
      "23/09/24 03:02:49 DEBUG DefaultManagedHttpClientConnection: http-outgoing-1: set socket timeout to 200000\n",
      "23/09/24 03:02:49 DEBUG MainClientExec: Executing request GET /cities/?list-type=2&delimiter=%2F&max-keys=2&prefix=cleanCities4.csv%2F&fetch-owner=false HTTP/1.1\n",
      "23/09/24 03:02:49 DEBUG MainClientExec: Proxy auth state: UNCHALLENGED\n",
      "23/09/24 03:02:49 DEBUG headers: http-outgoing-1 >> GET /cities/?list-type=2&delimiter=%2F&max-keys=2&prefix=cleanCities4.csv%2F&fetch-owner=false HTTP/1.1\n",
      "23/09/24 03:02:49 DEBUG headers: http-outgoing-1 >> Host: minio:9000\n",
      "23/09/24 03:02:49 DEBUG headers: http-outgoing-1 >> amz-sdk-invocation-id: 4ee64028-d459-808b-af74-664c9cb33db6\n",
      "23/09/24 03:02:49 DEBUG headers: http-outgoing-1 >> amz-sdk-request: ttl=20230924T030609Z;attempt=1;max=21\n",
      "23/09/24 03:02:49 DEBUG headers: http-outgoing-1 >> amz-sdk-retry: 0/0/500\n",
      "23/09/24 03:02:49 DEBUG headers: http-outgoing-1 >> Authorization: AWS4-HMAC-SHA256 Credential=minio-root-user/20230924/us-east-1/s3/aws4_request, SignedHeaders=amz-sdk-invocation-id;amz-sdk-request;amz-sdk-retry;content-type;host;user-agent;x-amz-content-sha256;x-amz-date, Signature=eb1f8b3934bdb9777d32930e4333413336453cb496f91b2bbf1b6e20fed44d61\n",
      "23/09/24 03:02:49 DEBUG headers: http-outgoing-1 >> Content-Type: application/octet-stream\n",
      "23/09/24 03:02:49 DEBUG headers: http-outgoing-1 >> User-Agent: Hadoop 3.3.2, aws-sdk-java/1.11.1026 Linux/6.1.44-060144-generic OpenJDK_64-Bit_Server_VM/25.345-b01 java/1.8.0_345 scala/2.12.15 vendor/BellSoft cfg/retry-mode/legacy\n",
      "23/09/24 03:02:49 DEBUG headers: http-outgoing-1 >> x-amz-content-sha256: e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\n",
      "23/09/24 03:02:49 DEBUG headers: http-outgoing-1 >> X-Amz-Date: 20230924T030249Z\n",
      "23/09/24 03:02:49 DEBUG headers: http-outgoing-1 >> Content-Length: 0\n",
      "23/09/24 03:02:49 DEBUG headers: http-outgoing-1 >> Connection: Keep-Alive\n",
      "23/09/24 03:02:49 DEBUG wire: http-outgoing-1 >> \"GET /cities/?list-type=2&delimiter=%2F&max-keys=2&prefix=cleanCities4.csv%2F&fetch-owner=false HTTP/1.1[\\r][\\n]\"\n",
      "23/09/24 03:02:49 DEBUG wire: http-outgoing-1 >> \"Host: minio:9000[\\r][\\n]\"\n",
      "23/09/24 03:02:49 DEBUG wire: http-outgoing-1 >> \"amz-sdk-invocation-id: 4ee64028-d459-808b-af74-664c9cb33db6[\\r][\\n]\"\n",
      "23/09/24 03:02:49 DEBUG wire: http-outgoing-1 >> \"amz-sdk-request: ttl=20230924T030609Z;attempt=1;max=21[\\r][\\n]\"\n",
      "23/09/24 03:02:49 DEBUG wire: http-outgoing-1 >> \"amz-sdk-retry: 0/0/500[\\r][\\n]\"\n",
      "23/09/24 03:02:49 DEBUG wire: http-outgoing-1 >> \"Authorization: AWS4-HMAC-SHA256 Credential=minio-root-user/20230924/us-east-1/s3/aws4_request, SignedHeaders=amz-sdk-invocation-id;amz-sdk-request;amz-sdk-retry;content-type;host;user-agent;x-amz-content-sha256;x-amz-date, Signature=eb1f8b3934bdb9777d32930e4333413336453cb496f91b2bbf1b6e20fed44d61[\\r][\\n]\"\n",
      "23/09/24 03:02:49 DEBUG wire: http-outgoing-1 >> \"Content-Type: application/octet-stream[\\r][\\n]\"\n",
      "23/09/24 03:02:49 DEBUG wire: http-outgoing-1 >> \"User-Agent: Hadoop 3.3.2, aws-sdk-java/1.11.1026 Linux/6.1.44-060144-generic OpenJDK_64-Bit_Server_VM/25.345-b01 java/1.8.0_345 scala/2.12.15 vendor/BellSoft cfg/retry-mode/legacy[\\r][\\n]\"\n",
      "23/09/24 03:02:49 DEBUG wire: http-outgoing-1 >> \"x-amz-content-sha256: e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855[\\r][\\n]\"\n",
      "23/09/24 03:02:49 DEBUG wire: http-outgoing-1 >> \"X-Amz-Date: 20230924T030249Z[\\r][\\n]\"\n",
      "23/09/24 03:02:49 DEBUG wire: http-outgoing-1 >> \"Content-Length: 0[\\r][\\n]\"\n",
      "23/09/24 03:02:49 DEBUG wire: http-outgoing-1 >> \"Connection: Keep-Alive[\\r][\\n]\"\n",
      "23/09/24 03:02:49 DEBUG wire: http-outgoing-1 >> \"[\\r][\\n]\"\n",
      "23/09/24 03:02:49 DEBUG wire: http-outgoing-1 << \"HTTP/1.1 200 OK[\\r][\\n]\"\n",
      "23/09/24 03:02:49 DEBUG wire: http-outgoing-1 << \"Accept-Ranges: bytes[\\r][\\n]\"\n",
      "23/09/24 03:02:49 DEBUG wire: http-outgoing-1 << \"Content-Length: 1003[\\r][\\n]\"\n",
      "23/09/24 03:02:49 DEBUG wire: http-outgoing-1 << \"Content-Security-Policy: block-all-mixed-content[\\r][\\n]\"\n",
      "23/09/24 03:02:49 DEBUG wire: http-outgoing-1 << \"Content-Type: application/xml[\\r][\\n]\"\n",
      "23/09/24 03:02:49 DEBUG wire: http-outgoing-1 << \"Server: MinIO[\\r][\\n]\"\n",
      "23/09/24 03:02:49 DEBUG wire: http-outgoing-1 << \"Strict-Transport-Security: max-age=31536000; includeSubDomains[\\r][\\n]\"\n",
      "23/09/24 03:02:49 DEBUG wire: http-outgoing-1 << \"Vary: Origin[\\r][\\n]\"\n",
      "23/09/24 03:02:49 DEBUG wire: http-outgoing-1 << \"Vary: Accept-Encoding[\\r][\\n]\"\n",
      "23/09/24 03:02:49 DEBUG wire: http-outgoing-1 << \"X-Amz-Request-Id: 1787B69CC87B164B[\\r][\\n]\"\n",
      "23/09/24 03:02:49 DEBUG wire: http-outgoing-1 << \"X-Content-Type-Options: nosniff[\\r][\\n]\"\n",
      "23/09/24 03:02:49 DEBUG wire: http-outgoing-1 << \"X-Xss-Protection: 1; mode=block[\\r][\\n]\"\n",
      "23/09/24 03:02:49 DEBUG wire: http-outgoing-1 << \"Date: Sun, 24 Sep 2023 03:02:49 GMT[\\r][\\n]\"\n",
      "23/09/24 03:02:49 DEBUG wire: http-outgoing-1 << \"[\\r][\\n]\"\n",
      "23/09/24 03:02:49 DEBUG wire: http-outgoing-1 << \"<?xml version=\"1.0\" encoding=\"UTF-8\"?>[\\n]\"\n",
      "23/09/24 03:02:49 DEBUG wire: http-outgoing-1 << \"<ListBucketResult xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\"><Name>cities</Name><Prefix>cleanCities4.csv/</Prefix><KeyCount>2</KeyCount><MaxKeys>2</MaxKeys><Delimiter>/</Delimiter><IsTruncated>false</IsTruncated><Contents><Key>cleanCities4.csv/_SUCCESS</Key><LastModified>2023-09-24T01:56:37.717Z</LastModified><ETag>&#34;67fbbdcde71226fde99ed7cafad7ebb3&#34;</ETag><Size>12077</Size><Owner><ID>02d6176db174dc93cb1b899f7c6078f08654445fe8cf1b6ce98d8855f66bdbf4</ID><DisplayName>minio</DisplayName></Owner><StorageClass>STANDARD</StorageClass></Contents><Contents><Key>cleanCities4.csv/part-00000-de16f836-9fc3-4065-ab19-0302a4291694-c000.csv</Key><LastModified>2023-09-24T01:56:37.624Z</LastModified><ETag>&#34;01723eb0a4534b895c04ec647dfa97e5-1&#34;</ETag><Size>737</Size><Owner><ID>02d6176db174dc93cb1b899f7c6078f08654445fe8cf1b6ce98d8855f66bdbf4</ID><DisplayName>minio</DisplayName></Owner><StorageClass>STANDARD</StorageClass></Contents></ListBucketResult>\"\n",
      "23/09/24 03:02:49 DEBUG headers: http-outgoing-1 << HTTP/1.1 200 OK\n",
      "23/09/24 03:02:49 DEBUG headers: http-outgoing-1 << Accept-Ranges: bytes\n",
      "23/09/24 03:02:49 DEBUG headers: http-outgoing-1 << Content-Length: 1003\n",
      "23/09/24 03:02:49 DEBUG headers: http-outgoing-1 << Content-Security-Policy: block-all-mixed-content\n",
      "23/09/24 03:02:49 DEBUG headers: http-outgoing-1 << Content-Type: application/xml\n",
      "23/09/24 03:02:49 DEBUG headers: http-outgoing-1 << Server: MinIO\n",
      "23/09/24 03:02:49 DEBUG headers: http-outgoing-1 << Strict-Transport-Security: max-age=31536000; includeSubDomains\n",
      "23/09/24 03:02:49 DEBUG headers: http-outgoing-1 << Vary: Origin\n",
      "23/09/24 03:02:49 DEBUG headers: http-outgoing-1 << Vary: Accept-Encoding\n",
      "23/09/24 03:02:49 DEBUG headers: http-outgoing-1 << X-Amz-Request-Id: 1787B69CC87B164B\n",
      "23/09/24 03:02:49 DEBUG headers: http-outgoing-1 << X-Content-Type-Options: nosniff\n",
      "23/09/24 03:02:49 DEBUG headers: http-outgoing-1 << X-Xss-Protection: 1; mode=block\n",
      "23/09/24 03:02:49 DEBUG headers: http-outgoing-1 << Date: Sun, 24 Sep 2023 03:02:49 GMT\n",
      "23/09/24 03:02:49 DEBUG MainClientExec: Connection can be kept alive for 60000 MILLISECONDS\n",
      "23/09/24 03:02:49 DEBUG ClockSkewAdjuster: Reported server date (from 'Date' header): Sun, 24 Sep 2023 03:02:49 GMT\n",
      "23/09/24 03:02:49 DEBUG XmlResponsesSaxParser: Sanitizing XML document destined for handler class com.amazonaws.services.s3.model.transform.XmlResponsesSaxParser$ListObjectsV2Handler\n",
      "23/09/24 03:02:49 DEBUG PoolingHttpClientConnectionManager: Connection [id: 1][route: {}->http://minio:9000] can be kept alive for 60.0 seconds\n",
      "23/09/24 03:02:49 DEBUG DefaultManagedHttpClientConnection: http-outgoing-1: set socket timeout to 0\n",
      "23/09/24 03:02:49 DEBUG PoolingHttpClientConnectionManager: Connection released: [id: 1][route: {}->http://minio:9000][total available: 1; route allocated: 1 of 96; total allocated: 1 of 96]\n",
      "23/09/24 03:02:49 DEBUG XmlResponsesSaxParser: Parsing XML response document with handler: class com.amazonaws.services.s3.model.transform.XmlResponsesSaxParser$ListObjectsV2Handler\n",
      "23/09/24 03:02:49 DEBUG XmlResponsesSaxParser: Examining listing for bucket: cities\n",
      "23/09/24 03:02:49 DEBUG request: Received successful response: 200, AWS Request ID: 1787B69CC87B164B\n",
      "23/09/24 03:02:49 DEBUG requestId: x-amzn-RequestId: not available\n",
      "23/09/24 03:02:49 DEBUG requestId: AWS Request ID: 1787B69CC87B164B\n",
      "23/09/24 03:02:49 DEBUG IOStatisticsStoreImpl: Incrementing counter store_io_request by 1 with final value 9\n",
      "23/09/24 03:02:49 DEBUG latency: ServiceName=[Amazon S3], StatusCode=[200], ServiceEndpoint=[http://minio:9000], RequestType=[ListObjectsV2Request], AWSRequestID=[1787B69CC87B164B], HttpClientPoolPendingCount=0, RetryCapacityConsumed=0, HttpClientPoolAvailableCount=1, RequestCount=1, HttpClientPoolLeasedCount=0, ResponseProcessingTime=[2.482], ClientExecuteTime=[9.664], HttpClientSendRequestTime=[0.697], HttpRequestTime=[5.726], ApiCallLatency=[9.411], RequestSigningTime=[0.347], CredentialsRequestTime=[0.009, 0.01], HttpClientReceiveResponseTime=[4.109], \n",
      "23/09/24 03:02:49 DEBUG S3AFileSystem: LIST: duration 0:00.010s\n",
      "23/09/24 03:02:49 DEBUG S3AFileSystem: Found path as directory (with /)\n",
      "23/09/24 03:02:49 DEBUG S3AFileSystem: Prefix count = 0; object count=2\n",
      "23/09/24 03:02:49 DEBUG S3AFileSystem: Summary: cleanCities4.csv/_SUCCESS 12077\n",
      "23/09/24 03:02:49 DEBUG S3AFileSystem: Summary: cleanCities4.csv/part-00000-de16f836-9fc3-4065-ab19-0302a4291694-c000.csv 737\n"
     ]
    },
    {
     "ename": "AnalysisException",
     "evalue": "path s3a://cities/cleanCities4.csv already exists.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m cleanCitiesDF\u001b[38;5;241m.\u001b[39mwrite\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39moption(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheader\u001b[39m\u001b[38;5;124m\"\u001b[39m,  \u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ms3a://cities/cleanCities4.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~opt/bitnami/spark/python/pyspark/sql/readwriter.py:968\u001b[0m, in \u001b[0;36mDataFrameWriter.save\u001b[0;34m(self, path, format, mode, partitionBy, **options)\u001b[0m\n\u001b[1;32m    966\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jwrite\u001b[38;5;241m.\u001b[39msave()\n\u001b[1;32m    967\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 968\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jwrite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~opt/bitnami/spark/venv/lib/python3.8/site-packages/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1315\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1316\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1320\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1321\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1322\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1325\u001b[0m     temp_arg\u001b[38;5;241m.\u001b[39m_detach()\n",
      "File \u001b[0;32m~opt/bitnami/spark/python/pyspark/sql/utils.py:196\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    192\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 196\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: path s3a://cities/cleanCities4.csv already exists."
     ]
    }
   ],
   "source": [
    "cleanCitiesDF.write.format(\"csv\").option(\"header\",  True).save(\"s3a://cities/cleanCities4.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61d3162c-9b1d-4837-a1be-c5a8689d16e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+\n",
      "|LatM|LonM|\n",
      "+----+----+\n",
      "|   5|  39|\n",
      "|  52|  23|\n",
      "|  35|  30|\n",
      "|  16|  48|\n",
      "|  37|  46|\n",
      "|   5|  15|\n",
      "|  52|   9|\n",
      "|  11|   9|\n",
      "|  14|  55|\n",
      "|  45|  33|\n",
      "|   9|  37|\n",
      "|  15|   0|\n",
      "|  40|  16|\n",
      "|  54|  29|\n",
      "|  41|  20|\n",
      "|   4|  43|\n",
      "|  43|   3|\n",
      "|  25|  19|\n",
      "|  25|  23|\n",
      "|  13|  20|\n",
      "+----+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "citiesDFRecovered = spark_sess.read.option(\"header\",True).csv('s3a://cities/cleanCities4.csv')\n",
    "citiesDFRecovered.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f907ab0-f89e-4741-87c0-de52d9bea7b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+------------------+\n",
      "|    name|      city|           stadium|\n",
      "+--------+----------+------------------+\n",
      "| Bengals|Cincinnati|Paul Brown Stadium|\n",
      "|Steelers|Pittsburgh|       Heinz Field|\n",
      "|  Browns| Cleveland| FirstEnergy Field|\n",
      "|  Ravens| Baltimore|  M&T Bank Stadium|\n",
      "+--------+----------+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "Team = Row(\"name\", \"city\", \"stadium\")\n",
    "afcNorth = [Team(\"Bengals\", \"Cincinnati\", \"Paul Brown Stadium\"),\n",
    "            Team(\"Steelers\", \"Pittsburgh\", \"Heinz Field\"),\n",
    "            Team(\"Browns\", \"Cleveland\", \"FirstEnergy Field\"),\n",
    "            Team(\"Ravens\", \"Baltimore\", \"M&T Bank Stadium\")]\n",
    "afcNorthDataFrame = spark_sess.createDataFrame(afcNorth)\n",
    "afcNorthDataFrame.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20d30c08-1b5f-4614-b075-2f47c534c5fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+\n",
      "| _1|    _2|\n",
      "+---+------+\n",
      "|  1|   One|\n",
      "| 30|Thirty|\n",
      "+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rdd = spark_ctxt.parallelize([(1, \"One\"), (30, \"Thirty\")])\n",
    "dfFromParallelize = rdd.toDF()\n",
    "dfFromParallelize.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87f932fc-8511-490d-8b5d-8489892d8a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType,StructField, StringType, IntegerType\n",
    "\n",
    "schema = StructType([ \\\n",
    "    StructField(\"number\",IntegerType(),True), \\\n",
    "    StructField(\"number_spelled\",StringType(),True) \\\n",
    "  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "228d1a20-c587-451c-af1f-28aca3b7c5a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------+\n",
      "|number|number_spelled|\n",
      "+------+--------------+\n",
      "|     1|           One|\n",
      "|    30|        Thirty|\n",
      "+------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "renewedDF = spark_sess.createDataFrame(rdd, schema)\n",
    "renewedDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "23a56ead-d312-435d-838a-9617625b04e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+--------------------+\n",
      "|                name|  artist|   well_known_lyrics|\n",
      "+--------------------+--------+--------------------+\n",
      "|Mary had a little...| Unknown|Mary had a little...|\n",
      "|Somebody's watchi...|Rockwell|I always fear abo...|\n",
      "|       Stayin' Alive|Bee Gees|Well, you can tel...|\n",
      "+--------------------+--------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Song = Row(\"name\", \"artist\", \"well_known_lyrics\")\n",
    "songs = [Song(\"Mary had a little lamb\", \"Unknown\", \"Mary had a little little lamb it's fleece was white as snow\"),\n",
    "            Song(\"Somebody's watching me\", \"Rockwell\", \"I always fear about it somebody watching me\"),\n",
    "            Song(\"Stayin' Alive\", \"Bee Gees\", \"Well, you can tell by the way I use my walkI'm a woman's man, no time to talk\")]\n",
    "songsDF = spark_sess.createDataFrame(songs)\n",
    "songsDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2aa5421c-8fd0-4e3c-94cb-a2010b7e025d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>artist</th>\n",
       "      <th>well_known_lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mary had a little lamb</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Mary had a little little lamb it's fleece was ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Somebody's watching me</td>\n",
       "      <td>Rockwell</td>\n",
       "      <td>I always fear about it somebody watching me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stayin' Alive</td>\n",
       "      <td>Bee Gees</td>\n",
       "      <td>Well, you can tell by the way I use my walkI'm...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     name    artist  \\\n",
       "0  Mary had a little lamb   Unknown   \n",
       "1  Somebody's watching me  Rockwell   \n",
       "2           Stayin' Alive  Bee Gees   \n",
       "\n",
       "                                   well_known_lyrics  \n",
       "0  Mary had a little little lamb it's fleece was ...  \n",
       "1        I always fear about it somebody watching me  \n",
       "2  Well, you can tell by the way I use my walkI'm...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songsDF.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7bac216a-40e0-47b9-bccc-29d038718321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+--------------------+-------------------+\n",
      "|                name|  artist|   well_known_lyrics|wellknownlyriccount|\n",
      "+--------------------+--------+--------------------+-------------------+\n",
      "|Mary had a little...| Unknown|Mary had a little...|                 12|\n",
      "|Somebody's watchi...|Rockwell|I always fear abo...|                  8|\n",
      "|       Stayin' Alive|Bee Gees|Well, you can tel...|                 18|\n",
      "+--------------------+--------+--------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "songsDF.withColumn('wellknownlyriccount', F.size(F.split(F.col('well_known_lyrics'), ' '))).show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d0459ba7-cf27-444f-ab0d-7a84759b3467",
   "metadata": {},
   "source": [
    "result = songsDF.rdd.map(lambda r: r['well_known_lyrics'].split(' ')) \n",
    "brokenout = result.toDF()\n",
    "brokenout.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "337c809f-fa8c-4990-8194-13218ab0a91a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[], [1, 3, 10, 103, 400], [], [900, 10000, 100009, 30000, 50000], []]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psdf = spark_ctxt.parallelize([1,3,10,103,400,900,10000,100009,30000,50000])\n",
    "psdf.getNumPartitions()\n",
    "psdf2 = psdf.repartition(5)\n",
    "psdf.getNumPartitions()\n",
    "psdf2.getNumPartitions()\n",
    "psdf2.glom().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7e4fb426-7b66-4b24-a135-c0e2e68f08fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+-------+-----+-------+-------+-------+-----+------------------+--------+\n",
      "| LatD| \"LatM\"| \"LatS\"| \"NS\"| \"LonD\"| \"LonM\"| \"LonS\"| \"EW\"|            \"City\"| \"State\"|\n",
      "+-----+-------+-------+-----+-------+-------+-------+-----+------------------+--------+\n",
      "|   41|      5|     59|  \"N\"|     80|     39|      0|  \"W\"|      \"Youngstown\"|      OH|\n",
      "|   42|     52|     48|  \"N\"|     97|     23|     23|  \"W\"|         \"Yankton\"|      SD|\n",
      "|   46|     35|     59|  \"N\"|    120|     30|     36|  \"W\"|          \"Yakima\"|      WA|\n",
      "|   42|     16|     12|  \"N\"|     71|     48|      0|  \"W\"|       \"Worcester\"|      MA|\n",
      "|   43|     37|     48|  \"N\"|     89|     46|     11|  \"W\"| \"Wisconsin Dells\"|      WI|\n",
      "|   36|      5|     59|  \"N\"|     80|     15|      0|  \"W\"|   \"Winston-Salem\"|      NC|\n",
      "|   49|     52|     48|  \"N\"|     97|      9|      0|  \"W\"|        \"Winnipeg\"|      MB|\n",
      "|   39|     11|     23|  \"N\"|     78|      9|     36|  \"W\"|      \"Winchester\"|      VA|\n",
      "|   34|     14|     24|  \"N\"|     77|     55|     11|  \"W\"|      \"Wilmington\"|      NC|\n",
      "|   39|     45|      0|  \"N\"|     75|     33|      0|  \"W\"|      \"Wilmington\"|      DE|\n",
      "|   48|      9|      0|  \"N\"|    103|     37|     12|  \"W\"|       \"Williston\"|      ND|\n",
      "|   41|     15|      0|  \"N\"|     77|      0|      0|  \"W\"|    \"Williamsport\"|      PA|\n",
      "|   37|     40|     48|  \"N\"|     82|     16|     47|  \"W\"|      \"Williamson\"|      WV|\n",
      "|   33|     54|      0|  \"N\"|     98|     29|     23|  \"W\"|   \"Wichita Falls\"|      TX|\n",
      "|   37|     41|     23|  \"N\"|     97|     20|     23|  \"W\"|         \"Wichita\"|      KS|\n",
      "|   40|      4|     11|  \"N\"|     80|     43|     12|  \"W\"|        \"Wheeling\"|      WV|\n",
      "|   26|     43|     11|  \"N\"|     80|      3|      0|  \"W\"| \"West Palm Beach\"|      FL|\n",
      "|   47|     25|     11|  \"N\"|    120|     19|     11|  \"W\"|       \"Wenatchee\"|      WA|\n",
      "|   41|     25|     11|  \"N\"|    122|     23|     23|  \"W\"|            \"Weed\"|      CA|\n",
      "|   31|     13|     11|  \"N\"|     82|     20|     59|  \"W\"|        \"Waycross\"|      GA|\n",
      "+-----+-------+-------+-----+-------+-------+-------+-----+------------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "citiesDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bff667da-2189-4027-805d-f7f90fb6dcdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LatD',\n",
       " ' \"LatM\"',\n",
       " ' \"LatS\"',\n",
       " ' \"NS\"',\n",
       " ' \"LonD\"',\n",
       " ' \"LonM\"',\n",
       " ' \"LonS\"',\n",
       " ' \"EW\"',\n",
       " ' \"City\"',\n",
       " ' \"State\"']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "citiesDF.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c748fc55-9317-43be-85e4-a311f9f24756",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Row(LatD='   41', LatM='    5',  \"LatS\"='   59',  \"NS\"=' \"N\"',  \"LonD\"='     80', LonM='   39',  \"LonS\"='    0',  \"EW\"=' \"W\"',  \"City\"=' \"Youngstown\"', State=' OH'),\n",
       "  Row(LatD='   42', LatM='   52',  \"LatS\"='   48',  \"NS\"=' \"N\"',  \"LonD\"='     97', LonM='   23',  \"LonS\"='   23',  \"EW\"=' \"W\"',  \"City\"=' \"Yankton\"', State=' SD'),\n",
       "  Row(LatD='   46', LatM='   35',  \"LatS\"='   59',  \"NS\"=' \"N\"',  \"LonD\"='    120', LonM='   30',  \"LonS\"='   36',  \"EW\"=' \"W\"',  \"City\"=' \"Yakima\"', State=' WA'),\n",
       "  Row(LatD='   42', LatM='   16',  \"LatS\"='   12',  \"NS\"=' \"N\"',  \"LonD\"='     71', LonM='   48',  \"LonS\"='    0',  \"EW\"=' \"W\"',  \"City\"=' \"Worcester\"', State=' MA'),\n",
       "  Row(LatD='   43', LatM='   37',  \"LatS\"='   48',  \"NS\"=' \"N\"',  \"LonD\"='     89', LonM='   46',  \"LonS\"='   11',  \"EW\"=' \"W\"',  \"City\"=' \"Wisconsin Dells\"', State=' WI'),\n",
       "  Row(LatD='   36', LatM='    5',  \"LatS\"='   59',  \"NS\"=' \"N\"',  \"LonD\"='     80', LonM='   15',  \"LonS\"='    0',  \"EW\"=' \"W\"',  \"City\"=' \"Winston-Salem\"', State=' NC'),\n",
       "  Row(LatD='   49', LatM='   52',  \"LatS\"='   48',  \"NS\"=' \"N\"',  \"LonD\"='     97', LonM='    9',  \"LonS\"='    0',  \"EW\"=' \"W\"',  \"City\"=' \"Winnipeg\"', State=' MB'),\n",
       "  Row(LatD='   39', LatM='   11',  \"LatS\"='   23',  \"NS\"=' \"N\"',  \"LonD\"='     78', LonM='    9',  \"LonS\"='   36',  \"EW\"=' \"W\"',  \"City\"=' \"Winchester\"', State=' VA'),\n",
       "  Row(LatD='   34', LatM='   14',  \"LatS\"='   24',  \"NS\"=' \"N\"',  \"LonD\"='     77', LonM='   55',  \"LonS\"='   11',  \"EW\"=' \"W\"',  \"City\"=' \"Wilmington\"', State=' NC'),\n",
       "  Row(LatD='   39', LatM='   45',  \"LatS\"='    0',  \"NS\"=' \"N\"',  \"LonD\"='     75', LonM='   33',  \"LonS\"='    0',  \"EW\"=' \"W\"',  \"City\"=' \"Wilmington\"', State=' DE'),\n",
       "  Row(LatD='   48', LatM='    9',  \"LatS\"='    0',  \"NS\"=' \"N\"',  \"LonD\"='    103', LonM='   37',  \"LonS\"='   12',  \"EW\"=' \"W\"',  \"City\"=' \"Williston\"', State=' ND'),\n",
       "  Row(LatD='   41', LatM='   15',  \"LatS\"='    0',  \"NS\"=' \"N\"',  \"LonD\"='     77', LonM='    0',  \"LonS\"='    0',  \"EW\"=' \"W\"',  \"City\"=' \"Williamsport\"', State=' PA'),\n",
       "  Row(LatD='   37', LatM='   40',  \"LatS\"='   48',  \"NS\"=' \"N\"',  \"LonD\"='     82', LonM='   16',  \"LonS\"='   47',  \"EW\"=' \"W\"',  \"City\"=' \"Williamson\"', State=' WV'),\n",
       "  Row(LatD='   33', LatM='   54',  \"LatS\"='    0',  \"NS\"=' \"N\"',  \"LonD\"='     98', LonM='   29',  \"LonS\"='   23',  \"EW\"=' \"W\"',  \"City\"=' \"Wichita Falls\"', State=' TX'),\n",
       "  Row(LatD='   37', LatM='   41',  \"LatS\"='   23',  \"NS\"=' \"N\"',  \"LonD\"='     97', LonM='   20',  \"LonS\"='   23',  \"EW\"=' \"W\"',  \"City\"=' \"Wichita\"', State=' KS'),\n",
       "  Row(LatD='   40', LatM='    4',  \"LatS\"='   11',  \"NS\"=' \"N\"',  \"LonD\"='     80', LonM='   43',  \"LonS\"='   12',  \"EW\"=' \"W\"',  \"City\"=' \"Wheeling\"', State=' WV'),\n",
       "  Row(LatD='   26', LatM='   43',  \"LatS\"='   11',  \"NS\"=' \"N\"',  \"LonD\"='     80', LonM='    3',  \"LonS\"='    0',  \"EW\"=' \"W\"',  \"City\"=' \"West Palm Beach\"', State=' FL'),\n",
       "  Row(LatD='   47', LatM='   25',  \"LatS\"='   11',  \"NS\"=' \"N\"',  \"LonD\"='    120', LonM='   19',  \"LonS\"='   11',  \"EW\"=' \"W\"',  \"City\"=' \"Wenatchee\"', State=' WA'),\n",
       "  Row(LatD='   41', LatM='   25',  \"LatS\"='   11',  \"NS\"=' \"N\"',  \"LonD\"='    122', LonM='   23',  \"LonS\"='   23',  \"EW\"=' \"W\"',  \"City\"=' \"Weed\"', State=' CA'),\n",
       "  Row(LatD='   31', LatM='   13',  \"LatS\"='   11',  \"NS\"=' \"N\"',  \"LonD\"='     82', LonM='   20',  \"LonS\"='   59',  \"EW\"=' \"W\"',  \"City\"=' \"Waycross\"', State=' GA'),\n",
       "  Row(LatD='   44', LatM='   57',  \"LatS\"='   35',  \"NS\"=' \"N\"',  \"LonD\"='     89', LonM='   38',  \"LonS\"='   23',  \"EW\"=' \"W\"',  \"City\"=' \"Wausau\"', State=' WI'),\n",
       "  Row(LatD='   42', LatM='   21',  \"LatS\"='   36',  \"NS\"=' \"N\"',  \"LonD\"='     87', LonM='   49',  \"LonS\"='   48',  \"EW\"=' \"W\"',  \"City\"=' \"Waukegan\"', State=' IL'),\n",
       "  Row(LatD='   44', LatM='   54',  \"LatS\"='    0',  \"NS\"=' \"N\"',  \"LonD\"='     97', LonM='    6',  \"LonS\"='   36',  \"EW\"=' \"W\"',  \"City\"=' \"Watertown\"', State=' SD'),\n",
       "  Row(LatD='   43', LatM='   58',  \"LatS\"='   47',  \"NS\"=' \"N\"',  \"LonD\"='     75', LonM='   55',  \"LonS\"='   11',  \"EW\"=' \"W\"',  \"City\"=' \"Watertown\"', State=' NY'),\n",
       "  Row(LatD='   42', LatM='   30',  \"LatS\"='    0',  \"NS\"=' \"N\"',  \"LonD\"='     92', LonM='   20',  \"LonS\"='   23',  \"EW\"=' \"W\"',  \"City\"=' \"Waterloo\"', State=' IA'),\n",
       "  Row(LatD='   41', LatM='   32',  \"LatS\"='   59',  \"NS\"=' \"N\"',  \"LonD\"='     73', LonM='    3',  \"LonS\"='    0',  \"EW\"=' \"W\"',  \"City\"=' \"Waterbury\"', State=' CT'),\n",
       "  Row(LatD='   38', LatM='   53',  \"LatS\"='   23',  \"NS\"=' \"N\"',  \"LonD\"='     77', LonM='    1',  \"LonS\"='   47',  \"EW\"=' \"W\"',  \"City\"=' \"Washington\"', State=' DC'),\n",
       "  Row(LatD='   41', LatM='   50',  \"LatS\"='   59',  \"NS\"=' \"N\"',  \"LonD\"='     79', LonM='    8',  \"LonS\"='   23',  \"EW\"=' \"W\"',  \"City\"=' \"Warren\"', State=' PA'),\n",
       "  Row(LatD='   46', LatM='    4',  \"LatS\"='   11',  \"NS\"=' \"N\"',  \"LonD\"='    118', LonM='   19',  \"LonS\"='   48',  \"EW\"=' \"W\"',  \"City\"=' \"Walla Walla\"', State=' WA'),\n",
       "  Row(LatD='   31', LatM='   32',  \"LatS\"='   59',  \"NS\"=' \"N\"',  \"LonD\"='     97', LonM='    8',  \"LonS\"='   23',  \"EW\"=' \"W\"',  \"City\"=' \"Waco\"', State=' TX'),\n",
       "  Row(LatD='   38', LatM='   40',  \"LatS\"='   48',  \"NS\"=' \"N\"',  \"LonD\"='     87', LonM='   31',  \"LonS\"='   47',  \"EW\"=' \"W\"',  \"City\"=' \"Vincennes\"', State=' IN'),\n",
       "  Row(LatD='   28', LatM='   48',  \"LatS\"='   35',  \"NS\"=' \"N\"',  \"LonD\"='     97', LonM='    0',  \"LonS\"='   36',  \"EW\"=' \"W\"',  \"City\"=' \"Victoria\"', State=' TX'),\n",
       "  Row(LatD='   32', LatM='   20',  \"LatS\"='   59',  \"NS\"=' \"N\"',  \"LonD\"='     90', LonM='   52',  \"LonS\"='   47',  \"EW\"=' \"W\"',  \"City\"=' \"Vicksburg\"', State=' MS'),\n",
       "  Row(LatD='   49', LatM='   16',  \"LatS\"='   12',  \"NS\"=' \"N\"',  \"LonD\"='    123', LonM='    7',  \"LonS\"='   12',  \"EW\"=' \"W\"',  \"City\"=' \"Vancouver\"', State=' BC'),\n",
       "  Row(LatD='   46', LatM='   55',  \"LatS\"='   11',  \"NS\"=' \"N\"',  \"LonD\"='     98', LonM='    0',  \"LonS\"='   36',  \"EW\"=' \"W\"',  \"City\"=' \"Valley City\"', State=' ND'),\n",
       "  Row(LatD='   30', LatM='   49',  \"LatS\"='   47',  \"NS\"=' \"N\"',  \"LonD\"='     83', LonM='   16',  \"LonS\"='   47',  \"EW\"=' \"W\"',  \"City\"=' \"Valdosta\"', State=' GA'),\n",
       "  Row(LatD='   43', LatM='    6',  \"LatS\"='   36',  \"NS\"=' \"N\"',  \"LonD\"='     75', LonM='   13',  \"LonS\"='   48',  \"EW\"=' \"W\"',  \"City\"=' \"Utica\"', State=' NY'),\n",
       "  Row(LatD='   39', LatM='   54',  \"LatS\"='    0',  \"NS\"=' \"N\"',  \"LonD\"='     79', LonM='   43',  \"LonS\"='   48',  \"EW\"=' \"W\"',  \"City\"=' \"Uniontown\"', State=' PA'),\n",
       "  Row(LatD='   32', LatM='   20',  \"LatS\"='   59',  \"NS\"=' \"N\"',  \"LonD\"='     95', LonM='   18',  \"LonS\"='    0',  \"EW\"=' \"W\"',  \"City\"=' \"Tyler\"', State=' TX'),\n",
       "  Row(LatD='   42', LatM='   33',  \"LatS\"='   36',  \"NS\"=' \"N\"',  \"LonD\"='    114', LonM='   28',  \"LonS\"='   12',  \"EW\"=' \"W\"',  \"City\"=' \"Twin Falls\"', State=' ID'),\n",
       "  Row(LatD='   33', LatM='   12',  \"LatS\"='   35',  \"NS\"=' \"N\"',  \"LonD\"='     87', LonM='   34',  \"LonS\"='   11',  \"EW\"=' \"W\"',  \"City\"=' \"Tuscaloosa\"', State=' AL'),\n",
       "  Row(LatD='   34', LatM='   15',  \"LatS\"='   35',  \"NS\"=' \"N\"',  \"LonD\"='     88', LonM='   42',  \"LonS\"='   35',  \"EW\"=' \"W\"',  \"City\"=' \"Tupelo\"', State=' MS'),\n",
       "  Row(LatD='   36', LatM='    9',  \"LatS\"='   35',  \"NS\"=' \"N\"',  \"LonD\"='     95', LonM='   54',  \"LonS\"='   36',  \"EW\"=' \"W\"',  \"City\"=' \"Tulsa\"', State=' OK'),\n",
       "  Row(LatD='   32', LatM='   13',  \"LatS\"='   12',  \"NS\"=' \"N\"',  \"LonD\"='    110', LonM='   58',  \"LonS\"='   12',  \"EW\"=' \"W\"',  \"City\"=' \"Tucson\"', State=' AZ'),\n",
       "  Row(LatD='   37', LatM='   10',  \"LatS\"='   11',  \"NS\"=' \"N\"',  \"LonD\"='    104', LonM='   30',  \"LonS\"='   36',  \"EW\"=' \"W\"',  \"City\"=' \"Trinidad\"', State=' CO'),\n",
       "  Row(LatD='   40', LatM='   13',  \"LatS\"='   47',  \"NS\"=' \"N\"',  \"LonD\"='     74', LonM='   46',  \"LonS\"='   11',  \"EW\"=' \"W\"',  \"City\"=' \"Trenton\"', State=' NJ'),\n",
       "  Row(LatD='   44', LatM='   45',  \"LatS\"='   35',  \"NS\"=' \"N\"',  \"LonD\"='     85', LonM='   37',  \"LonS\"='   47',  \"EW\"=' \"W\"',  \"City\"=' \"Traverse City\"', State=' MI'),\n",
       "  Row(LatD='   43', LatM='   39',  \"LatS\"='    0',  \"NS\"=' \"N\"',  \"LonD\"='     79', LonM='   22',  \"LonS\"='   47',  \"EW\"=' \"W\"',  \"City\"=' \"Toronto\"', State=' ON'),\n",
       "  Row(LatD='   39', LatM='    2',  \"LatS\"='   59',  \"NS\"=' \"N\"',  \"LonD\"='     95', LonM='   40',  \"LonS\"='   11',  \"EW\"=' \"W\"',  \"City\"=' \"Topeka\"', State=' KS'),\n",
       "  Row(LatD='   41', LatM='   39',  \"LatS\"='    0',  \"NS\"=' \"N\"',  \"LonD\"='     83', LonM='   32',  \"LonS\"='   24',  \"EW\"=' \"W\"',  \"City\"=' \"Toledo\"', State=' OH'),\n",
       "  Row(LatD='   33', LatM='   25',  \"LatS\"='   48',  \"NS\"=' \"N\"',  \"LonD\"='     94', LonM='    3',  \"LonS\"='    0',  \"EW\"=' \"W\"',  \"City\"=' \"Texarkana\"', State=' TX'),\n",
       "  Row(LatD='   39', LatM='   28',  \"LatS\"='   12',  \"NS\"=' \"N\"',  \"LonD\"='     87', LonM='   24',  \"LonS\"='   36',  \"EW\"=' \"W\"',  \"City\"=' \"Terre Haute\"', State=' IN'),\n",
       "  Row(LatD='   27', LatM='   57',  \"LatS\"='    0',  \"NS\"=' \"N\"',  \"LonD\"='     82', LonM='   26',  \"LonS\"='   59',  \"EW\"=' \"W\"',  \"City\"=' \"Tampa\"', State=' FL'),\n",
       "  Row(LatD='   30', LatM='   27',  \"LatS\"='    0',  \"NS\"=' \"N\"',  \"LonD\"='     84', LonM='   16',  \"LonS\"='   47',  \"EW\"=' \"W\"',  \"City\"=' \"Tallahassee\"', State=' FL'),\n",
       "  Row(LatD='   47', LatM='   14',  \"LatS\"='   24',  \"NS\"=' \"N\"',  \"LonD\"='    122', LonM='   25',  \"LonS\"='   48',  \"EW\"=' \"W\"',  \"City\"=' \"Tacoma\"', State=' WA'),\n",
       "  Row(LatD='   43', LatM='    2',  \"LatS\"='   59',  \"NS\"=' \"N\"',  \"LonD\"='     76', LonM='    9',  \"LonS\"='    0',  \"EW\"=' \"W\"',  \"City\"=' \"Syracuse\"', State=' NY'),\n",
       "  Row(LatD='   32', LatM='   35',  \"LatS\"='   59',  \"NS\"=' \"N\"',  \"LonD\"='     82', LonM='   20',  \"LonS\"='   23',  \"EW\"=' \"W\"',  \"City\"=' \"Swainsboro\"', State=' GA'),\n",
       "  Row(LatD='   33', LatM='   55',  \"LatS\"='   11',  \"NS\"=' \"N\"',  \"LonD\"='     80', LonM='   20',  \"LonS\"='   59',  \"EW\"=' \"W\"',  \"City\"=' \"Sumter\"', State=' SC'),\n",
       "  Row(LatD='   40', LatM='   59',  \"LatS\"='   24',  \"NS\"=' \"N\"',  \"LonD\"='     75', LonM='   11',  \"LonS\"='   24',  \"EW\"=' \"W\"',  \"City\"=' \"Stroudsburg\"', State=' PA'),\n",
       "  Row(LatD='   37', LatM='   57',  \"LatS\"='   35',  \"NS\"=' \"N\"',  \"LonD\"='    121', LonM='   17',  \"LonS\"='   24',  \"EW\"=' \"W\"',  \"City\"=' \"Stockton\"', State=' CA'),\n",
       "  Row(LatD='   44', LatM='   31',  \"LatS\"='   12',  \"NS\"=' \"N\"',  \"LonD\"='     89', LonM='   34',  \"LonS\"='   11',  \"EW\"=' \"W\"',  \"City\"=' \"Stevens Point\"', State=' WI'),\n",
       "  Row(LatD='   40', LatM='   21',  \"LatS\"='   36',  \"NS\"=' \"N\"',  \"LonD\"='     80', LonM='   37',  \"LonS\"='   12',  \"EW\"=' \"W\"',  \"City\"=' \"Steubenville\"', State=' OH'),\n",
       "  Row(LatD='   40', LatM='   37',  \"LatS\"='   11',  \"NS\"=' \"N\"',  \"LonD\"='    103', LonM='   13',  \"LonS\"='   12',  \"EW\"=' \"W\"',  \"City\"=' \"Sterling\"', State=' CO'),\n",
       "  Row(LatD='   38', LatM='    9',  \"LatS\"='    0',  \"NS\"=' \"N\"',  \"LonD\"='     79', LonM='    4',  \"LonS\"='   11',  \"EW\"=' \"W\"',  \"City\"=' \"Staunton\"', State=' VA'),\n",
       "  Row(LatD='   39', LatM='   55',  \"LatS\"='   11',  \"NS\"=' \"N\"',  \"LonD\"='     83', LonM='   48',  \"LonS\"='   35',  \"EW\"=' \"W\"',  \"City\"=' \"Springfield\"', State=' OH'),\n",
       "  Row(LatD='   37', LatM='   13',  \"LatS\"='   12',  \"NS\"=' \"N\"',  \"LonD\"='     93', LonM='   17',  \"LonS\"='   24',  \"EW\"=' \"W\"',  \"City\"=' \"Springfield\"', State=' MO'),\n",
       "  Row(LatD='   42', LatM='    5',  \"LatS\"='   59',  \"NS\"=' \"N\"',  \"LonD\"='     72', LonM='   35',  \"LonS\"='   23',  \"EW\"=' \"W\"',  \"City\"=' \"Springfield\"', State=' MA'),\n",
       "  Row(LatD='   39', LatM='   47',  \"LatS\"='   59',  \"NS\"=' \"N\"',  \"LonD\"='     89', LonM='   39',  \"LonS\"='    0',  \"EW\"=' \"W\"',  \"City\"=' \"Springfield\"', State=' IL'),\n",
       "  Row(LatD='   47', LatM='   40',  \"LatS\"='   11',  \"NS\"=' \"N\"',  \"LonD\"='    117', LonM='   24',  \"LonS\"='   36',  \"EW\"=' \"W\"',  \"City\"=' \"Spokane\"', State=' WA'),\n",
       "  Row(LatD='   41', LatM='   40',  \"LatS\"='   48',  \"NS\"=' \"N\"',  \"LonD\"='     86', LonM='   15',  \"LonS\"='    0',  \"EW\"=' \"W\"',  \"City\"=' \"South Bend\"', State=' IN'),\n",
       "  Row(LatD='   43', LatM='   32',  \"LatS\"='   24',  \"NS\"=' \"N\"',  \"LonD\"='     96', LonM='   43',  \"LonS\"='   48',  \"EW\"=' \"W\"',  \"City\"=' \"Sioux Falls\"', State=' SD'),\n",
       "  Row(LatD='   42', LatM='   29',  \"LatS\"='   24',  \"NS\"=' \"N\"',  \"LonD\"='     96', LonM='   23',  \"LonS\"='   23',  \"EW\"=' \"W\"',  \"City\"=' \"Sioux City\"', State=' IA'),\n",
       "  Row(LatD='   32', LatM='   30',  \"LatS\"='   35',  \"NS\"=' \"N\"',  \"LonD\"='     93', LonM='   45',  \"LonS\"='    0',  \"EW\"=' \"W\"',  \"City\"=' \"Shreveport\"', State=' LA'),\n",
       "  Row(LatD='   33', LatM='   38',  \"LatS\"='   23',  \"NS\"=' \"N\"',  \"LonD\"='     96', LonM='   36',  \"LonS\"='   36',  \"EW\"=' \"W\"',  \"City\"=' \"Sherman\"', State=' TX'),\n",
       "  Row(LatD='   44', LatM='   47',  \"LatS\"='   59',  \"NS\"=' \"N\"',  \"LonD\"='    106', LonM='   57',  \"LonS\"='   35',  \"EW\"=' \"W\"',  \"City\"=' \"Sheridan\"', State=' WY'),\n",
       "  Row(LatD='   35', LatM='   13',  \"LatS\"='   47',  \"NS\"=' \"N\"',  \"LonD\"='     96', LonM='   40',  \"LonS\"='   48',  \"EW\"=' \"W\"',  \"City\"=' \"Seminole\"', State=' OK'),\n",
       "  Row(LatD='   32', LatM='   25',  \"LatS\"='   11',  \"NS\"=' \"N\"',  \"LonD\"='     87', LonM='    1',  \"LonS\"='   11',  \"EW\"=' \"W\"',  \"City\"=' \"Selma\"', State=' AL'),\n",
       "  Row(LatD='   38', LatM='   42',  \"LatS\"='   35',  \"NS\"=' \"N\"',  \"LonD\"='     93', LonM='   13',  \"LonS\"='   48',  \"EW\"=' \"W\"',  \"City\"=' \"Sedalia\"', State=' MO'),\n",
       "  Row(LatD='   47', LatM='   35',  \"LatS\"='   59',  \"NS\"=' \"N\"',  \"LonD\"='    122', LonM='   19',  \"LonS\"='   48',  \"EW\"=' \"W\"',  \"City\"=' \"Seattle\"', State=' WA'),\n",
       "  Row(LatD='   41', LatM='   24',  \"LatS\"='   35',  \"NS\"=' \"N\"',  \"LonD\"='     75', LonM='   40',  \"LonS\"='   11',  \"EW\"=' \"W\"',  \"City\"=' \"Scranton\"', State=' PA'),\n",
       "  Row(LatD='   41', LatM='   52',  \"LatS\"='   11',  \"NS\"=' \"N\"',  \"LonD\"='    103', LonM='   39',  \"LonS\"='   36',  \"EW\"=' \"W\"',  \"City\"=' \"Scottsbluff\"', State=' NB'),\n",
       "  Row(LatD='   42', LatM='   49',  \"LatS\"='   11',  \"NS\"=' \"N\"',  \"LonD\"='     73', LonM='   56',  \"LonS\"='   59',  \"EW\"=' \"W\"',  \"City\"=' \"Schenectady\"', State=' NY'),\n",
       "  Row(LatD='   32', LatM='    4',  \"LatS\"='   48',  \"NS\"=' \"N\"',  \"LonD\"='     81', LonM='    5',  \"LonS\"='   23',  \"EW\"=' \"W\"',  \"City\"=' \"Savannah\"', State=' GA'),\n",
       "  Row(LatD='   46', LatM='   29',  \"LatS\"='   24',  \"NS\"=' \"N\"',  \"LonD\"='     84', LonM='   20',  \"LonS\"='   59',  \"EW\"=' \"W\"',  \"City\"=' \"Sault Sainte Marie\"', State=' MI'),\n",
       "  Row(LatD='   27', LatM='   20',  \"LatS\"='   24',  \"NS\"=' \"N\"',  \"LonD\"='     82', LonM='   31',  \"LonS\"='   47',  \"EW\"=' \"W\"',  \"City\"=' \"Sarasota\"', State=' FL'),\n",
       "  Row(LatD='   38', LatM='   26',  \"LatS\"='   23',  \"NS\"=' \"N\"',  \"LonD\"='    122', LonM='   43',  \"LonS\"='   12',  \"EW\"=' \"W\"',  \"City\"=' \"Santa Rosa\"', State=' CA'),\n",
       "  Row(LatD='   35', LatM='   40',  \"LatS\"='   48',  \"NS\"=' \"N\"',  \"LonD\"='    105', LonM='   56',  \"LonS\"='   59',  \"EW\"=' \"W\"',  \"City\"=' \"Santa Fe\"', State=' NM'),\n",
       "  Row(LatD='   34', LatM='   25',  \"LatS\"='   11',  \"NS\"=' \"N\"',  \"LonD\"='    119', LonM='   41',  \"LonS\"='   59',  \"EW\"=' \"W\"',  \"City\"=' \"Santa Barbara\"', State=' CA'),\n",
       "  Row(LatD='   33', LatM='   45',  \"LatS\"='   35',  \"NS\"=' \"N\"',  \"LonD\"='    117', LonM='   52',  \"LonS\"='   12',  \"EW\"=' \"W\"',  \"City\"=' \"Santa Ana\"', State=' CA'),\n",
       "  Row(LatD='   37', LatM='   20',  \"LatS\"='   24',  \"NS\"=' \"N\"',  \"LonD\"='    121', LonM='   52',  \"LonS\"='   47',  \"EW\"=' \"W\"',  \"City\"=' \"San Jose\"', State=' CA'),\n",
       "  Row(LatD='   37', LatM='   46',  \"LatS\"='   47',  \"NS\"=' \"N\"',  \"LonD\"='    122', LonM='   25',  \"LonS\"='   11',  \"EW\"=' \"W\"',  \"City\"=' \"San Francisco\"', State=' CA'),\n",
       "  Row(LatD='   41', LatM='   27',  \"LatS\"='    0',  \"NS\"=' \"N\"',  \"LonD\"='     82', LonM='   42',  \"LonS\"='   35',  \"EW\"=' \"W\"',  \"City\"=' \"Sandusky\"', State=' OH'),\n",
       "  Row(LatD='   32', LatM='   42',  \"LatS\"='   35',  \"NS\"=' \"N\"',  \"LonD\"='    117', LonM='    9',  \"LonS\"='    0',  \"EW\"=' \"W\"',  \"City\"=' \"San Diego\"', State=' CA'),\n",
       "  Row(LatD='   34', LatM='    6',  \"LatS\"='   36',  \"NS\"=' \"N\"',  \"LonD\"='    117', LonM='   18',  \"LonS\"='   35',  \"EW\"=' \"W\"',  \"City\"=' \"San Bernardino\"', State=' CA'),\n",
       "  Row(LatD='   29', LatM='   25',  \"LatS\"='   12',  \"NS\"=' \"N\"',  \"LonD\"='     98', LonM='   30',  \"LonS\"='    0',  \"EW\"=' \"W\"',  \"City\"=' \"San Antonio\"', State=' TX'),\n",
       "  Row(LatD='   31', LatM='   27',  \"LatS\"='   35',  \"NS\"=' \"N\"',  \"LonD\"='    100', LonM='   26',  \"LonS\"='   24',  \"EW\"=' \"W\"',  \"City\"=' \"San Angelo\"', State=' TX'),\n",
       "  Row(LatD='   40', LatM='   45',  \"LatS\"='   35',  \"NS\"=' \"N\"',  \"LonD\"='    111', LonM='   52',  \"LonS\"='   47',  \"EW\"=' \"W\"',  \"City\"=' \"Salt Lake City\"', State=' UT'),\n",
       "  Row(LatD='   38', LatM='   22',  \"LatS\"='   11',  \"NS\"=' \"N\"',  \"LonD\"='     75', LonM='   35',  \"LonS\"='   59',  \"EW\"=' \"W\"',  \"City\"=' \"Salisbury\"', State=' MD'),\n",
       "  Row(LatD='   36', LatM='   40',  \"LatS\"='   11',  \"NS\"=' \"N\"',  \"LonD\"='    121', LonM='   39',  \"LonS\"='    0',  \"EW\"=' \"W\"',  \"City\"=' \"Salinas\"', State=' CA'),\n",
       "  Row(LatD='   38', LatM='   50',  \"LatS\"='   24',  \"NS\"=' \"N\"',  \"LonD\"='     97', LonM='   36',  \"LonS\"='   36',  \"EW\"=' \"W\"',  \"City\"=' \"Salina\"', State=' KS'),\n",
       "  Row(LatD='   38', LatM='   31',  \"LatS\"='   47',  \"NS\"=' \"N\"',  \"LonD\"='    106', LonM='    0',  \"LonS\"='    0',  \"EW\"=' \"W\"',  \"City\"=' \"Salida\"', State=' CO'),\n",
       "  Row(LatD='   44', LatM='   56',  \"LatS\"='   23',  \"NS\"=' \"N\"',  \"LonD\"='    123', LonM='    1',  \"LonS\"='   47',  \"EW\"=' \"W\"',  \"City\"=' \"Salem\"', State=' OR'),\n",
       "  Row(LatD='   44', LatM='   57',  \"LatS\"='    0',  \"NS\"=' \"N\"',  \"LonD\"='     93', LonM='    5',  \"LonS\"='   59',  \"EW\"=' \"W\"',  \"City\"=' \"Saint Paul\"', State=' MN'),\n",
       "  Row(LatD='   38', LatM='   37',  \"LatS\"='   11',  \"NS\"=' \"N\"',  \"LonD\"='     90', LonM='   11',  \"LonS\"='   24',  \"EW\"=' \"W\"',  \"City\"=' \"Saint Louis\"', State=' MO'),\n",
       "  Row(LatD='   39', LatM='   46',  \"LatS\"='   12',  \"NS\"=' \"N\"',  \"LonD\"='     94', LonM='   50',  \"LonS\"='   23',  \"EW\"=' \"W\"',  \"City\"=' \"Saint Joseph\"', State=' MO'),\n",
       "  Row(LatD='   42', LatM='    5',  \"LatS\"='   59',  \"NS\"=' \"N\"',  \"LonD\"='     86', LonM='   28',  \"LonS\"='   48',  \"EW\"=' \"W\"',  \"City\"=' \"Saint Joseph\"', State=' MI'),\n",
       "  Row(LatD='   44', LatM='   25',  \"LatS\"='   11',  \"NS\"=' \"N\"',  \"LonD\"='     72', LonM='    1',  \"LonS\"='   11',  \"EW\"=' \"W\"',  \"City\"=' \"Saint Johnsbury\"', State=' VT'),\n",
       "  Row(LatD='   45', LatM='   34',  \"LatS\"='   11',  \"NS\"=' \"N\"',  \"LonD\"='     94', LonM='   10',  \"LonS\"='   11',  \"EW\"=' \"W\"',  \"City\"=' \"Saint Cloud\"', State=' MN'),\n",
       "  Row(LatD='   29', LatM='   53',  \"LatS\"='   23',  \"NS\"=' \"N\"',  \"LonD\"='     81', LonM='   19',  \"LonS\"='   11',  \"EW\"=' \"W\"',  \"City\"=' \"Saint Augustine\"', State=' FL'),\n",
       "  Row(LatD='   43', LatM='   25',  \"LatS\"='   48',  \"NS\"=' \"N\"',  \"LonD\"='     83', LonM='   56',  \"LonS\"='   24',  \"EW\"=' \"W\"',  \"City\"=' \"Saginaw\"', State=' MI'),\n",
       "  Row(LatD='   38', LatM='   35',  \"LatS\"='   24',  \"NS\"=' \"N\"',  \"LonD\"='    121', LonM='   29',  \"LonS\"='   23',  \"EW\"=' \"W\"',  \"City\"=' \"Sacramento\"', State=' CA'),\n",
       "  Row(LatD='   43', LatM='   36',  \"LatS\"='   36',  \"NS\"=' \"N\"',  \"LonD\"='     72', LonM='   58',  \"LonS\"='   12',  \"EW\"=' \"W\"',  \"City\"=' \"Rutland\"', State=' VT'),\n",
       "  Row(LatD='   33', LatM='   24',  \"LatS\"='    0',  \"NS\"=' \"N\"',  \"LonD\"='    104', LonM='   31',  \"LonS\"='   47',  \"EW\"=' \"W\"',  \"City\"=' \"Roswell\"', State=' NM'),\n",
       "  Row(LatD='   35', LatM='   56',  \"LatS\"='   23',  \"NS\"=' \"N\"',  \"LonD\"='     77', LonM='   48',  \"LonS\"='    0',  \"EW\"=' \"W\"',  \"City\"=' \"Rocky Mount\"', State=' NC'),\n",
       "  Row(LatD='   41', LatM='   35',  \"LatS\"='   24',  \"NS\"=' \"N\"',  \"LonD\"='    109', LonM='   13',  \"LonS\"='   48',  \"EW\"=' \"W\"',  \"City\"=' \"Rock Springs\"', State=' WY'),\n",
       "  Row(LatD='   42', LatM='   16',  \"LatS\"='   12',  \"NS\"=' \"N\"',  \"LonD\"='     89', LonM='    5',  \"LonS\"='   59',  \"EW\"=' \"W\"',  \"City\"=' \"Rockford\"', State=' IL'),\n",
       "  Row(LatD='   43', LatM='    9',  \"LatS\"='   35',  \"NS\"=' \"N\"',  \"LonD\"='     77', LonM='   36',  \"LonS\"='   36',  \"EW\"=' \"W\"',  \"City\"=' \"Rochester\"', State=' NY'),\n",
       "  Row(LatD='   44', LatM='    1',  \"LatS\"='   12',  \"NS\"=' \"N\"',  \"LonD\"='     92', LonM='   27',  \"LonS\"='   35',  \"EW\"=' \"W\"',  \"City\"=' \"Rochester\"', State=' MN'),\n",
       "  Row(LatD='   37', LatM='   16',  \"LatS\"='   12',  \"NS\"=' \"N\"',  \"LonD\"='     79', LonM='   56',  \"LonS\"='   24',  \"EW\"=' \"W\"',  \"City\"=' \"Roanoke\"', State=' VA'),\n",
       "  Row(LatD='   37', LatM='   32',  \"LatS\"='   24',  \"NS\"=' \"N\"',  \"LonD\"='     77', LonM='   26',  \"LonS\"='   59',  \"EW\"=' \"W\"',  \"City\"=' \"Richmond\"', State=' VA'),\n",
       "  Row(LatD='   39', LatM='   49',  \"LatS\"='   48',  \"NS\"=' \"N\"',  \"LonD\"='     84', LonM='   53',  \"LonS\"='   23',  \"EW\"=' \"W\"',  \"City\"=' \"Richmond\"', State=' IN'),\n",
       "  Row(LatD='   38', LatM='   46',  \"LatS\"='   12',  \"NS\"=' \"N\"',  \"LonD\"='    112', LonM='    5',  \"LonS\"='   23',  \"EW\"=' \"W\"',  \"City\"=' \"Richfield\"', State=' UT'),\n",
       "  Row(LatD='   45', LatM='   38',  \"LatS\"='   23',  \"NS\"=' \"N\"',  \"LonD\"='     89', LonM='   25',  \"LonS\"='   11',  \"EW\"=' \"W\"',  \"City\"=' \"Rhinelander\"', State=' WI'),\n",
       "  Row(LatD='   39', LatM='   31',  \"LatS\"='   12',  \"NS\"=' \"N\"',  \"LonD\"='    119', LonM='   48',  \"LonS\"='   35',  \"EW\"=' \"W\"',  \"City\"=' \"Reno\"', State=' NV'),\n",
       "  Row(LatD='   50', LatM='   25',  \"LatS\"='   11',  \"NS\"=' \"N\"',  \"LonD\"='    104', LonM='   39',  \"LonS\"='    0',  \"EW\"=' \"W\"',  \"City\"=' \"Regina\"', State=' SA'),\n",
       "  Row(LatD='   40', LatM='   10',  \"LatS\"='   48',  \"NS\"=' \"N\"',  \"LonD\"='    122', LonM='   14',  \"LonS\"='   23',  \"EW\"=' \"W\"',  \"City\"=' \"Red Bluff\"', State=' CA'),\n",
       "  Row(LatD='   40', LatM='   19',  \"LatS\"='   48',  \"NS\"=' \"N\"',  \"LonD\"='     75', LonM='   55',  \"LonS\"='   48',  \"EW\"=' \"W\"',  \"City\"=' \"Reading\"', State=' PA'),\n",
       "  Row(LatD='   41', LatM='    9',  \"LatS\"='   35',  \"NS\"=' \"N\"',  \"LonD\"='     81', LonM='   14',  \"LonS\"='   23',  \"EW\"=' \"W\"',  \"City\"=' \"Ravenna\"', State=' OH ')]]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleanedCitiesDF = citiesDF \\\n",
    "   .withColumnRenamed(' \"LatM\"', 'LatM') \\\n",
    "   .withColumnRenamed(' \"LonM\"', 'LonM') \\\n",
    "   .withColumnRenamed(' \"State\"', 'State')\n",
    "\n",
    "cleanedCitiesDF.rdd.glom().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e01c352e-8bf6-4669-b17a-e5872873e957",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partitionedRange = cleanedCitiesDF.repartitionByRange(10, \"State\")\n",
    "partitionedRange.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "359333cf-fd1a-48d2-8181-582a05590e99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[' CA',\n",
       "  ' BC',\n",
       "  ' AL',\n",
       "  ' AZ',\n",
       "  ' CA',\n",
       "  ' AL',\n",
       "  ' CA',\n",
       "  ' CA',\n",
       "  ' CA',\n",
       "  ' CA',\n",
       "  ' CA',\n",
       "  ' CA',\n",
       "  ' CA',\n",
       "  ' CA',\n",
       "  ' CA',\n",
       "  ' CA'],\n",
       " [' DE', ' FL', ' CT', ' DC', ' CO', ' FL', ' FL', ' CO', ' FL', ' CO', ' FL'],\n",
       " [' GA',\n",
       "  ' IL',\n",
       "  ' IA',\n",
       "  ' IN',\n",
       "  ' GA',\n",
       "  ' ID',\n",
       "  ' IN',\n",
       "  ' GA',\n",
       "  ' IL',\n",
       "  ' IN',\n",
       "  ' IA',\n",
       "  ' GA',\n",
       "  ' IL',\n",
       "  ' IN'],\n",
       " [' MA',\n",
       "  ' MB',\n",
       "  ' KS',\n",
       "  ' MI',\n",
       "  ' KS',\n",
       "  ' MA',\n",
       "  ' LA',\n",
       "  ' MI',\n",
       "  ' MD',\n",
       "  ' KS',\n",
       "  ' MI',\n",
       "  ' MI'],\n",
       " [' NC',\n",
       "  ' NC',\n",
       "  ' MS',\n",
       "  ' MS',\n",
       "  ' MO',\n",
       "  ' MO',\n",
       "  ' NB',\n",
       "  ' MN',\n",
       "  ' MO',\n",
       "  ' MO',\n",
       "  ' MN',\n",
       "  ' NC',\n",
       "  ' MN'],\n",
       " [' ND', ' NY', ' ND', ' NY', ' NJ', ' NY', ' NY', ' NM', ' NM', ' NY', ' NV'],\n",
       " [' OH',\n",
       "  ' PA',\n",
       "  ' PA',\n",
       "  ' PA',\n",
       "  ' OK',\n",
       "  ' ON',\n",
       "  ' OH',\n",
       "  ' PA',\n",
       "  ' OH',\n",
       "  ' OH',\n",
       "  ' OK',\n",
       "  ' PA',\n",
       "  ' OH',\n",
       "  ' OR',\n",
       "  ' PA',\n",
       "  ' OH '],\n",
       " [' SD',\n",
       "  ' TX',\n",
       "  ' SD',\n",
       "  ' TX',\n",
       "  ' TX',\n",
       "  ' TX',\n",
       "  ' TX',\n",
       "  ' SC',\n",
       "  ' SD',\n",
       "  ' TX',\n",
       "  ' TX',\n",
       "  ' TX',\n",
       "  ' SA'],\n",
       " [' WA',\n",
       "  ' VA',\n",
       "  ' WA',\n",
       "  ' WA',\n",
       "  ' WA',\n",
       "  ' VA',\n",
       "  ' WA',\n",
       "  ' WA',\n",
       "  ' UT',\n",
       "  ' VT',\n",
       "  ' VT',\n",
       "  ' VA',\n",
       "  ' VA',\n",
       "  ' UT'],\n",
       " [' WI', ' WV', ' WV', ' WI', ' WI', ' WY', ' WY', ' WI']]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "partitionedRange.rdd.map(lambda r: r['State']).glom().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f21d7a73-e0fd-49e5-a813-4a6f3fbe5957",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[' CA',\n",
       "  ' BC',\n",
       "  ' AL',\n",
       "  ' AZ',\n",
       "  ' CA',\n",
       "  ' AL',\n",
       "  ' CA',\n",
       "  ' CA',\n",
       "  ' CA',\n",
       "  ' CA',\n",
       "  ' CA',\n",
       "  ' CA',\n",
       "  ' CA',\n",
       "  ' CA',\n",
       "  ' CA',\n",
       "  ' CA',\n",
       "  ' MA',\n",
       "  ' MB',\n",
       "  ' KS',\n",
       "  ' MI',\n",
       "  ' KS',\n",
       "  ' MA',\n",
       "  ' LA',\n",
       "  ' MI',\n",
       "  ' MD',\n",
       "  ' KS',\n",
       "  ' MI',\n",
       "  ' MI',\n",
       "  ' OH',\n",
       "  ' PA',\n",
       "  ' PA',\n",
       "  ' PA',\n",
       "  ' OK',\n",
       "  ' ON',\n",
       "  ' OH',\n",
       "  ' PA',\n",
       "  ' OH',\n",
       "  ' OH',\n",
       "  ' OK',\n",
       "  ' PA',\n",
       "  ' OH',\n",
       "  ' OR',\n",
       "  ' PA',\n",
       "  ' OH ',\n",
       "  ' WI',\n",
       "  ' WV',\n",
       "  ' WV',\n",
       "  ' WI',\n",
       "  ' WI',\n",
       "  ' WY',\n",
       "  ' WY',\n",
       "  ' WI'],\n",
       " [' DE',\n",
       "  ' FL',\n",
       "  ' CT',\n",
       "  ' DC',\n",
       "  ' CO',\n",
       "  ' FL',\n",
       "  ' FL',\n",
       "  ' CO',\n",
       "  ' FL',\n",
       "  ' CO',\n",
       "  ' FL',\n",
       "  ' NC',\n",
       "  ' NC',\n",
       "  ' MS',\n",
       "  ' MS',\n",
       "  ' MO',\n",
       "  ' MO',\n",
       "  ' NB',\n",
       "  ' MN',\n",
       "  ' MO',\n",
       "  ' MO',\n",
       "  ' MN',\n",
       "  ' NC',\n",
       "  ' MN',\n",
       "  ' SD',\n",
       "  ' TX',\n",
       "  ' SD',\n",
       "  ' TX',\n",
       "  ' TX',\n",
       "  ' TX',\n",
       "  ' TX',\n",
       "  ' SC',\n",
       "  ' SD',\n",
       "  ' TX',\n",
       "  ' TX',\n",
       "  ' TX',\n",
       "  ' SA'],\n",
       " [' GA',\n",
       "  ' IL',\n",
       "  ' IA',\n",
       "  ' IN',\n",
       "  ' GA',\n",
       "  ' ID',\n",
       "  ' IN',\n",
       "  ' GA',\n",
       "  ' IL',\n",
       "  ' IN',\n",
       "  ' IA',\n",
       "  ' GA',\n",
       "  ' IL',\n",
       "  ' IN',\n",
       "  ' ND',\n",
       "  ' NY',\n",
       "  ' ND',\n",
       "  ' NY',\n",
       "  ' NJ',\n",
       "  ' NY',\n",
       "  ' NY',\n",
       "  ' NM',\n",
       "  ' NM',\n",
       "  ' NY',\n",
       "  ' NV',\n",
       "  ' WA',\n",
       "  ' VA',\n",
       "  ' WA',\n",
       "  ' WA',\n",
       "  ' WA',\n",
       "  ' VA',\n",
       "  ' WA',\n",
       "  ' WA',\n",
       "  ' UT',\n",
       "  ' VT',\n",
       "  ' VT',\n",
       "  ' VA',\n",
       "  ' VA',\n",
       "  ' UT']]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partitionedRange.coalesce(3).rdd.map(lambda r: r['State']).glom().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5662514-453f-4f96-9cb8-acec886a81bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/09/24 04:48:08 INFO SparkUI: Stopped Spark web UI at http://172.18.0.4:4040\n",
      "23/09/24 04:48:08 INFO StandaloneSchedulerBackend: Shutting down all executors\n",
      "23/09/24 04:48:08 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down\n",
      "23/09/24 04:48:08 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!\n",
      "23/09/24 04:48:08 INFO MemoryStore: MemoryStore cleared\n",
      "23/09/24 04:48:08 INFO BlockManager: BlockManager stopped\n",
      "23/09/24 04:48:09 INFO BlockManagerMaster: BlockManagerMaster stopped\n",
      "23/09/24 04:48:09 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!\n",
      "23/09/24 04:48:09 DEBUG PoolThreadCache: Freed 16 thread-local buffer(s) from thread: rpc-server-4-1\n",
      "23/09/24 04:48:09 DEBUG PoolThreadCache: Freed 3 thread-local buffer(s) from thread: rpc-server-4-3\n",
      "23/09/24 04:48:09 DEBUG PoolThreadCache: Freed 3 thread-local buffer(s) from thread: rpc-server-4-2\n",
      "23/09/24 04:48:09 DEBUG PoolThreadCache: Freed 15 thread-local buffer(s) from thread: rpc-server-4-8\n",
      "23/09/24 04:48:09 DEBUG PoolThreadCache: Freed 15 thread-local buffer(s) from thread: rpc-server-4-7\n",
      "23/09/24 04:48:09 INFO SparkContext: Successfully stopped SparkContext\n",
      "23/09/24 04:48:10 DEBUG PoolThreadCache: Freed 4 thread-local buffer(s) from thread: shuffle-server-7-2\n",
      "23/09/24 04:48:10 DEBUG PoolThreadCache: Freed 4 thread-local buffer(s) from thread: shuffle-server-7-1\n",
      "23/09/24 04:48:10 DEBUG PoolThreadCache: Freed 8 thread-local buffer(s) from thread: rpc-server-4-5\n",
      "23/09/24 04:48:10 DEBUG PoolThreadCache: Freed 8 thread-local buffer(s) from thread: rpc-server-4-6\n",
      "23/09/24 04:48:10 DEBUG PoolThreadCache: Freed 6 thread-local buffer(s) from thread: rpc-server-4-4\n"
     ]
    }
   ],
   "source": [
    "spark_sess.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
