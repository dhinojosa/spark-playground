{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23e65a46-8e57-42ac-a75a-1248b765b739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/opt/bitnami/spark/jars/ivy-2.5.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /root/.ivy2/cache\n",
      "The jars for the packages stored in: /root/.ivy2/jars\n",
      "org.apache.hadoop#hadoop-aws added as a dependency\n",
      "com.amazonaws#aws-java-sdk-bundle added as a dependency\n",
      "org.apache.spark#spark-hadoop-cloud_2.12 added as a dependency\n",
      "org.apache.spark#spark-sql-kafka-0-10_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-b9f53e47-1a76-4869-8f4f-65a3934e6f56;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.apache.hadoop#hadoop-aws;3.2.0 in central\n",
      "\tfound com.amazonaws#aws-java-sdk-bundle;1.11.704 in central\n",
      "\tfound org.apache.spark#spark-hadoop-cloud_2.12;3.3.0 in central\n",
      "\tfound org.apache.hadoop#hadoop-client-runtime;3.3.2 in central\n",
      "\tfound org.apache.hadoop#hadoop-client-api;3.3.2 in central\n",
      "\tfound org.xerial.snappy#snappy-java;1.1.8.4 in central\n",
      "\tfound org.slf4j#slf4j-api;1.7.32 in central\n",
      "\tfound commons-logging#commons-logging;1.1.3 in central\n",
      "\tfound com.google.code.findbugs#jsr305;3.0.0 in central\n",
      "\tfound org.apache.hadoop#hadoop-aws;3.3.2 in central\n",
      "\tfound com.amazonaws#aws-java-sdk-bundle;1.11.1026 in central\n",
      "\tfound org.wildfly.openssl#wildfly-openssl;1.0.7.Final in central\n",
      "\tfound org.apache.hadoop#hadoop-openstack;3.3.2 in central\n",
      "\tfound org.apache.hadoop#hadoop-annotations;3.3.2 in central\n",
      "\tfound org.apache.httpcomponents#httpcore;4.4.14 in central\n",
      "\tfound com.fasterxml.jackson.core#jackson-annotations;2.13.3 in central\n",
      "\tfound com.fasterxml.jackson.core#jackson-databind;2.13.3 in central\n",
      "\tfound com.fasterxml.jackson.core#jackson-core;2.13.3 in central\n",
      "\tfound joda-time#joda-time;2.10.13 in central\n",
      "\tfound com.fasterxml.jackson.dataformat#jackson-dataformat-cbor;2.13.3 in central\n",
      "\tfound org.apache.httpcomponents#httpclient;4.5.13 in central\n",
      "\tfound commons-codec#commons-codec;1.15 in central\n",
      "\tfound org.apache.hadoop#hadoop-azure;3.3.2 in central\n",
      "\tfound com.microsoft.azure#azure-storage;7.0.1 in central\n",
      "\tfound com.microsoft.azure#azure-keyvault-core;1.0.0 in central\n",
      "\tfound org.apache.hadoop.thirdparty#hadoop-shaded-guava;1.1.1 in central\n",
      "\tfound org.codehaus.jackson#jackson-mapper-asl;1.9.13 in central\n",
      "\tfound org.codehaus.jackson#jackson-core-asl;1.9.13 in central\n",
      "\tfound org.apache.hadoop#hadoop-cloud-storage;3.3.2 in central\n",
      "\tfound org.apache.hadoop#hadoop-aliyun;3.3.2 in central\n",
      "\tfound com.aliyun.oss#aliyun-sdk-oss;3.13.0 in central\n",
      "\tfound org.jdom#jdom2;2.0.6 in central\n",
      "\tfound org.codehaus.jettison#jettison;1.1 in central\n",
      "\tfound stax#stax-api;1.0.1 in central\n",
      "\tfound com.aliyun#aliyun-java-sdk-core;4.5.10 in central\n",
      "\tfound com.google.code.gson#gson;2.8.9 in central\n",
      "\tfound javax.xml.bind#jaxb-api;2.2.11 in central\n",
      "\tfound org.ini4j#ini4j;0.5.4 in central\n",
      "\tfound io.opentracing#opentracing-api;0.33.0 in central\n",
      "\tfound io.opentracing#opentracing-util;0.33.0 in central\n",
      "\tfound io.opentracing#opentracing-noop;0.33.0 in central\n",
      "\tfound com.aliyun#aliyun-java-sdk-ram;3.1.0 in central\n",
      "\tfound com.aliyun#aliyun-java-sdk-kms;2.11.0 in central\n",
      "\tfound org.apache.hadoop#hadoop-azure-datalake;3.3.2 in central\n",
      "\tfound com.microsoft.azure#azure-data-lake-store-sdk;2.3.9 in central\n",
      "\tfound org.apache.hadoop#hadoop-cos;3.3.2 in central\n",
      "\tfound com.qcloud#cos_api-bundle;5.6.19 in central\n",
      "\tfound org.eclipse.jetty#jetty-util-ajax;9.4.46.v20220331 in central\n",
      "\tfound org.eclipse.jetty#jetty-util;9.4.46.v20220331 in central\n",
      "\tfound org.spark-project.spark#unused;1.0.0 in central\n",
      "\tfound org.apache.spark#spark-sql-kafka-0-10_2.12;3.3.0 in central\n",
      "\tfound org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.3.0 in central\n",
      "\tfound org.apache.kafka#kafka-clients;2.8.1 in central\n",
      "\tfound org.lz4#lz4-java;1.8.0 in central\n",
      "\tfound org.apache.commons#commons-pool2;2.11.1 in central\n",
      ":: resolution report :: resolve 4138ms :: artifacts dl 108ms\n",
      "\t:: modules in use:\n",
      "\tcom.aliyun#aliyun-java-sdk-core;4.5.10 from central in [default]\n",
      "\tcom.aliyun#aliyun-java-sdk-kms;2.11.0 from central in [default]\n",
      "\tcom.aliyun#aliyun-java-sdk-ram;3.1.0 from central in [default]\n",
      "\tcom.aliyun.oss#aliyun-sdk-oss;3.13.0 from central in [default]\n",
      "\tcom.amazonaws#aws-java-sdk-bundle;1.11.1026 from central in [default]\n",
      "\tcom.fasterxml.jackson.core#jackson-annotations;2.13.3 from central in [default]\n",
      "\tcom.fasterxml.jackson.core#jackson-core;2.13.3 from central in [default]\n",
      "\tcom.fasterxml.jackson.core#jackson-databind;2.13.3 from central in [default]\n",
      "\tcom.fasterxml.jackson.dataformat#jackson-dataformat-cbor;2.13.3 from central in [default]\n",
      "\tcom.google.code.findbugs#jsr305;3.0.0 from central in [default]\n",
      "\tcom.google.code.gson#gson;2.8.9 from central in [default]\n",
      "\tcom.microsoft.azure#azure-data-lake-store-sdk;2.3.9 from central in [default]\n",
      "\tcom.microsoft.azure#azure-keyvault-core;1.0.0 from central in [default]\n",
      "\tcom.microsoft.azure#azure-storage;7.0.1 from central in [default]\n",
      "\tcom.qcloud#cos_api-bundle;5.6.19 from central in [default]\n",
      "\tcommons-codec#commons-codec;1.15 from central in [default]\n",
      "\tcommons-logging#commons-logging;1.1.3 from central in [default]\n",
      "\tio.opentracing#opentracing-api;0.33.0 from central in [default]\n",
      "\tio.opentracing#opentracing-noop;0.33.0 from central in [default]\n",
      "\tio.opentracing#opentracing-util;0.33.0 from central in [default]\n",
      "\tjavax.xml.bind#jaxb-api;2.2.11 from central in [default]\n",
      "\tjoda-time#joda-time;2.10.13 from central in [default]\n",
      "\torg.apache.commons#commons-pool2;2.11.1 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-aliyun;3.3.2 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-annotations;3.3.2 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-aws;3.3.2 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-azure;3.3.2 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-azure-datalake;3.3.2 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-client-api;3.3.2 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-client-runtime;3.3.2 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-cloud-storage;3.3.2 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-cos;3.3.2 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-openstack;3.3.2 from central in [default]\n",
      "\torg.apache.hadoop.thirdparty#hadoop-shaded-guava;1.1.1 from central in [default]\n",
      "\torg.apache.httpcomponents#httpclient;4.5.13 from central in [default]\n",
      "\torg.apache.httpcomponents#httpcore;4.4.14 from central in [default]\n",
      "\torg.apache.kafka#kafka-clients;2.8.1 from central in [default]\n",
      "\torg.apache.spark#spark-hadoop-cloud_2.12;3.3.0 from central in [default]\n",
      "\torg.apache.spark#spark-sql-kafka-0-10_2.12;3.3.0 from central in [default]\n",
      "\torg.apache.spark#spark-token-provider-kafka-0-10_2.12;3.3.0 from central in [default]\n",
      "\torg.codehaus.jackson#jackson-core-asl;1.9.13 from central in [default]\n",
      "\torg.codehaus.jackson#jackson-mapper-asl;1.9.13 from central in [default]\n",
      "\torg.codehaus.jettison#jettison;1.1 from central in [default]\n",
      "\torg.eclipse.jetty#jetty-util;9.4.46.v20220331 from central in [default]\n",
      "\torg.eclipse.jetty#jetty-util-ajax;9.4.46.v20220331 from central in [default]\n",
      "\torg.ini4j#ini4j;0.5.4 from central in [default]\n",
      "\torg.jdom#jdom2;2.0.6 from central in [default]\n",
      "\torg.lz4#lz4-java;1.8.0 from central in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.32 from central in [default]\n",
      "\torg.spark-project.spark#unused;1.0.0 from central in [default]\n",
      "\torg.wildfly.openssl#wildfly-openssl;1.0.7.Final from central in [default]\n",
      "\torg.xerial.snappy#snappy-java;1.1.8.4 from central in [default]\n",
      "\tstax#stax-api;1.0.1 from central in [default]\n",
      "\t:: evicted modules:\n",
      "\torg.apache.hadoop#hadoop-aws;3.2.0 by [org.apache.hadoop#hadoop-aws;3.3.2] in [default]\n",
      "\tcom.amazonaws#aws-java-sdk-bundle;1.11.375 by [com.amazonaws#aws-java-sdk-bundle;1.11.704] in [default]\n",
      "\tcom.amazonaws#aws-java-sdk-bundle;1.11.704 by [com.amazonaws#aws-java-sdk-bundle;1.11.1026] in [default]\n",
      "\torg.eclipse.jetty#jetty-util-ajax;9.4.43.v20210629 by [org.eclipse.jetty#jetty-util-ajax;9.4.46.v20220331] in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   57  |   0   |   0   |   4   ||   53  |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-b9f53e47-1a76-4869-8f4f-65a3934e6f56\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 53 already retrieved (0kB/99ms)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/09/24 04:01:41 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "from pyspark.conf import SparkConf\n",
    "from pyspark.sql import SparkSession, Catalog\n",
    "from pyspark.sql import DataFrame, DataFrameStatFunctions, DataFrameNaFunctions\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import types as T\n",
    "from pyspark.sql.types import Row\n",
    "from subprocess import check_output\n",
    "\n",
    "SPARK_DRIVER_HOST = check_output([\"hostname\", \"-i\"]).decode(encoding=\"utf-8\").strip()\n",
    "spark_conf = SparkConf()\n",
    "spark_conf.setAll([\n",
    "    ('spark.master', 'spark://spark:7077'),\n",
    "    ('spark.app.name', 'read_write_kafka'),\n",
    "    ('spark.submit.deployMode', 'client'),\n",
    "    ('spark.ui.showConsoleProgress', 'true'),\n",
    "    ('spark.eventLog.enabled', 'false'),\n",
    "    ('spark.logConf', 'false'),\n",
    "    ('spark.driver.bindAddress', '0.0.0.0'),\n",
    "    ('spark.driver.host', SPARK_DRIVER_HOST),\n",
    "    ('spark.jars.packages', 'org.apache.hadoop:hadoop-aws:3.2.0,com.amazonaws:aws-java-sdk-bundle:1.11.704,org.apache.spark:spark-hadoop-cloud_2.12:3.3.0,org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.0'),\n",
    "    (\"spark.hadoop.fs.s3a.endpoint\", 'http://minio:9000'),\n",
    "    ('spark.hadoop.fs.s3a.access.key', 'minio-root-user'),\n",
    "    ('spark.hadoop.fs.s3a.secret.key', 'minio-root-password'),\n",
    "    ('spark.hadoop.fs.s3a.bucket.all.committer.magic.enabled', True),\n",
    "    (\"spark.hadoop.fs.s3a.fast.upload\", True),\n",
    "    (\"spark.hadoop.fs.s3a.path.style.access\", True),\n",
    "    (\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\")\n",
    "])\n",
    " \n",
    "spark_sess          = SparkSession.builder.config(conf=spark_conf).getOrCreate()\n",
    "spark_ctxt          = spark_sess.sparkContext\n",
    "spark_reader        = spark_sess.read\n",
    "spark_streamReader  = spark_sess.readStream\n",
    "spark_ctxt.setLogLevel(\"WARN\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "152f7d25-db75-4794-a5c7-b5351f231201",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark_sess \\\n",
    "    .readStream \\\n",
    "    .format(\"kafka\") \\\n",
    "    .option(\"kafka.bootstrap.servers\", \"kafka:9092\") \\\n",
    "    .option(\"subscribe\", \"word-processor\") \\\n",
    "    .option(\"startingOffsets\", \"earliest\") \\\n",
    "    .load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd04c11e-8d5a-44c6-870f-b6edd0fa066a",
   "metadata": {},
   "outputs": [],
   "source": [
    "asString = df.selectExpr(\"CAST(key AS STRING)\", \"CAST(value AS STRING)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "349e1bf9-a778-4b1d-b2f6-04f4dd4dcd05",
   "metadata": {},
   "outputs": [],
   "source": [
    "newFrame = asString.withColumn(\"wordCount\", F.size(F.split(F.col('value'), ' ')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a58c6acd-878e-44cb-817e-16e79b1c11aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/09/24 04:02:05 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties\n",
      "23/09/24 04:02:07 WARN ResolveWriteToStream: spark.sql.adaptive.enabled is not supported in streaming DataFrames/Datasets and will be disabled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:KeyboardInterrupt while sending command.                             \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/bitnami/spark/venv/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/opt/bitnami/spark/venv/lib/python3.8/site-packages/py4j/clientserver.py\", line 511, in send_command\n",
      "    answer = smart_decode(self.stream.readline()[:-1])\n",
      "  File \"/opt/bitnami/python/lib/python3.8/socket.py\", line 669, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m newFrame\u001b[38;5;241m.\u001b[39mwriteStream \\\n\u001b[1;32m      2\u001b[0m         \u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjson\u001b[39m\u001b[38;5;124m\"\u001b[39m) \\\n\u001b[1;32m      3\u001b[0m         \u001b[38;5;241m.\u001b[39moutputMode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mappend\u001b[39m\u001b[38;5;124m\"\u001b[39m) \\\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;241m.\u001b[39moption(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcheckpointLocation\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms3a://kafka-checkpoint/checkpoint\u001b[39m\u001b[38;5;124m'\u001b[39m) \\\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;241m.\u001b[39moption(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpath\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ms3a://kafka-output/output.json\u001b[39m\u001b[38;5;124m\"\u001b[39m) \\\n\u001b[1;32m      6\u001b[0m         \u001b[38;5;241m.\u001b[39mstart() \\\n\u001b[1;32m      7\u001b[0m         \u001b[38;5;241m.\u001b[39mawaitTermination()\n",
      "File \u001b[0;32m~opt/bitnami/spark/python/pyspark/sql/streaming.py:107\u001b[0m, in \u001b[0;36mStreamingQuery.awaitTermination\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jsq\u001b[38;5;241m.\u001b[39mawaitTermination(\u001b[38;5;28mint\u001b[39m(timeout \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1000\u001b[39m))\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 107\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jsq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mawaitTermination\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~opt/bitnami/spark/venv/lib/python3.8/site-packages/py4j/java_gateway.py:1320\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1313\u001b[0m args_command, temp_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_args(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m   1315\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1316\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m-> 1320\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1321\u001b[0m return_value \u001b[38;5;241m=\u001b[39m get_return_value(\n\u001b[1;32m   1322\u001b[0m     answer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n",
      "File \u001b[0;32m~opt/bitnami/spark/venv/lib/python3.8/site-packages/py4j/java_gateway.py:1038\u001b[0m, in \u001b[0;36mGatewayClient.send_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1036\u001b[0m connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_connection()\n\u001b[1;32m   1037\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1038\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1039\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m binary:\n\u001b[1;32m   1040\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m response, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_connection_guard(connection)\n",
      "File \u001b[0;32m~opt/bitnami/spark/venv/lib/python3.8/site-packages/py4j/clientserver.py:511\u001b[0m, in \u001b[0;36mClientServerConnection.send_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    510\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 511\u001b[0m         answer \u001b[38;5;241m=\u001b[39m smart_decode(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    512\u001b[0m         logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnswer received: \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(answer))\n\u001b[1;32m    513\u001b[0m         \u001b[38;5;66;03m# Happens when a the other end is dead. There might be an empty\u001b[39;00m\n\u001b[1;32m    514\u001b[0m         \u001b[38;5;66;03m# answer before the socket raises an error.\u001b[39;00m\n",
      "File \u001b[0;32m~opt/bitnami/python/lib/python3.8/socket.py:669\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    667\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    668\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 669\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    670\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    671\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "newFrame.writeStream \\\n",
    "        .format(\"json\") \\\n",
    "        .outputMode(\"append\") \\\n",
    "        .option(\"checkpointLocation\", 's3a://kafka-checkpoint/checkpoint') \\\n",
    "        .option(\"path\", \"s3a://kafka-output/output.json\") \\\n",
    "        .start() \\\n",
    "        .awaitTermination()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a35daca-b9d2-46d3-a027-2435bc28e6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_sess.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.14"
  },
  "vscode": {
   "interpreter": {
    "hash": "9ac03a0a6051494cc606d484d27d20fce22fb7b4d169f583271e11d5ba46a56e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
