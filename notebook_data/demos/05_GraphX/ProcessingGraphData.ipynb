{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be00730-aad3-4627-bac3-75f0cd774981",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "from pyspark.conf import SparkConf\n",
    "from pyspark.sql import SparkSession, Catalog\n",
    "from pyspark.sql import DataFrame, DataFrameStatFunctions, DataFrameNaFunctions\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import types as T\n",
    "from pyspark.sql.types import Row\n",
    "from subprocess import check_output\n",
    "\n",
    "SPARK_DRIVER_HOST = check_output([\"hostname\", \"-i\"]).decode(encoding=\"utf-8\").strip()\n",
    "spark_conf = SparkConf()\n",
    "spark_conf.setAll([\n",
    "    ('spark.master', 'spark://spark:7077'),\n",
    "    ('spark.app.name', 'myApp'),\n",
    "    ('spark.submit.deployMode', 'client'),\n",
    "    ('spark.ui.showConsoleProgress', 'true'),\n",
    "    ('spark.eventLog.enabled', 'false'),\n",
    "    ('spark.logConf', 'false'),\n",
    "    ('spark.driver.bindAddress', '0.0.0.0'),\n",
    "    ('spark.driver.host', SPARK_DRIVER_HOST),\n",
    "    ('spark.jars.packages', 'org.apache.hadoop:hadoop-aws:3.2.0,com.amazonaws:aws-java-sdk-bundle:1.11.704,org.apache.spark:spark-hadoop-cloud_2.12:3.3.0'),\n",
    "    (\"spark.hadoop.fs.s3a.endpoint\", 'http://minio:9000'),\n",
    "    ('spark.hadoop.fs.s3a.access.key', 'minio-root-user'),\n",
    "    ('spark.hadoop.fs.s3a.secret.key', 'minio-root-password'),\n",
    "    ('spark.hadoop.fs.s3a.bucket.all.committer.magic.enabled', True),\n",
    "    (\"spark.hadoop.fs.s3a.fast.upload\", True),\n",
    "    (\"spark.hadoop.fs.s3a.path.style.access\", True),\n",
    "    (\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\")\n",
    "])\n",
    " \n",
    "spark_sess          = SparkSession.builder.config(conf=spark_conf).getOrCreate()\n",
    "spark_ctxt          = spark_sess.sparkContext\n",
    "spark_reader        = spark_sess.read\n",
    "spark_streamReader  = spark_sess.readStream\n",
    "spark_ctxt.setLogLevel(\"WARN\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae927d90-9782-4076-884e-a0aac7b083eb",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected character after line continuation character (2157633864.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn [4], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    (3, (\"rxin\", \"student\")),\\\u001b[0m\n\u001b[0m                               \n^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected character after line continuation character\n"
     ]
    }
   ],
   "source": [
    "users =\\\n",
    "    spark_ctxt.parallelize([\\\n",
    "      (3, (\"rxin\", \"student\")),\\ \n",
    "      (7, (\"jgonzal\", \"postdoc\")),\\\n",
    "      (5, (\"franklin\", \"prof\")),\\\n",
    "      (2, (\"istoica\", \"prof\")),\\\n",
    "      (4, (\"peter\", \"student\"))])\n",
    "\n",
    "relationships = \\\n",
    "    spark_ctxt.parallelize([\n",
    "      Edge(3, 7, \"collab\"),    Edge(5, 3, \"advisor\"), \\\n",
    "      Edge(2, 5, \"colleague\"), Edge(5, 7, \"pi\"), \\\n",
    "      Edge(4, 0, \"student\"),   Edge(5, 0, \"colleague\"))\n",
    "    ])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
